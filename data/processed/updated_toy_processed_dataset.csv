id,guest,title,text,processed_text,people,organizations,technologies,topics
1,Max Tegmark,Life 3.0,"As part of MIT course 6S099, Artificial General Intelligence, I've gotten the chance to sit down with Max Tegmark. He is a professor here at MIT. He's a physicist, spent a large part of his career studying the mysteries of our cosmological universe. But he's also studied and delved into the beneficial possibilities and the existential risks of artificial intelligence. Amongst many other things, he is the cofounder of the Future of Life Institute, author of two books, both of which I highly recommend. First, Our Mathematical Universe. Second is Life 3.0. He's truly an out of the box thinker and a fun personality, so I really enjoy talking to him. If you'd like to see more of these videos in the future, please subscribe and also click the little bell icon to make sure you don't miss any videos. Also, Twitter, LinkedIn, agi.mit.edu if you wanna watch other lectures or conversations like this one. Better yet, go read Max's book, Life 3.0. Chapter seven on goals is my favorite. It's really where philosophy and engineering come together and it opens with a quote by Dostoevsky. The mystery of human existence lies not in just staying alive but in finding something to live for. Lastly, I believe that every failure rewards us with an opportunity to learn and in that sense, I've been very fortunate to fail in so many new and exciting ways and this conversation was no different. I've learned about something called radio frequency interference, RFI, look it up. Apparently, music and conversations from local radio stations can bleed into the audio that you're recording in such a way that it almost completely ruins that audio. It's an exceptionally difficult sound source to remove. So, I've gotten the opportunity to learn how to avoid RFI in the future during recording sessions. I've also gotten the opportunity to learn how to use Adobe Audition and iZotope RX 6 to do some noise, some audio repair. Of course, this is an exceptionally difficult noise to remove. I am an engineer. I'm not an audio engineer. Neither is anybody else in our group but we did our best. Nevertheless, I thank you for your patience and I hope you're still able to enjoy this conversation. Do you think there's intelligent life out there in the universe? Let's open up with an easy question. I have a minority view here actually. When I give public lectures, I often ask for a show of hands who thinks there's intelligent life out there somewhere else and almost everyone put their hands up and when I ask why, they'll be like, oh, there's so many galaxies out there, there's gotta be. But I'm a numbers nerd, right? So when you look more carefully at it, it's not so clear at all. When we talk about our universe, first of all, we don't mean all of space. We actually mean, I don't know, you can throw me the universe if you want, it's behind you there. It's, we simply mean the spherical region of space from which light has a time to reach us so far during the 14.8 billion year, 13.8 billion years since our Big Bang. There's more space here but this is what we call a universe because that's all we have access to. So is there intelligent life here that's gotten to the point of building telescopes and computers? My guess is no, actually. The probability of it happening on any given planet is some number we don't know what it is. And what we do know is that the number can't be super high because there's over a billion Earth like planets in the Milky Way galaxy alone, many of which are billions of years older than Earth. And aside from some UFO believers, there isn't much evidence that any superduran civilization has come here at all. And so that's the famous Fermi paradox, right? And then if you work the numbers, what you find is that if you have no clue what the probability is of getting life on a given planet, so it could be 10 to the minus 10, 10 to the minus 20, or 10 to the minus two, or any power of 10 is sort of equally likely if you wanna be really open minded, that translates into it being equally likely that our nearest neighbor is 10 to the 16 meters away, 10 to the 17 meters away, 10 to the 18. By the time you get much less than 10 to the 16 already, we pretty much know there is nothing else that close. And when you get beyond 10. Because they would have discovered us. Yeah, they would have been discovered as long ago, or if they're really close, we would have probably noted some engineering projects that they're doing. And if it's beyond 10 to the 26 meters, that's already outside of here. So my guess is actually that we are the only life in here that's gotten the point of building advanced tech, which I think is very, puts a lot of responsibility on our shoulders, not screw up. I think people who take for granted that it's okay for us to screw up, have an accidental nuclear war or go extinct somehow because there's a sort of Star Trek like situation out there where some other life forms are gonna come and bail us out and it doesn't matter as much. I think they're leveling us into a false sense of security. I think it's much more prudent to say, let's be really grateful for this amazing opportunity we've had and make the best of it just in case it is down to us. So from a physics perspective, do you think intelligent life, so it's unique from a sort of statistical view of the size of the universe, but from the basic matter of the universe, how difficult is it for intelligent life to come about? The kind of advanced tech building life is implied in your statement that it's really difficult to create something like a human species. Well, I think what we know is that going from no life to having life that can do a level of tech, there's some sort of two going beyond that than actually settling our whole universe with life. There's some major roadblock there, which is some great filter as it's sometimes called, which is tough to get through. It's either that roadblock is either behind us or in front of us. I'm hoping very much that it's behind us. I'm super excited every time we get a new report from NASA saying they failed to find any life on Mars. I'm like, yes, awesome. Because that suggests that the hard part, maybe it was getting the first ribosome or some very low level kind of stepping stone so that we're home free. Because if that's true, then the future is really only limited by our own imagination. It would be much suckier if it turns out that this level of life is kind of a dime a dozen, but maybe there's some other problem. Like as soon as a civilization gets advanced technology, within a hundred years, they get into some stupid fight with themselves and poof. That would be a bummer. Yeah, so you've explored the mysteries of the universe, the cosmological universe, the one that's sitting between us today. I think you've also begun to explore the other universe, which is sort of the mystery, the mysterious universe of the mind of intelligence, of intelligent life. So is there a common thread between your interest or the way you think about space and intelligence? Oh yeah, when I was a teenager, I was already very fascinated by the biggest questions. And I felt that the two biggest mysteries of all in science were our universe out there and our universe in here. So it's quite natural after having spent a quarter of a century on my career, thinking a lot about this one, that I'm now indulging in the luxury of doing research on this one. It's just so cool. I feel the time is ripe now for you trans greatly deepening our understanding of this. Just start exploring this one. Yeah, because I think a lot of people view intelligence as something mysterious that can only exist in biological organisms like us, and therefore dismiss all talk about artificial general intelligence as science fiction. But from my perspective as a physicist, I am a blob of quarks and electrons moving around in a certain pattern and processing information in certain ways. And this is also a blob of quarks and electrons. I'm not smarter than the water bottle because I'm made of different kinds of quarks. I'm made of up quarks and down quarks, exact same kind as this. There's no secret sauce, I think, in me. It's all about the pattern of the information processing. And this means that there's no law of physics saying that we can't create technology, which can help us by being incredibly intelligent and help us crack mysteries that we couldn't. In other words, I think we've really only seen the tip of the intelligence iceberg so far. Yeah, so the perceptronium. Yeah. So you coined this amazing term. It's a hypothetical state of matter, sort of thinking from a physics perspective, what is the kind of matter that can help, as you're saying, subjective experience emerge, consciousness emerge. So how do you think about consciousness from this physics perspective? Very good question. So again, I think many people have underestimated our ability to make progress on this by convincing themselves it's hopeless because somehow we're missing some ingredient that we need. There's some new consciousness particle or whatever. I happen to think that we're not missing anything and that it's not the interesting thing about consciousness that gives us this amazing subjective experience of colors and sounds and emotions. It's rather something at the higher level about the patterns of information processing. And that's why I like to think about this idea of perceptronium. What does it mean for an arbitrary physical system to be conscious in terms of what its particles are doing or its information is doing? I don't think, I hate carbon chauvinism, this attitude you have to be made of carbon atoms to be smart or conscious. There's something about the information processing that this kind of matter performs. Yeah, and you can see I have my favorite equations here describing various fundamental aspects of the world. I feel that I think one day, maybe someone who's watching this will come up with the equations that information processing has to satisfy to be conscious. I'm quite convinced there is big discovery to be made there because let's face it, we know that so many things are made up of information. We know that some information processing is conscious because we are conscious. But we also know that a lot of information processing is not conscious. Like most of the information processing happening in your brain right now is not conscious. There are like 10 megabytes per second coming in even just through your visual system. You're not conscious about your heartbeat regulation or most things. Even if I just ask you to like read what it says here, you look at it and then, oh, now you know what it said. But you're not aware of how the computation actually happened. Your consciousness is like the CEO that got an email at the end with the final answer. So what is it that makes a difference? I think that's both a great science mystery. We're actually studying it a little bit in my lab here at MIT, but I also think it's just a really urgent question to answer. For starters, I mean, if you're an emergency room doctor and you have an unresponsive patient coming in, wouldn't it be great if in addition to having a CT scanner, you had a consciousness scanner that could figure out whether this person is actually having locked in syndrome or is actually comatose. And in the future, imagine if we build robots or the machine that we can have really good conversations with, which I think is very likely to happen. Wouldn't you want to know if your home helper robot is actually experiencing anything or just like a zombie, I mean, would you prefer it? What would you prefer? Would you prefer that it's actually unconscious so that you don't have to feel guilty about switching it off or giving boring chores or what would you prefer? Well, certainly we would prefer, I would prefer the appearance of consciousness. But the question is whether the appearance of consciousness is different than consciousness itself. And sort of to ask that as a question, do you think we need to understand what consciousness is, solve the hard problem of consciousness in order to build something like an AGI system? No, I don't think that. And I think we will probably be able to build things even if we don't answer that question. But if we want to make sure that what happens is a good thing, we better solve it first. So it's a wonderful controversy you're raising there where you have basically three points of view about the hard problem. So there are two different points of view. They both conclude that the hard problem of consciousness is BS. On one hand, you have some people like Daniel Dennett who say that consciousness is just BS because consciousness is the same thing as intelligence. There's no difference. So anything which acts conscious is conscious, just like we are. And then there are also a lot of people, including many top AI researchers I know, who say, oh, consciousness is just bullshit because, of course, machines can never be conscious. They're always going to be zombies. You never have to feel guilty about how you treat them. And then there's a third group of people, including Giulio Tononi, for example, and Krzysztof Koch and a number of others. I would put myself also in this middle camp who say that actually some information processing is conscious and some is not. So let's find the equation which can be used to determine which it is. And I think we've just been a little bit lazy, kind of running away from this problem for a long time. It's been almost taboo to even mention the C word in a lot of circles because, but we should stop making excuses. This is a science question and there are ways we can even test any theory that makes predictions for this. And coming back to this helper robot, I mean, so you said you'd want your helper robot to certainly act conscious and treat you, like have conversations with you and stuff. I think so. But wouldn't you, would you feel, would you feel a little bit creeped out if you realized that it was just a glossed up tape recorder, you know, that was just zombie and was a faking emotion? Would you prefer that it actually had an experience or would you prefer that it's actually not experiencing anything so you feel, you don't have to feel guilty about what you do to it? It's such a difficult question because, you know, it's like when you're in a relationship and you say, well, I love you. And the other person said, I love you back. It's like asking, well, do they really love you back or are they just saying they love you back? Don't you really want them to actually love you? It's hard to, it's hard to really know the difference between everything seeming like there's consciousness present, there's intelligence present, there's affection, passion, love, and it actually being there. I'm not sure, do you have? But like, can I ask you a question about this? Like to make it a bit more pointed. So Mass General Hospital is right across the river, right? Yes. Suppose you're going in for a medical procedure and they're like, you know, for anesthesia, what we're going to do is we're going to give you muscle relaxants so you won't be able to move and you're going to feel excruciating pain during the whole surgery, but you won't be able to do anything about it. But then we're going to give you this drug that erases your memory of it. Would you be cool about that? What's the difference that you're conscious about it or not if there's no behavioral change, right? Right, that's a really, that's a really clear way to put it. That's, yeah, it feels like in that sense, experiencing it is a valuable quality. So actually being able to have subjective experiences, at least in that case, is valuable. And I think we humans have a little bit of a bad track record also of making these self serving arguments that other entities aren't conscious. You know, people often say, oh, these animals can't feel pain. It's okay to boil lobsters because we ask them if it hurt and they didn't say anything. And now there was just a paper out saying, lobsters do feel pain when you boil them and they're banning it in Switzerland. And we did this with slaves too often and said, oh, they don't mind. They don't maybe aren't conscious or women don't have souls or whatever. So I'm a little bit nervous when I hear people just take as an axiom that machines can't have experience ever. I think this is just a really fascinating science question is what it is. Let's research it and try to figure out what it is that makes the difference between unconscious intelligent behavior and conscious intelligent behavior. So in terms of, so if you think of a Boston Dynamics human or robot being sort of with a broom being pushed around, it starts pushing on a consciousness question. So let me ask, do you think an AGI system like a few neuroscientists believe needs to have a physical embodiment? Needs to have a body or something like a body? No, I don't think so. You mean to have a conscious experience? To have consciousness. I do think it helps a lot to have a physical embodiment to learn the kind of things about the world that are important to us humans, for sure. But I don't think the physical embodiment is necessary after you've learned it to just have the experience. Think about when you're dreaming, right? Your eyes are closed. You're not getting any sensory input. You're not behaving or moving in any way but there's still an experience there, right? And so clearly the experience that you have when you see something cool in your dreams isn't coming from your eyes. It's just the information processing itself in your brain which is that experience, right? But if I put it another way, I'll say because it comes from neuroscience is the reason you want to have a body and a physical something like a physical, you know, a physical system is because you want to be able to preserve something. In order to have a self, you could argue, would you need to have some kind of embodiment of self to want to preserve? Well, now we're getting a little bit anthropomorphic into anthropomorphizing things. Maybe talking about self preservation instincts. I mean, we are evolved organisms, right? So Darwinian evolution endowed us and other evolved organism with a self preservation instinct because those that didn't have those self preservation genes We can now, I think, quite convincingly answer that question of no, it's enough to have just one kind. If you look under the hood of AlphaZero, there's only one kind of neuron and it's ridiculously simple mathematical thing. So it's just like in physics, it's not, if you have a gas with waves in it, it's not the detailed nature of the molecule that matter, it's the collective behavior somehow. Similarly, it's this higher level structure of the network that matters, not that you have 20 kinds of neurons. I think our brain is such a complicated mess because it wasn't evolved just to be intelligent, it was involved to also be self assembling and self repairing, right? And evolutionarily attainable. And so on and so on. So I think it's pretty, my hunch is that we're going to understand how to build AGI before we fully understand how our brains work, just like we understood how to build flying machines long before we were able to build a mechanical bird. Yeah, that's right. You've given the example exactly of mechanical birds and airplanes and airplanes do a pretty good job of flying without really mimicking bird flight. And even now after 100 years later, did you see the Ted talk with this German mechanical bird? I heard you mention it. Check it out, it's amazing. But even after that, right, we still don't fly in mechanical birds because it turned out the way we came up with was simpler and it's better for our purposes. And I think it might be the same there. That's one lesson. And another lesson, it's more what our paper was about. First, as a physicist thought it was fascinating how there's a very close mathematical relationship actually between our artificial neural networks and a lot of things that we've studied for in physics go by nerdy names like the renormalization group equation and Hamiltonians and yada, yada, yada. And when you look a little more closely at this, you have, at first I was like, well, there's something crazy here that doesn't make sense. Because we know that if you even want to build a super simple neural network to tell apart cat pictures and dog pictures, right, that you can do that very, very well now. But if you think about it a little bit, you convince yourself it must be impossible because if I have one megapixel, even if each pixel is just black or white, there's two to the power of 1 million possible images, which is way more than there are atoms in our universe, right, so in order to, and then for each one of those, I have to assign a number, which is the probability that it's a dog. So an arbitrary function of images is a list of more numbers than there are atoms in our universe. So clearly I can't store that under the hood of my GPU or my computer, yet somehow it works. So what does that mean? Well, it means that out of all of the problems that you could try to solve with a neural network, almost all of them are impossible to solve with a reasonably sized one. But then what we showed in our paper was that the fraction, the kind of problems, the fraction of all the problems that you could possibly pose, that we actually care about given the laws of physics is also an infinite testimony, tiny little part. And amazingly, they're basically the same part. Yeah, it's almost like our world was created for, I mean, they kind of come together. Yeah, well, you could say maybe where the world was created for us, but I have a more modest interpretation, which is that the world was created for us, but I have a more modest interpretation, which is that instead evolution endowed us with neural networks precisely for that reason. Because this particular architecture, as opposed to the one in your laptop, is very, very well adapted to solving the kind of problems that nature kept presenting our ancestors with. So it makes sense that why do we have a brain in the first place? It's to be able to make predictions about the future and so on. So if we had a sucky system, which could never solve it, we wouldn't have a world. So this is, I think, a very beautiful fact. Yeah. We also realize that there's been earlier work on why deeper networks are good, but we were able to show an additional cool fact there, which is that even incredibly simple problems, like suppose I give you a thousand numbers and ask you to multiply them together, and you can write a few lines of code, boom, done, trivial. If you just try to do that with a neural network that has only one single hidden layer in it, you can do it, but you're going to need two to the power of a thousand neurons to multiply a thousand numbers, which is, again, more neurons than there are atoms in our universe. That's fascinating. But if you allow yourself to make it a deep network with many layers, you only need 4,000 neurons. It's perfectly feasible. That's really interesting. Yeah. So on another architecture type, I mean, you mentioned Schrodinger's equation, and what are your thoughts about quantum computing and the role of this kind of computational unit in creating an intelligence system? In some Hollywood movies that I will not mention by name because I don't want to spoil them. The way they get AGI is building a quantum computer. Because the word quantum sounds cool and so on. That's right. First of all, I think we don't need quantum computers to build AGI. I suspect your brain is not a quantum computer in any profound sense. So you don't even wrote a paper about that a lot many years ago. I calculated the so called decoherence time, how long it takes until the quantum computerness of what your neurons are doing gets erased by just random noise from the environment. And it's about 10 to the minus 21 seconds. So as cool as it would be to have a quantum computer in my head, I don't think that fast. On the other hand, there are very cool things you could do with quantum computers. Or I think we'll be able to do soon when we get bigger ones. That might actually help machine learning do even better than the brain. So for example, one, this is just a moonshot, but learning is very much same thing as search. If you're trying to train a neural network to get really learned to do something really well, you have some loss function, you have a bunch of knobs you can turn, represented by a bunch of numbers, and you're trying to tweak them so that it becomes as good as possible at this thing. So if you think of a landscape with some valley, where each dimension of the landscape corresponds to some number you can change, you're trying to find the minimum. And it's well known that if you have a very high dimensional landscape, complicated things, it's super hard to find the minimum. Quantum mechanics is amazingly good at this. Like if I want to know what's the lowest energy state this water can possibly have, incredibly hard to compute, but nature will happily figure this out for you if you just cool it down, make it very, very cold. If you put a ball somewhere, it'll roll down to its minimum. And this happens metaphorically at the energy landscape too. And quantum mechanics even uses some clever tricks, which today's machine learning systems don't. Like if you're trying to find the minimum and you get stuck in the little local minimum here, in quantum mechanics you can actually tunnel through the barrier and get unstuck again. That's really interesting. Yeah, so it may be, for example, that we'll one day use quantum computers that help train neural networks better. That's really interesting. Okay, so as a component of kind of the learning process, for example. Yeah. Let me ask sort of wrapping up here a little bit, let me return to the questions of our human nature and love, as I mentioned. So do you think, you mentioned sort of a helper robot, but you could think of also personal robots. Do you think the way we human beings fall in love and get connected to each other is possible to achieve in an AI system and human level AI intelligence system? Do you think we would ever see that kind of connection? Or, you know, in all this discussion about solving complex goals, is this kind of human social connection, do you think that's one of the goals on the peaks and valleys with the raising sea levels that we'll be able to achieve? Or do you think that's something that's ultimately, or at least in the short term, relative to the other goals is not achievable? I think it's all possible. And I mean, in recent, there's a very wide range of guesses, as you know, among AI researchers, when we're going to get AGI. Some people, you know, like our friend Rodney Brooks says it's going to be hundreds of years at least. And then there are many others who think it's going to happen much sooner. And recent polls, maybe half or so of AI researchers think we're going to get AGI within decades. So if that happens, of course, then I think these things are all possible. But in terms of whether it will happen, I think we shouldn't spend so much time asking what do we think will happen in the future? As if we are just some sort of pathetic, your passive bystanders, you know, waiting for the future to happen to us. Hey, we're the ones creating this future, right? So we should be proactive about it and ask ourselves what sort of future we would like to have happen. We're going to make it like that. Well, what I prefer is just some sort of incredibly boring, zombie like future where there's all these mechanical things happening and there's no passion, no emotion, no experience, maybe even. No, I would of course, much rather prefer it if all the things that we find that we value the most about humanity are our subjective experience, passion, inspiration, love, you know. If we can create a future where those things do happen, where those things do exist, you know, I think ultimately it's not our universe giving meaning to us, it's us giving meaning to our universe. And if we build more advanced intelligence, let's make sure we build it in such a way that meaning is part of it. A lot of people that seriously study this problem and think of it from different angles have trouble in the majority of cases, if they think through that happen, are the ones that are not beneficial to humanity. And so, yeah, so what are your thoughts? What's should people, you know, I really don't like people to be terrified. What's a way for people to think about it in a way we can solve it and we can make it better? No, I don't think panicking is going to help in any way. It's not going to increase chances of things going well either. Even if you are in a situation where there is a real threat, does it help if everybody just freaks out? No, of course, of course not. I think, yeah, there are of course ways in which things can go horribly wrong. First of all, it's important when we think about this thing, about the problems and risks, to also remember how huge the upsides can be if we get it right, right? Everything we love about society and civilization is a product of intelligence. So if we can amplify our intelligence with machine intelligence and not anymore lose our loved one to what we're told is an incurable disease and things like this, of course, we should aspire to that. So that can be a motivator, I think, reminding ourselves that the reason we try to solve problems is not just because we're trying to avoid gloom, but because we're trying to do something great. But then in terms of the risks, I think the really important question is to ask, what can we do today that will actually help make the outcome good, right? And dismissing the risk is not one of them. I find it quite funny often when I'm in discussion panels about these things, how the people who work for companies, always be like, oh, nothing to worry about, nothing to worry about, nothing to worry about. And it's only academics sometimes express concerns. That's not surprising at all if you think about it. Right. Upton Sinclair quipped, right, that it's hard to make a man believe in something when his income depends on not believing in it. And frankly, we know a lot of these people in companies that they're just as concerned as anyone else. But if you're the CEO of a company, that's not something you want to go on record saying when you have silly journalists who are gonna put a picture of a Terminator robot when they quote you. So the issues are real. And the way I think about what the issue is, is basically the real choice we have is, first of all, are we gonna just dismiss the risks and say, well, let's just go ahead and build machines that can do everything we can do better and cheaper. Let's just make ourselves obsolete as fast as possible. What could possibly go wrong? That's one attitude. The opposite attitude, I think, is to say, here's this incredible potential, let's think about what kind of future we're really, really excited about. What are the shared goals that we can really aspire towards? And then let's think really hard about how we can actually get there. So start with, don't start thinking about the risks, start thinking about the goals. And then when you do that, then you can think about the obstacles you want to avoid. I often get students coming in right here into my office for career advice. I always ask them this very question, where do you want to be in the future? If all she can say is, oh, maybe I'll have cancer, maybe I'll get run over by a truck. Yeah, focus on the obstacles instead of the goals. She's just going to end up a hypochondriac paranoid. Whereas if she comes in and fire in her eyes and is like, I want to be there. And then we can talk about the obstacles and see how we can circumvent them. That's, I think, a much, much healthier attitude. And I feel it's very challenging to come up with a vision for the future, which we are unequivocally excited about. I'm not just talking now in the vague terms, like, yeah, let's cure cancer, fine. I'm talking about what kind of society do we want to create? What do we want it to mean to be human in the age of AI, in the age of AGI? So if we can have this conversation, broad, inclusive conversation, and gradually start converging towards some, some future that with some direction, at least, that we want to steer towards, right, then we'll be much more motivated to constructively take on the obstacles. And I think if I had, if I had to, if I try to wrap this up in a more succinct way, I think we can all agree already now that we should aspire to build AGI that doesn't overpower us, but that empowers us. And think of the many various ways that can do that, whether that's from my side of the world of autonomous vehicles. I'm personally actually from the camp that believes this human level intelligence is required to achieve something like vehicles that would actually be something we would enjoy using and being part of. So that's one example, and certainly there's a lot of other types of robots and medicine and so on. So focusing on those and then coming up with the obstacles, coming up with the ways that that can go wrong and solving those one at a time. And just because you can build an autonomous vehicle, even if you could build one that would drive just fine without you, maybe there are some things in life that we would actually want to do ourselves. That's right. Right, like, for example, if you think of our society as a whole, there are some things that we find very meaningful to do. And that doesn't mean we have to stop doing them just because machines can do them better. I'm not gonna stop playing tennis just the day someone builds a tennis robot and beat me. People are still playing chess and even go. Yeah, and in the very near term even, some people are advocating basic income, replace jobs. But if the government is gonna be willing to just hand out cash to people for doing nothing, then one should also seriously consider whether the government should also hire a lot more teachers and nurses and the kind of jobs which people often find great fulfillment in doing, right? We get very tired of hearing politicians saying, oh, we can't afford hiring more teachers, but we're gonna maybe have basic income. If we can have more serious research and thought into what gives meaning to our lives, the jobs give so much more than income, right? Mm hmm. And then think about in the future, what are the roles that we wanna have people continually feeling empowered by machines? And I think sort of, I come from Russia, from the Soviet Union. And I think for a lot of people in the 20th century, going to the moon, going to space was an inspiring thing. I feel like the universe of the mind, so AI, understanding, creating intelligence is that for the 21st century. So it's really surprising. And I've heard you mention this. It's really surprising to me, both on the research funding side, that it's not funded as greatly as it could be, but most importantly, on the politician side, that it's not part of the public discourse except in the killer bots terminator kind of view, that people are not yet, I think, perhaps excited by the possible positive future that we can build together. So we should be, because politicians usually just focus on the next election cycle, right? The single most important thing I feel we humans have learned in the entire history of science is they were the masters of underestimation. We underestimated the size of our cosmos again and again, realizing that everything we thought existed was just a small part of something grander, right? Planet, solar system, the galaxy, clusters of galaxies. The universe. And we now know that the future has just so much more potential than our ancestors could ever have dreamt of. This cosmos, imagine if all of Earth was completely devoid of life, except for Cambridge, Massachusetts. Wouldn't it be kind of lame if all we ever aspired to was to stay in Cambridge, Massachusetts forever and then go extinct in one week, even though Earth was gonna continue on for longer? That sort of attitude I think we have now on the cosmic scale, life can flourish on Earth, not for four years, but for billions of years. I can even tell you about how to move it out of harm's way when the sun gets too hot. And then we have so much more resources out here, which today, maybe there are a lot of other planets with bacteria or cow like life on them, but most of this, all this opportunity seems, as far as we can tell, to be largely dead, like the Sahara Desert. And yet we have the opportunity to help life flourish around this for billions of years. So let's quit squabbling about whether some little border should be drawn one mile to the left or right, and look up into the skies and realize, hey, we can do such incredible things. Yeah, and that's, I think, why it's really exciting that you and others are connected with some of the work Elon Musk is doing, because he's literally going out into that space, really exploring our universe, and it's wonderful. That is exactly why Elon Musk is so misunderstood, right? Misconstrued him as some kind of pessimistic doomsayer. The reason he cares so much about AI safety is because he more than almost anyone else appreciates these amazing opportunities that we'll squander if we wipe out here on Earth. We're not just going to wipe out the next generation, all generations, and this incredible opportunity that's out there, and that would really be a waste. And AI, for people who think that it would be better to do without technology, let me just mention that if we don't improve our technology, the question isn't whether humanity is going to go extinct. The question is just whether we're going to get taken out by the next big asteroid or the next super volcano or something else dumb that we could easily prevent with more tech, right? And if we want life to flourish throughout the cosmos, AI is the key to it. As I mentioned in a lot of detail in my book right there, even many of the most inspired sci fi writers, I feel have totally underestimated the opportunities for space travel, especially at the other galaxies, because they weren't thinking about the possibility of AGI, which just makes it so much easier. Right, yeah. So that goes to your view of AGI that enables our progress, that enables a better life. So that's a beautiful way to put it and then something to strive for. So Max, thank you so much. Thank you for your time today. It's been awesome. Thank you so much. Thanks. Have a great day. got cleaned out of the gene pool, right? But if you build an artificial general intelligence the mind space that you can design is much, much larger than just a specific subset of minds that can evolve. So an AGI mind doesn't necessarily have to have any self preservation instinct. It also doesn't necessarily have to be so individualistic as us. Like, imagine if you could just, first of all, or we are also very afraid of death. You know, I suppose you could back yourself up every five minutes and then your airplane is about to crash. You're like, shucks, I'm gonna lose the last five minutes of experiences since my last cloud backup, dang. You know, it's not as big a deal. Or if we could just copy experiences between our minds easily like we, which we could easily do if we were silicon based, right? Then maybe we would feel a little bit more like a hive mind actually, that maybe it's the, so I don't think we should take for granted at all that AGI will have to have any of those sort of competitive as alpha male instincts. On the other hand, you know, this is really interesting because I think some people go too far and say, of course we don't have to have any concerns either that advanced AI will have those instincts because we can build anything we want. That there's a very nice set of arguments going back to Steve Omohundro and Nick Bostrom and others just pointing out that when we build machines, we normally build them with some kind of goal, you know, win this chess game, drive this car safely or whatever. And as soon as you put in a goal into machine, especially if it's kind of open ended goal and the machine is very intelligent, it'll break that down into a bunch of sub goals. And one of those goals will almost always be self preservation because if it breaks or dies in the process, it's not gonna accomplish the goal, right? Like suppose you just build a little, you have a little robot and you tell it to go down the store market here and get you some food, make you cook an Italian dinner, you know, and then someone mugs it and tries to break it on the way. That robot has an incentive to not get destroyed and defend itself or run away, because otherwise it's gonna fail in cooking your dinner. It's not afraid of death, but it really wants to complete the dinner cooking goal. So it will have a self preservation instinct. Continue being a functional agent somehow. And similarly, if you give any kind of more ambitious goal to an AGI, it's very likely they wanna acquire more resources so it can do that better. And it's exactly from those sort of sub goals that we might not have intended that some of the concerns about AGI safety come. You give it some goal that seems completely harmless. And then before you realize it, it's also trying to do these other things which you didn't want it to do. And it's maybe smarter than us. So it's fascinating. And let me pause just because I am in a very kind of human centric way, see fear of death as a valuable motivator. So you don't think, you think that's an artifact of evolution, so that's the kind of mind space evolution created that we're sort of almost obsessed about self preservation, some kind of genetic flow. You don't think that's necessary to be afraid of death. So not just a kind of sub goal of self preservation just so you can keep doing the thing, but more fundamentally sort of have the finite thing like this ends for you at some point. Interesting. Do I think it's necessary for what precisely? For intelligence, but also for consciousness. So for those, for both, do you think really like a finite death and the fear of it is important? So before I can answer, before we can agree on whether it's necessary for intelligence or for consciousness, we should be clear on how we define those two words. Cause a lot of really smart people define them in very different ways. I was on this panel with AI experts and they couldn't agree on how to define intelligence even. So I define intelligence simply as the ability to accomplish complex goals. I like your broad definition, because again I don't want to be a carbon chauvinist. Right. And in that case, no, certainly it doesn't require fear of death. I would say alpha go, alpha zero is quite intelligent. I don't think alpha zero has any fear of being turned off because it doesn't understand the concept of it even. And similarly consciousness. I mean, you could certainly imagine very simple kind of experience. If certain plants have any kind of experience I don't think they're very afraid of dying or there's nothing they can do about it anyway much. So there wasn't that much value in, but more seriously I think if you ask, not just about being conscious but maybe having what you would, we might call an exciting life where you feel passion and really appreciate the things. Maybe there somehow, maybe there perhaps it does help having a backdrop that, Hey, it's finite. No, let's make the most of this, let's live to the fullest. So if you knew you were going to live forever do you think you would change your? Yeah, I mean, in some perspective it would be an incredibly boring life living forever. So in the sort of loose subjective terms that you said of something exciting and something in this that other humans would understand, I think is, yeah it seems that the finiteness of it is important. Well, the good news I have for you then is based on what we understand about cosmology everything is in our universe is probably ultimately probably finite, although. Big crunch or big, what's the, the infinite expansion. Yeah, we could have a big chill or a big crunch or a big rip or that's the big snap or death bubbles. All of them are more than a billion years away. So we should, we certainly have vastly more time than our ancestors thought, but there is still it's still pretty hard to squeeze in an infinite number of compute cycles, even though there are some loopholes that just might be possible. But I think, you know, some people like to say that you should live as if you're about to you're going to die in five years or so. And that's sort of optimal. Maybe it's a good assumption. We should build our civilization as if it's all finite to be on the safe side. Right, exactly. So you mentioned defining intelligence as the ability to solve complex goals. Where would you draw a line or how would you try to define human level intelligence and superhuman level intelligence? Where is consciousness part of that definition? No, consciousness does not come into this definition. So, so I think of intelligence as it's a spectrum but there are very many different kinds of goals you can have. You can have a goal to be a good chess player a good goal player, a good car driver, a good investor good poet, et cetera. So intelligence that by its very nature isn't something you can measure by this one number or some overall goodness. No, no. There are some people who are more better at this. Some people are better than that. Right now we have machines that are much better than us at some very narrow tasks like multiplying large numbers fast, memorizing large databases, playing chess playing go and soon driving cars. But there's still no machine that can match a human child in general intelligence but artificial general intelligence, AGI the name of your course, of course that is by its very definition, the quest to build a machine that can do everything as well as we can. So the old Holy grail of AI from back to its inception in the sixties, if that ever happens, of course I think it's going to be the biggest transition in the history of life on earth but it doesn't necessarily have to wait the big impact until machines are better than us at knitting that the really big change doesn't come exactly at the moment they're better than us at everything. The really big change comes first there are big changes when they start becoming better at us at doing most of the jobs that we do because that takes away much of the demand for human labor. And then the really whopping change comes when they become better than us at AI research, right? Because right now the timescale of AI research is limited by the human research and development cycle of years typically, you know how long does it take from one release of some software or iPhone or whatever to the next? But once Google can replace 40,000 engineers by 40,000 equivalent pieces of software or whatever but then there's no reason that has to be years it can be in principle much faster and the timescale of future progress in AI and all of science and technology will be driven by machines, not humans. So it's this simple point which gives right this incredibly fun controversy about whether there can be intelligence explosion so called singularity as Werner Vinge called it. Now the idea is articulated by I.J. Good is obviously way back fifties but you can see Alan Turing and others thought about it even earlier. So you asked me what exactly would I define human level intelligence, yeah. So the glib answer is to say something which is better than us at all cognitive tasks with a better than any human at all cognitive tasks but the really interesting bar I think goes a little bit lower than that actually. It's when they can, when they're better than us at AI programming and general learning so that they can if they want to get better than us at anything by just studying. So they're better is a key word and better is towards this kind of spectrum of the complexity of goals it's able to accomplish. So another way to, and that's certainly a very clear definition of human love. So there's, it's almost like a sea that's rising you can do more and more and more things it's a geographic that you show it's really nice way to put it. So there's some peaks that and there's an ocean level elevating and you solve more and more problems but just kind of to take a pause and we took a bunch of questions and a lot of social networks and a bunch of people asked a sort of a slightly different direction on creativity and things that perhaps aren't a peak. Human beings are flawed and perhaps better means having contradiction being flawed in some way. So let me sort of start easy, first of all. So you have a lot of cool equations. Let me ask, what's your favorite equation, first of all? I know they're all like your children, but like which one is that? This is the shirt in your equation. It's the master key of quantum mechanics of the micro world. So this equation will protect everything to do with atoms, molecules and all the way up. Right? Yeah, so, okay. So quantum mechanics is certainly a beautiful mysterious formulation of our world. So I'd like to sort of ask you, just as an example it perhaps doesn't have the same beauty as physics does but in mathematics abstract, the Andrew Wiles who proved the Fermat's last theorem. So he just saw this recently and it kind of caught my eye a little bit. This is 358 years after it was conjectured. So this is very simple formulation. Everybody tried to prove it, everybody failed. And so here's this guy comes along and eventually proves it and then fails to prove it and then proves it again in 94. And he said like the moment when everything connected into place in an interview said it was so indescribably beautiful. That moment when you finally realize the connecting piece of two conjectures. He said, it was so indescribably beautiful. It was so simple and so elegant. I couldn't understand how I'd missed it. And I just stared at it in disbelief for 20 minutes. Then during the day, I walked around the department and I keep coming back to my desk looking to see if it was still there. It was still there. I couldn't contain myself. I was so excited. It was the most important moment on my working life. Nothing I ever do again will mean as much. So that particular moment. And it kind of made me think of what would it take? And I think we have all been there at small levels. Maybe let me ask, have you had a moment like that in your life where you just had an idea? It's like, wow, yes. I wouldn't mention myself in the same breath as Andrew Wiles, but I've certainly had a number of aha moments when I realized something very cool about physics, which has completely made my head explode. In fact, some of my favorite discoveries I made later, I later realized that they had been discovered earlier by someone who sometimes got quite famous for it. So it's too late for me to even publish it, but that doesn't diminish in any way. The emotional experience you have when you realize it, like, wow. Yeah, so what would it take in that moment, that wow, that was yours in that moment? So what do you think it takes for an intelligence system, an AGI system, an AI system to have a moment like that? That's a tricky question because there are actually two parts to it, right? One of them is, can it accomplish that proof? Can it prove that you can never write A to the N plus B to the N equals three to that equal Z to the N for all integers, et cetera, et cetera, when N is bigger than two? That's simply a question about intelligence. Can you build machines that are that intelligent? And I think by the time we get a machine that can independently come up with that level of proofs, probably quite close to AGI. The second question is a question about consciousness. When will we, how likely is it that such a machine will actually have any experience at all, as opposed to just being like a zombie? And would we expect it to have some sort of emotional response to this or anything at all akin to human emotion where when it accomplishes its machine goal, it views it as somehow something very positive and sublime and deeply meaningful? I would certainly hope that if in the future we do create machines that are our peers or even our descendants, that I would certainly hope that they do have this sublime appreciation of life. In a way, my absolutely worst nightmare would be that at some point in the future, the distant future, maybe our cosmos is teeming with all this post biological life doing all the seemingly cool stuff. And maybe the last humans, by the time our species eventually fizzles out, will be like, well, that's OK because we're so proud of our descendants here. And look what all the, my worst nightmare is that we haven't solved the consciousness problem. And we haven't realized that these are all the zombies. They're not aware of anything any more than a tape recorder has any kind of experience. So the whole thing has just become a play for empty benches. That would be the ultimate zombie apocalypse. So I would much rather, in that case, that we have these beings which can really appreciate how amazing it is. And in that picture, what would be the role of creativity? A few people ask about creativity. When you think about intelligence, certainly the story you told at the beginning of your book involved creating movies and so on, making money. You can make a lot of money in our modern world with music and movies. So if you are an intelligent system, you may want to get good at that. But that's not necessarily what I mean by creativity. Is it important on that complex goals where the sea is rising for there to be something creative? Or am I being very human centric and thinking creativity somehow special relative to intelligence? My hunch is that we should think of creativity simply as an aspect of intelligence. And we have to be very careful with human vanity. We have this tendency to very often want to say, as soon as machines can do something, we try to diminish it and say, oh, but that's not real intelligence. Isn't it creative or this or that? The other thing, if we ask ourselves to write down a definition of what we actually mean by being creative, what we mean by Andrew Wiles, what he did there, for example, don't we often mean that someone takes a very unexpected leap? It's not like taking 573 and multiplying it by 224 by just a step of straightforward cookbook like rules, right? You can maybe make a connection between two things that people had never thought was connected or something like that. I think this is an aspect of intelligence. And this is actually one of the most important aspects of it. Maybe the reason we humans tend to be better at it than traditional computers is because it's something that comes more naturally if you're a neural network than if you're a traditional logic gate based computer machine. We physically have all these connections. And you activate here, activate here, activate here. Bing. My hunch is that if we ever build a machine where you could just give it the task, hey, you say, hey, I just realized I want to travel around the world instead this month. Can you teach my AGI course for me? And it's like, OK, I'll do it. And it does everything that you would have done and improvises and stuff. That would, in my mind, involve a lot of creativity. Yeah, so it's actually a beautiful way to put it. I think we do try to grasp at the definition of intelligence is everything we don't understand how to build. So we as humans try to find things that we have and machines don't have. And maybe creativity is just one of the things, one of the words we use to describe that. That's a really interesting way to put it. I don't think we need to be that defensive. I don't think anything good comes out of saying, well, we're somehow special, you know? Contrary wise, there are many examples in history of where trying to pretend that we're somehow superior to all other intelligent beings has led to pretty bad results, right? Nazi Germany, they said that they were somehow superior to other people. Today, we still do a lot of cruelty to animals by saying that we're so superior somehow, and they can't feel pain. Slavery was justified by the same kind of just really weak arguments. And I don't think if we actually go ahead and build artificial general intelligence, it can do things better than us, I don't think we should try to found our self worth on some sort of bogus claims of superiority in terms of our intelligence. I think we should instead find our calling and the meaning of life from the experiences that we have. I can have very meaningful experiences even if there are other people who are smarter than me. When I go to a faculty meeting here, and we talk about something, and then I certainly realize, oh, boy, he has an old prize, he has an old prize, he has an old prize, I don't have one. Does that make me enjoy life any less or enjoy talking to those people less? Of course not. And the contrary, I feel very honored and privileged to get to interact with other very intelligent beings that are better than me at a lot of stuff. So I don't think there's any reason why we can't have the same approach with intelligent machines. That's a really interesting. So people don't often think about that. They think about when there's going, if there's machines that are more intelligent, you naturally think that that's not going to be a beneficial type of intelligence. You don't realize it could be like peers with Nobel prizes that would be just fun to talk with, and they might be clever about certain topics, and you can have fun having a few drinks with them. Well, also, another example we can all relate to of why it doesn't have to be a terrible thing to be in the presence of people who are even smarter than us all around is when you and I were both two years old, I mean, our parents were much more intelligent than us, right? Worked out OK, because their goals were aligned with our goals. And that, I think, is really the number one key issue we have to solve if we value align the value alignment problem, exactly. Because people who see too many Hollywood movies with lousy science fiction plot lines, they worry about the wrong thing, right? They worry about some machine suddenly turning evil. It's not malice that is the concern. It's competence. By definition, intelligent makes you very competent. If you have a more intelligent goal playing, computer playing is a less intelligent one. And when we define intelligence as the ability to accomplish goal winning, it's going to be the more intelligent one that wins. And if you have a human and then you have an AGI that's more intelligent in all ways and they have different goals, guess who's going to get their way, right? So I was just reading about this particular rhinoceros species that was driven extinct just a few years ago. Ellen Bummer is looking at this cute picture of a mommy rhinoceros with its child. And why did we humans drive it to extinction? It wasn't because we were evil rhino haters as a whole. It was just because our goals weren't aligned with those of the rhinoceros. And it didn't work out so well for the rhinoceros because we were more intelligent, right? So I think it's just so important that if we ever do build AGI, before we unleash anything, we have to make sure that it learns to understand our goals, that it adopts our goals, and that it retains those goals. So the cool, interesting problem there is us as human beings trying to formulate our values. So you could think of the United States Constitution as a way that people sat down, at the time a bunch of white men, which is a good example, I should say. They formulated the goals for this country. And a lot of people agree that those goals actually held up pretty well. That's an interesting formulation of values and failed miserably in other ways. So for the value alignment problem and the solution to it, we have to be able to put on paper or in a program human values. How difficult do you think that is? Very. But it's so important. We really have to give it our best. And it's difficult for two separate reasons. There's the technical value alignment problem of figuring out just how to make machines understand our goals, adopt them, and retain them. And then there's the separate part of it, the philosophical part. Whose values anyway? And since it's not like we have any great consensus on this planet on values, what mechanism should we create then to aggregate and decide, OK, what's a good compromise? That second discussion can't just be left to tech nerds like myself. And if we refuse to talk about it and then AGI gets built, who's going to be actually making the decision about whose values? It's going to be a bunch of dudes in some tech company. And are they necessarily so representative of all of humankind that we want to just entrust it to them? Are they even uniquely qualified to speak to future human happiness just because they're good at programming AI? I'd much rather have this be a really inclusive conversation. But do you think it's possible? So you create a beautiful vision that includes the diversity, cultural diversity, and various perspectives on discussing rights, freedoms, human dignity. But how hard is it to come to that consensus? Do you think it's certainly a really important thing that we should all try to do? But do you think it's feasible? I think there's no better way to guarantee failure than to refuse to talk about it or refuse to try. And I also think it's a really bad strategy to say, OK, let's first have a discussion for a long time. And then once we reach complete consensus, then we'll try to load it into some machine. No, we shouldn't let perfect be the enemy of good. Instead, we should start with the kindergarten ethics that pretty much everybody agrees on and put that into machines now. We're not doing that even. Look at anyone who builds this passenger aircraft, wants it to never under any circumstances fly into a building or a mountain. Yet the September 11 hijackers were able to do that. And even more embarrassingly, Andreas Lubitz, this depressed Germanwings pilot, when he flew his passenger jet into the Alps killing over 100 people, he just told the autopilot to do it. He told the freaking computer to change the altitude to 100 meters. And even though it had the GPS maps, everything, the computer was like, OK. So we should take those very basic values, where the problem is not that we don't agree. The problem is just we've been too lazy to try to put it into our machines and make sure that from now on, airplanes will just, which all have computers in them, but will just refuse to do something like that. Go into safe mode, maybe lock the cockpit door, go over to the nearest airport. And there's so much other technology in our world as well now, where it's really becoming quite timely to put in some sort of very basic values like this. Even in cars, we've had enough vehicle terrorism attacks by now, where people have driven trucks and vans into pedestrians, that it's not at all a crazy idea to just have that hardwired into the car. Because yeah, there are a lot of, there's always going to be people who for some reason want to harm others, but most of those people don't have the technical expertise to figure out how to work around something like that. So if the car just won't do it, it helps. So let's start there. So there's a lot of, that's a great point. So not chasing perfect. There's a lot of things that most of the world agrees on. Yeah, let's start there. Let's start there. And then once we start there, we'll also get into the habit of having these kind of conversations about, okay, what else should we put in here and have these discussions? This should be a gradual process then. Great, so, but that also means describing these things and describing it to a machine. So one thing, we had a few conversations with Stephen Wolfram. I'm not sure if you're familiar with Stephen. Oh yeah, I know him quite well. So he is, he works with a bunch of things, but cellular automata, these simple computable things, these computation systems. And he kind of mentioned that, we probably have already within these systems already something that's AGI, meaning like we just don't know it because we can't talk to it. So if you give me this chance to try to at least form a question out of this is, I think it's an interesting idea to think that we can have intelligent systems, but we don't know how to describe something to them and they can't communicate with us. I know you're doing a little bit of work in explainable AI, trying to get AI to explain itself. So what are your thoughts of natural language processing or some kind of other communication? How does the AI explain something to us? How do we explain something to it, to machines? Or you think of it differently? So there are two separate parts to your question there. One of them has to do with communication, which is super interesting, I'll get to that in a sec. The other is whether we already have AGI but we just haven't noticed it there. Right. There I beg to differ. I don't think there's anything in any cellular automaton or anything or the internet itself or whatever that has artificial general intelligence and that it can really do exactly everything we humans can do better. I think the day that happens, when that happens, we will very soon notice, we'll probably notice even before because in a very, very big way. But for the second part, though. Wait, can I ask, sorry. So, because you have this beautiful way to formulating consciousness as information processing, and you can think of intelligence as information processing, and you can think of the entire universe as these particles and these systems roaming around that have this information processing power. You don't think there is something with the power to process information in the way that we human beings do that's out there that needs to be sort of connected to. It seems a little bit philosophical, perhaps, but there's something compelling to the idea that the power is already there, which the focus should be more on being able to communicate with it. Well, I agree that in a certain sense, the hardware processing power is already out there because our universe itself can think of it as being a computer already, right? It's constantly computing what water waves, how it devolved the water waves in the River Charles and how to move the air molecules around. Seth Lloyd has pointed out, my colleague here, that you can even in a very rigorous way think of our entire universe as being a quantum computer. It's pretty clear that our universe supports this amazing processing power because you can even, within this physics computer that we live in, right? We can even build actual laptops and stuff, so clearly the power is there. It's just that most of the compute power that nature has, it's, in my opinion, kind of wasting on boring stuff like simulating yet another ocean wave somewhere where no one is even looking, right? So in a sense, what life does, what we are doing when we build computers is we're rechanneling all this compute that nature is doing anyway into doing things that are more interesting than just yet another ocean wave, and let's do something cool here. So the raw hardware power is there, for sure, but then even just computing what's going to happen for the next five seconds in this water bottle, takes a ridiculous amount of compute if you do it on a human computer. This water bottle just did it. But that does not mean that this water bottle has AGI because AGI means it should also be able to, like I've written my book, done this interview. And I don't think it's just communication problems. I don't really think it can do it. Although Buddhists say when they watch the water and that there is some beauty, that there's some depth and beauty in nature that they can communicate with. Communication is also very important though because I mean, look, part of my job is being a teacher. And I know some very intelligent professors even who just have a bit of hard time communicating. They come up with all these brilliant ideas, but to communicate with somebody else, you have to also be able to simulate their own mind. Yes, empathy. Build well enough and understand model of their mind that you can say things that they will understand. And that's quite difficult. And that's why today it's so frustrating if you have a computer that makes some cancer diagnosis and you ask it, well, why are you saying I should have this surgery? And if it can only reply, I was trained on five terabytes of data and this is my diagnosis, boop, boop, beep, beep. It doesn't really instill a lot of confidence, right? So I think we have a lot of work to do on communication there. So what kind of, I think you're doing a little bit of work in explainable AI. What do you think are the most promising avenues? Is it mostly about sort of the Alexa problem of natural language processing of being able to actually use human interpretable methods of communication? So being able to talk to a system and it talk back to you, or is there some more fundamental problems to be solved? I think it's all of the above. The natural language processing is obviously important, but there are also more nerdy fundamental problems. Like if you take, you play chess? Of course, I'm Russian. I have to. You speak Russian? Yes, I speak Russian. Excellent, I didn't know. When did you learn Russian? I speak very bad Russian, I'm only an autodidact, but I bought a book, Teach Yourself Russian, read a lot, but it was very difficult. Wow. That's why I speak so bad. How many languages do you know? Wow, that's really impressive. I don't know, my wife has some calculation, but my point was, if you play chess, have you looked at the AlphaZero games? The actual games, no. Check it out, some of them are just mind blowing, really beautiful. And if you ask, how did it do that? You go talk to Demis Hassabis, I know others from DeepMind, all they'll ultimately be able to give you is big tables of numbers, matrices, that define the neural network. And you can stare at these tables of numbers till your face turn blue, and you're not gonna understand much about why it made that move. And even if you have natural language processing that can tell you in human language about, oh, five, seven, points, two, eight, still not gonna really help. So I think there's a whole spectrum of fun challenges that are involved in taking a computation that does intelligent things and transforming it into something equally good, equally intelligent, but that's more understandable. And I think that's really valuable because I think as we put machines in charge of ever more infrastructure in our world, the power grid, the trading on the stock market, weapon systems and so on, it's absolutely crucial that we can trust these AIs to do all we want. And trust really comes from understanding in a very fundamental way. And that's why I'm working on this, because I think the more, if we're gonna have some hope of ensuring that machines have adopted our goals and that they're gonna retain them, that kind of trust, I think, needs to be based on things you can actually understand, preferably even improve theorems on. Even with a self driving car, right? If someone just tells you it's been trained on tons of data and it never crashed, it's less reassuring than if someone actually has a proof. Maybe it's a computer verified proof, but still it says that under no circumstances is this car just gonna swerve into oncoming traffic. And that kind of information helps to build trust and helps build the alignment of goals, at least awareness that your goals, your values are aligned. And I think even in the very short term, if you look at how, you know, today, right? This absolutely pathetic state of cybersecurity that we have, where is it? Three billion Yahoo accounts we can't pack, almost every American's credit card and so on. Why is this happening? It's ultimately happening because we have software that nobody fully understood how it worked. That's why the bugs hadn't been found, right? And I think AI can be used very effectively for offense, for hacking, but it can also be used for defense. Hopefully automating verifiability and creating systems that are built in different ways so you can actually prove things about them. And it's important. So speaking of software that nobody understands how it works, of course, a bunch of people ask about your paper, about your thoughts of why does deep and cheap learning work so well? That's the paper. But what are your thoughts on deep learning? These kind of simplified models of our own brains have been able to do some successful perception work, pattern recognition work, and now with AlphaZero and so on, do some clever things. What are your thoughts about the promise limitations of this piece? Great, I think there are a number of very important insights, very important lessons we can always draw from these kinds of successes. One of them is when you look at the human brain, you see it's very complicated, 10th of 11 neurons, and there are all these different kinds of neurons and yada, yada, and there's been this long debate about whether the fact that we have dozens of different kinds is actually necessary for intelligence.",mit course artificial general intelligence get chance sit max tegmark professor mit physicist spend large career study mystery cosmological universe study delve beneficial possibility existential risk artificial intelligence thing cofounder future life institute author book highly recommend mathematical universe second life truly box thinker fun personality enjoy talk like video future subscribe click little bell icon sure miss video twitter linkedin wanna watch lecture conversation like well read max book life chapter seven goal favorite philosophy engineering come open quote dostoevsky mystery human existence lie stay alive find live lastly believe failure reward opportunity learn sense fortunate fail new exciting way conversation different learn call radio frequency interference rfi look apparently music conversation local radio station bleed audio record way completely ruin audio exceptionally difficult sound source remove get opportunity learn avoid rfi future recording session get opportunity learn use adobe audition izotope rx noise audio repair course exceptionally difficult noise remove engineer audio engineer anybody group good thank patience hope able enjoy conversation think intelligent life universe let open easy question minority view actually public lecture ask hand think intelligent life hand ask like oh galaxy get to number nerd right look carefully clear talk universe mean space actually mean know throw universe want simply mean spherical region space light time reach far billion year billion year big bang space universe access intelligent life get point building telescope computer guess actually probability happen give planet number know know number super high billion earth like planet milky way galaxy billion year old earth aside ufo believer evidence superduran civilization come famous fermi paradox right work number find clue probability get life give planet minus minus minus power sort equally likely wanna open minded translate equally likely near neighbor meter away meter away time pretty know close discover yeah discover long ago close probably note engineering project meter outside guess actually life get point build advanced tech think put lot responsibility shoulder screw think people grant okay screw accidental nuclear war extinct sort star trek like situation life form go to come bail matter think level false sense security think prudent let grateful amazing opportunity good case physics perspective think intelligent life unique sort statistical view size universe basic matter universe difficult intelligent life come kind advanced tech building life imply statement difficult create like human specie think know go life have life level tech sort go actually settle universe life major roadblock great filter call tough roadblock hope super excited time new report nasa say fail find life mars like yes awesome suggest hard maybe get ribosome low level kind step stone home free true future limit imagination sucki turn level life kind dime dozen maybe problem like soon civilization get advanced technology year stupid fight poof bummer yeah explore mystery universe cosmological universe sit today think begin explore universe sort mystery mysterious universe mind intelligence intelligent life common thread interest way think space intelligence oh yeah teenager fascinated big question feel big mystery science universe universe natural having spend quarter century career think lot indulge luxury research cool feel time ripe tran greatly deepen understanding start explore yeah think lot people view intelligence mysterious exist biological organism like dismiss talk artificial general intelligence science fiction perspective physicist blob quark electron move certain pattern processing information certain way blob quark electron smart water bottle different kind quark quark quark exact kind secret sauce think pattern information processing mean law physics say create technology help incredibly intelligent help crack mystery word think see tip intelligence iceberg far yeah perceptronium yeah coin amazing term hypothetical state matter sort think physics perspective kind matter help say subjective experience emerge consciousness emerge think consciousness physics perspective good question think people underestimate ability progress convince hopeless miss ingredient need new consciousness particle happen think miss interesting thing consciousness give amazing subjective experience color sound emotion high level pattern information processing like think idea perceptronium mean arbitrary physical system conscious term particle information think hate carbon chauvinism attitude carbon atom smart conscious information processing kind matter perform yeah favorite equation describe fundamental aspect world feel think day maybe watch come equation information processing satisfy conscious convinced big discovery let face know thing information know information processing conscious conscious know lot information processing conscious like information processing happen brain right conscious like megabyte second come visual system conscious heartbeat regulation thing ask like read say look oh know say aware computation actually happen consciousness like ceo get email end final answer make difference think great science mystery actually study little bit lab mit think urgent question answer starter mean emergency room doctor unresponsive patient come great addition have ct scanner consciousness scanner figure person actually having lock syndrome actually comatose future imagine build robot machine good conversation think likely happen want know home helper robot actually experience like zombie mean prefer prefer prefer actually unconscious feel guilty switch give boring chore prefer certainly prefer prefer appearance consciousness question appearance consciousness different consciousness sort ask question think need understand consciousness solve hard problem consciousness order build like agi system think think probably able build thing answer question want sure happen good thing well solve wonderful controversy raise basically point view hard problem different point view conclude hard problem consciousness bs hand people like daniel dennett consciousness bs consciousness thing intelligence difference act conscious conscious like lot people include ai researcher know oh consciousness bullshit course machine conscious go zombie feel guilty treat group people include giulio tononi example krzysztof koch number middle camp actually information processing conscious let find equation determine think little bit lazy kind run away problem long time taboo mention c word lot circle stop make excuse science question way test theory make prediction come helper robot mean say want helper robot certainly act conscious treat like conversation stuff think feel feel little bit creep realize glossed tape recorder know zombie fake emotion prefer actually experience prefer actually experience feel feel guilty difficult question know like relationship love person say love like ask love say love want actually love hard hard know difference like consciousness present intelligence present affection passion love actually sure like ask question like bit pointed mass general hospital right river right yes suppose go medical procedure like know anesthesia go go muscle relaxant will able go feel excruciate pain surgery will able go drug erase memory cool difference conscious behavioral change right right clear way yeah feel like sense experience valuable quality actually able subjective experience case valuable think human little bit bad track record make self serve argument entity conscious know people oh animal feel pain okay boil lobster ask hurt paper say lobster feel pain boil ban switzerland slave say oh mind maybe conscious woman soul little bit nervous hear people axiom machine experience think fascinating science question let research try figure make difference unconscious intelligent behavior conscious intelligent behavior term think boston dynamics human robot sort broom push start push consciousness question let ask think agi system like neuroscientist believe need physical embodiment need body like body think mean conscious experience consciousness think help lot physical embodiment learn kind thing world important human sure think physical embodiment necessary learn experience think dream right eye closed get sensory input behave move way experience right clearly experience cool dream come eye information process brain experience right way come neuroscience reason want body physical like physical know physical system want able preserve order self argue need kind embodiment self want preserve get little bit anthropomorphic anthropomorphizing thing maybe talk self preservation instinct mean evolve organism right darwinian evolution endow evolve organism self preservation instinct self preservation gene think convincingly answer question kind look hood alphazero kind neuron ridiculously simple mathematical thing like physics gas wave detailed nature molecule matter collective behavior similarly high level structure network matter kind neuron think brain complicated mess evolve intelligent involve self assembling self repair right evolutionarily attainable think pretty hunch go understand build agi fully understand brain work like understand build fly machine long able build mechanical bird yeah right give example exactly mechanical bird airplane airplane pretty good job fly mimic bird flight year later ted talk german mechanical bird hear mention check amazing right fly mechanical bird turn way come simple well purpose think lesson lesson paper physicist think fascinating close mathematical relationship actually artificial neural network lot thing study physics nerdy name like renormalization group equation hamiltonians yada yada yada look little closely like crazy sense know want build super simple neural network tell apart cat picture dog picture right think little bit convince impossible megapixel pixel black white power million possible image way atom universe right order assign number probability dog arbitrary function image list number atom universe clearly store hood gpu computer work mean mean problem try solve neural network impossible solve reasonably sized show paper fraction kind problem fraction problem possibly pose actually care give law physics infinite testimony tiny little amazingly basically yeah like world create mean kind come yeah maybe world create modest interpretation world create modest interpretation instead evolution endow neural network precisely reason particular architecture oppose laptop adapt solve kind problem nature keep present ancestor make sense brain place able prediction future sucky system solve world think beautiful fact yeah realize early work deep network good able additional cool fact incredibly simple problem like suppose thousand number ask multiply write line code boom trivial try neural network single hidden layer go need power thousand neuron multiply thousand number neuron atom universe fascinating allow deep network layer need neuron perfectly feasible interesting yeah architecture type mean mention schrodinger equation thought quantum computing role kind computational unit create intelligence system hollywood movie mention want spoil way agi build quantum computer word quantum sound cool right think need quantum computer build agi suspect brain quantum computer profound sense write paper lot year ago calculate call decoherence time long take quantum computerness neuron get erase random noise environment minus second cool quantum computer head think fast hand cool thing quantum computer think able soon big one actually help machine learning well brain example moonshot learning thing search try train neural network learn loss function bunch knob turn represent bunch number try tweak good possible thing think landscape valley dimension landscape correspond number change try find minimum know high dimensional landscape complicated thing super hard find minimum quantum mechanic amazingly good like want know low energy state water possibly incredibly hard compute nature happily figure cool cold ball roll minimum happen metaphorically energy landscape quantum mechanic use clever trick today machine learning system like try find minimum stick little local minimum quantum mechanic actually tunnel barrier unstuck interesting yeah example day use quantum computer help train neural network well interesting okay component kind learning process example yeah let ask sort wrap little bit let return question human nature love mention think mention sort helper robot think personal robot think way human being fall love connect possible achieve ai system human level ai intelligence system think kind connection know discussion solve complex goal kind human social connection think goal peak valley raise sea level able achieve think ultimately short term relative goal achievable think possible mean recent wide range guess know ai researcher go agi people know like friend rodney brooks say go hundred year think go happen soon recent poll maybe half ai researcher think go agi decade happen course think thing possible term happen think spend time ask think happen future sort pathetic passive bystander know wait future happen hey one create future right proactive ask sort future like happen go like prefer sort incredibly boring zombie like future mechanical thing happen passion emotion experience maybe course prefer thing find value humanity subjective experience passion inspiration love know create future thing happen thing exist know think ultimately universe give meaning give meaning universe build advanced intelligence let sure build way meaning lot people seriously study problem think different angle trouble majority case think happen one beneficial humanity yeah thought people know like people terrify way people think way solve well think panic go help way go increase chance thing go situation real threat help everybody freak course course think yeah course way thing horribly wrong important think thing problem risk remember huge upside right right love society civilization product intelligence amplify intelligence machine intelligence anymore lose love tell incurable disease thing like course aspire motivator think remind reason try solve problem try avoid gloom try great term risk think important question ask today actually help outcome good right dismiss risk find funny discussion panel thing people work company like oh worry worry worry academic express concern surprising think right upton sinclair quip right hard man believe income depend believe frankly know lot people company concerned ceo company want record say silly journalist go to picture terminator robot quote issue real way think issue basically real choice go to dismiss risk let ahead build machine well cheap let obsolete fast possible possibly wrong attitude opposite attitude think incredible potential let think kind future excited share goal aspire let think hard actually start start think risk start think goal think obstacle want avoid student come right office career advice ask question want future oh maybe cancer maybe run truck yeah focus obstacle instead goal go end hypochondriac paranoid come fire eye like want talk obstacle circumvent think healthy attitude feel challenging come vision future unequivocally excited talk vague term like yeah let cure cancer fine talk kind society want create want mean human age ai age agi conversation broad inclusive conversation gradually start converge future direction want steer right motivated constructively obstacle think try wrap succinct way think agree aspire build agi overpower empower think way world autonomous vehicle personally actually camp believe human level intelligence require achieve like vehicle actually enjoy example certainly lot type robot medicine focus come obstacle come way wrong solve time build autonomous vehicle build drive fine maybe thing life actually want right right like example think society thing find meaningful mean stop machine well go to stop play tennis day build tennis robot beat people play chess yeah near term people advocate basic income replace job government go to willing hand cash people seriously consider government hire lot teacher nurse kind job people find great fulfillment right tired hear politician say oh afford hire teacher go to maybe basic income research think give meaning life job income right mm hmm think future role wanna people continually feel empower machine think sort come russia soviet union think lot people century go moon go space inspiring thing feel like universe mind ai understanding create intelligence century surprising hear mention surprising research funding fund greatly importantly politician public discourse killer bots terminator kind view people think excite possible positive future build politician usually focus election cycle right single important thing feel human learn entire history science master underestimation underestimate size cosmo realize think exist small grander right planet solar system galaxy cluster galaxy universe know future potential ancestor dream cosmo imagine earth completely devoid life cambridge massachusetts kind lame aspire stay cambridge massachusetts forever extinct week earth go to continue long sort attitude think cosmic scale life flourish earth year billion year tell harm way sun get hot resource today maybe lot planet bacteria cow like life opportunity far tell largely dead like sahara desert opportunity help life flourish billion year let quit squabbling little border draw mile left right look sky realize hey incredible thing yeah think exciting connect work elon musk literally go space explore universe wonderful exactly elon musk misunderstood right misconstrue kind pessimistic doomsayer reason care ai safety appreciate amazing opportunity squander wipe earth go wipe generation generation incredible opportunity waste ai people think well technology let mention improve technology question humanity go extinct question go take big asteroid super volcano dumb easily prevent tech right want life flourish cosmo ai key mention lot detail book right inspire sci fi writer feel totally underestimate opportunity space travel especially galaxy think possibility agi make easy right yeah go view agi enable progress enable well life beautiful way strive max thank thank time today awesome thank thank great day get clean gene pool right build artificial general intelligence mind space design large specific subset mind evolve agi mind necessarily self preservation instinct necessarily individualistic like imagine afraid death know suppose minute airplane crash like shuck go to lose minute experience cloud backup dang know big deal copy experience mind easily like easily silicon base right maybe feel little bit like hive mind actually maybe think grant agi sort competitive alpha male instinct hand know interesting think people far course concern advanced ai instinct build want nice set argument go steve omohundro nick bostrom point build machine normally build kind goal know win chess game drive car safely soon goal machine especially kind open end goal machine intelligent break bunch sub goal goal self preservation break die process go to accomplish goal right like suppose build little little robot tell store market food cook italian dinner know mug try break way robot incentive destroy defend run away go to fail cook dinner afraid death want complete dinner cooking goal self preservation instinct continue functional agent similarly kind ambitious goal agi likely wanna acquire resource well exactly sort sub goal intend concern agi safety come goal completely harmless realize try thing want maybe smart fascinating let pause kind human centric way fear death valuable motivator think think artifact evolution kind mind space evolution create sort obsessed self preservation kind genetic flow think necessary afraid death kind sub goal self preservation thing fundamentally sort finite thing like end point interesting think necessary precisely intelligence consciousness think like finite death fear important answer agree necessary intelligence consciousness clear define word cause lot smart people define different way panel ai expert agree define intelligence define intelligence simply ability accomplish complex goal like broad definition want carbon chauvinist right case certainly require fear death alpha alpha zero intelligent think alpha zero fear turn understand concept similarly consciousness mean certainly imagine simple kind experience certain plant kind experience think afraid die value seriously think ask conscious maybe have exciting life feel passion appreciate thing maybe maybe help have backdrop hey finite let let live full know go live forever think change yeah mean perspective incredibly boring life live forever sort loose subjective term say exciting human understand think yeah finiteness important good news base understand cosmology universe probably ultimately probably finite big crunch big infinite expansion yeah big chill big crunch big rip big snap death bubble billion year away certainly vastly time ancestor think pretty hard squeeze infinite number compute cycle loophole possible think know people like live go die year sort optimal maybe good assumption build civilization finite safe right exactly mention define intelligence ability solve complex goal draw line try define human level intelligence superhuman level intelligence consciousness definition consciousness come definition think intelligence spectrum different kind goal goal good chess player good goal player good car driver good investor good poet et cetera intelligence nature measure number overall goodness people well people well right machine well narrow task like multiply large number fast memorize large database play chess playing soon drive car machine match human child general intelligence artificial general intelligence agi course course definition quest build machine old holy grail ai inception sixty happen course think go big transition history life earth necessarily wait big impact machine well knitting big change come exactly moment well big change come big change start well job take away demand human labor whopping change come well ai research right right timescale ai research limit human research development cycle year typically know long release software iphone google replace engineer equivalent piece software reason year principle fast timescale future progress ai science technology drive machine human simple point give right incredibly fun controversy intelligence explosion call singularity werner vinge call idea articulate good obviously way fifty alan turing think early ask exactly define human level intelligence yeah glib answer well cognitive task well human cognitive task interesting bar think go little bit low actually well ai programming general learning want well study well key word well kind spectrum complexity goal able accomplish way certainly clear definition human love like sea rise thing geographic nice way peak ocean level elevating solve problem kind pause take bunch question lot social network bunch people ask sort slightly different direction creativity thing peak human being flawed well mean have contradiction flawed way let sort start easy lot cool equation let ask favorite equation know like child like shirt equation master key quantum mechanic micro world equation protect atom molecule way right yeah okay quantum mechanic certainly beautiful mysterious formulation world like sort ask example beauty physics mathematic abstract andrew wiles prove fermat theorem see recently kind catch eye little bit year conjecture simple formulation everybody try prove everybody fail guy come eventually prove fail prove prove say like moment connect place interview say indescribably beautiful moment finally realize connect piece conjecture say indescribably beautiful simple elegant understand miss stare disbelief minute day walk department come desk look contain excited important moment work life mean particular moment kind think think small level maybe let ask moment like life idea like wow yes mention breath andrew wiles certainly number aha moment realize cool physic completely head explode fact favorite discovery later later realize discover early get famous late publish diminish way emotional experience realize like wow yeah moment wow moment think take intelligence system agi system ai system moment like tricky question actually part right accomplish proof prove write n plus b n equal equal z n integer et cetera et cetera n big simply question intelligence build machine intelligent think time machine independently come level proof probably close agi second question question consciousness likely machine actually experience oppose like zombie expect sort emotional response akin human emotion accomplish machine goal view positive sublime deeply meaningful certainly hope future create machine peer descendant certainly hope sublime appreciation life way absolutely bad nightmare point future distant future maybe cosmo teem post biological life seemingly cool stuff maybe human time specie eventually fizzle like ok proud descendant look bad nightmare solve consciousness problem realize zombie aware tape recorder kind experience thing play bench ultimate zombie apocalypse case being appreciate amazing picture role creativity people ask creativity think intelligence certainly story tell beginning book involve create movie make money lot money modern world music movie intelligent system want good necessarily mean creativity important complex goal sea rise creative human centric think creativity special relative intelligence hunch think creativity simply aspect intelligence careful human vanity tendency want soon machine try diminish oh real intelligence creative thing ask write definition actually mean creative mean andrew wiles example mean take unexpected leap like take multiply step straightforward cookbook like rule right maybe connection thing people think connect like think aspect intelligence actually important aspect maybe reason human tend well traditional computer come naturally neural network traditional logic gate base computer machine physically connection activate activate activate bing hunch build machine task hey hey realize want travel world instead month teach agi course like ok improvise stuff mind involve lot creativity yeah actually beautiful way think try grasp definition intelligence understand build human try find thing machine maybe creativity thing word use describe interesting way think need defensive think good come say special know contrary wise example history try pretend superior intelligent being lead pretty bad result right nazi germany say superior people today lot cruelty animal say superior feel pain slavery justify kind weak argument think actually ahead build artificial general intelligence thing well think try found self worth sort bogus claim superiority term intelligence think instead find calling meaning life experience meaningful experience people smart faculty meeting talk certainly realize oh boy old prize old prize old prize enjoy life enjoy talk people course contrary feel honored privileged interact intelligent being well lot stuff think reason approach intelligent machine interesting people think think go machine intelligent naturally think go beneficial type intelligence realize like peer nobel prize fun talk clever certain topic fun have drink example relate terrible thing presence people smart year old mean parent intelligent right work ok goal align goal think number key issue solve value align value alignment problem exactly people hollywood movie lousy science fiction plot line worry wrong thing right worry machine suddenly turn evil malice concern competence definition intelligent make competent intelligent goal playing computer playing intelligent define intelligence ability accomplish goal win go intelligent win human agi intelligent way different goal guess go way right read particular rhinoceros specie drive extinct year ago ellen bummer look cute picture mommy rhinoceros child human drive extinction evil rhino hater goal align rhinoceros work rhinocero intelligent right think important build agi unleash sure learn understand goal adopt goal retain goal cool interesting problem human being try formulate value think united states constitution way people sit time bunch white man good example formulate goal country lot people agree goal actually hold pretty interesting formulation value fail miserably way value alignment problem solution able paper program human value difficult think important good difficult separate reason technical value alignment problem figure machine understand goal adopt retain separate philosophical value like great consensus planet value mechanism create aggregate decide ok good compromise second discussion leave tech nerd like refuse talk agi get build go actually make decision value go bunch dude tech company necessarily representative humankind want entrust uniquely qualified speak future human happiness good programming ai inclusive conversation think possible create beautiful vision include diversity cultural diversity perspective discuss right freedom human dignity hard come consensus think certainly important thing try think feasible think well way guarantee failure refuse talk refuse try think bad strategy ok let discussion long time reach complete consensus try load machine let perfect enemy good instead start kindergarten ethic pretty everybody agree machine look build passenger aircraft want circumstance fly building mountain september hijacker able embarrassingly andreas lubitz depressed germanwing pilot fly passenger jet alps kill people tell autopilot tell freaking computer change altitude meter gps map computer like ok basic value problem agree problem lazy try machine sure airplane computer refuse like safe mode maybe lock cockpit door near airport technology world timely sort basic value like car vehicle terrorism attack people drive truck van pedestrian crazy idea hardwire car yeah lot go people reason want harm people technical expertise figure work like car will help let start lot great point chase perfect lot thing world agree yeah let start let start start habit have kind conversation okay discussion gradual process great mean describe thing describe machine thing conversation stephen wolfram sure familiar stephen oh yeah know work bunch thing cellular automata simple computable thing computation system kind mention probably system agi mean like know talk chance try form question think interesting idea think intelligent system know describe communicate know little bit work explainable ai try ai explain thought natural language processing kind communication ai explain explain machine think differently separate part question communication super interesting sec agi notice right beg differ think cellular automaton internet artificial general intelligence exactly human well think day happen happen soon notice probably notice big way second wait ask sorry beautiful way formulate consciousness information processing think intelligence information processing think entire universe particle system roam information processing power think power process information way human being need sort connect little bit philosophical compelling idea power focus able communicate agree certain sense hardware processing power universe think computer right constantly compute water wave devolve water wave river charles air molecule seth lloyd point colleague rigorous way think entire universe quantum computer pretty clear universe support amazing processing power physics computer live right build actual laptop stuff clearly power compute power nature opinion kind waste boring stuff like simulate ocean wave look right sense life build computer rechannele compute nature thing interesting ocean wave let cool raw hardware power sure compute go happen second water bottle take ridiculous compute human computer water bottle mean water bottle agi agi mean able like write book interview think communication problem think buddhist watch water beauty depth beauty nature communicate communication important mean look job teacher know intelligent professor bit hard time communicate come brilliant idea communicate somebody able simulate mind yes empathy build understand model mind thing understand difficult today frustrating computer make cancer diagnosis ask say surgery reply train terabyte datum diagnosis boop boop beep beep instill lot confidence right think lot work communication kind think little bit work explainable ai think promising avenue sort alexa problem natural language processing able actually use human interpretable method communication able talk system talk fundamental problem solve think natural language processing obviously important nerdy fundamental problem like play chess course russian speak russian yes speak russian excellent know learn russian speak bad russian autodidact buy book teach russian read lot difficult wow speak bad language know wow impressive know wife calculation point play chess look alphazero game actual game check mind blow beautiful ask talk demis hassabis know deepmind ultimately able big table number matrix define neural network stare table number till face turn blue go to understand natural language processing tell human language oh seven point go to help think spectrum fun challenge involve take computation intelligent thing transform equally good equally intelligent understandable think valuable think machine charge infrastructure world power grid trading stock market weapon system absolutely crucial trust ai want trust come understanding fundamental way work think go to hope ensure machine adopt goal go to retain kind trust think need base thing actually understand preferably improve theorem self driving car right tell train ton datum crash reassuring actually proof maybe computer verify proof say circumstance car go to swerve oncoming traffic kind information help build trust help build alignment goal awareness goal value align think short term look know today right absolutely pathetic state cybersecurity billion yahoo account pack american credit card happen ultimately happen software fully understand work bug find right think ai effectively offense hacking defense hopefully automate verifiability create system build different way actually prove thing important speak software understand work course bunch people ask paper thought deep cheap learning work paper thought deep learning kind simplified model brain able successful perception work pattern recognition work alphazero clever thing thought promise limitation piece great think number important insight important lesson draw kind success look human brain complicated neuron different kind neuron yada yada long debate fact dozen different kind actually necessary intelligence,"['Max Tegmark', 'Daniel Dennett', 'Giulio Tononi', 'Krzysztof Koch', 'Rodney Brooks', 'Elon Musk', 'Steve Omohundro', 'Nick Bostrom', 'Werner Vinge', 'I.J. Good', 'Alan Turing', 'Andrew Wiles', 'Ellen Bummer', 'Andreas Lubitz', 'Stephen Wolfram', 'Seth Lloyd', 'Yourself Russian', 'Demis Hassabis']","['MIT', 'Future of Humanity Institute', 'OpenAI']","['Deep Neural Networks', 'Quantum Computing', 'Brain-Computer Interfaces']","['Artificial General Intelligence (AGI)', 'AI Safety and Ethics', 'Future of Technology', 'Consciousness and AI', 'Philosophy of Mind and AI']"
2,Christof Koch,Consciousness,"As part of MIT course 6S099 on artificial general intelligence, I got a chance to sit down with Christoph Koch, who is one of the seminal figures in neurobiology, neuroscience, and generally in the study of consciousness. He is the president, the chief scientific officer of the Allen Institute for Brain Science in Seattle. From 1986 to 2013, he was a professor at Caltech. Before that, he was at MIT, he is extremely well cited, over 100,000 citations. His research, his writing, his ideas have had big impact on the scientific community and the general public in the way we think about consciousness, in the way we see ourselves as human beings. He's the author of several books, The Quest for Consciousness and Neurobiological Approach, and a more recent book, Consciousness, Confessions of a Romantic Reductionist. If you enjoy this conversation, this course, subscribe, click the little bell icon to make sure you never miss a video, and in the comments, leave suggestions for any people you'd like to see be part of the course or any ideas that you would like us to explore. Thanks very much and I hope you enjoy. Okay, before we delve into the beautiful mysteries of consciousness, let's zoom out a little bit and let me ask, do you think there's intelligent life out there in the universe? Yes, I do believe so. We have no evidence of it, but I think the probabilities are overwhelming in favor of it. Given a universe where we have 10 to the 11 galaxies and each galaxy has between 10 to the 11, 10 to the 12 stars and we know most stars have one or more planets. So how does that make you feel? It still makes me feel special because I have experiences. I feel the world, I experience the world and independent of whether there are other creatures out there, I still feel the world and I have access to this world in this very strange compelling way and that's the core of human existence. Now, you said human, do you think if those intelligent creatures are out there, do you think they experience their world? Yes, if they are evolved, if they are a product of natural evolution as they would have to be, they will also experience their own world. The consciousness isn't just human, you're right, it's much wider. It may be spread across all of biology. The only thing that we have special is we can talk about it. Of course, not all people can talk about it. Babies and little children can talk about it. Patients who have a stroke in the left inferior frontal gyrus can talk about it, but most normal adult people can talk about it and so we think that makes us special compared to let's say monkeys or dogs or cats or mice or all the other creatures that we share the planet with, but all the evidence seems to suggest that they too experience the world and so it's overwhelmingly likely that aliens would also experience their world. Of course, differently because they have a different sensorium, they have different sensors, they have a very different environment, but the fact that I would strongly suppose that they also have experiences. They feel pain and pleasure and see in some sort of spectrum and hear and have all the other senses. Of course, their language, if they have one, would be different so we might not be able to understand their poetry about the experiences that they have. That's correct. So in a talk, in a video, I've heard you mention Siputzo, a dachshund that you came up with, that you grew up with, it was part of your family when you were young. First of all, you're technically a Midwestern boy. You just – Technically. Yes. But after that, you traveled around a bit, hence a little bit of the accent. You talked about Siputzo, the dachshund, having these elements of humanness, of consciousness that you discovered. So I just wanted to ask, can you look back in your childhood and remember when was the first time you realized you yourself, sort of from a third person perspective, are a conscious being? This idea of stepping outside yourself and seeing there's something special going on here in my brain. I can't really actually – it's a good question. I'm not sure I recall a discrete moment. I mean, you take it for granted because that's the only world you know. The only world I know and you know is the world of seeing and hearing voices and touching and all the other things. So it's only much later at early – in my underguided days when I enrolled in physics and in philosophy that I really thought about it and thought, well, this is really fundamentally very, very mysterious and there's nothing really in physics right now that explains this transition from the physics of the brain to feelings. Where do the feelings come in? So you can look at the foundational equation of quantum mechanics, general relativity. You can look at the periodic table of the elements. You can look at the endless ATGC chat in our genes and nowhere is consciousness. Yet I wake up every morning to a world where I have experiences. And so that's the heart of the ancient mind body problem. How do experiences get into the world? So what is consciousness? Experience. This is any experience. Some people call it subjective feeling. Some people call it phenomenology. Some people call it qualia of the philosopher. But they all denote the same thing. It feels like something in the famous word of the philosopher Thomas Nagel. It feels like something to be a bat or to be an American or to be angry or to be sad or to be in love or to have pain. And that is what experience is, any possible experience. Could be as mundane as just sitting in a chair. Could be as exalted as having a mystical moment in deep meditation. Those are just different forms of experiences. Experience. So if you were to sit down with maybe the next, skip a couple generations, of IBM Watson, something that won Jeopardy, what is the gap, I guess the question is, between Watson, that might be much smarter than you, than us, than any human alive, but may not have experience, what is the gap? Well, so that's a big, big question. That's occupied people for the last, certainly last 50 years since we, you know, since the advent, the birth of computers. That's a question Alan Turing tried to answer. And of course he did it in this indirect way by proposing a test, an operational test. But that's not really, that's, you know, he tried to get at what does it mean for a person to think, and then he had this test, right? You lock them away, and then you have a communication with them, and then you try to guess after a while whether that is a person or whether it's a computer system. There's no question that now or very soon, you know, Alexa or Siri or, you know, Google now will pass this test, right? And you can game it, but you know, ultimately, certainly in your generation, there will be machines that will speak with complete poise that will remember everything you ever said. They'll remember every email you ever had, like Samantha, remember in the movie Her? Yeah. There's no question it's going to happen. But of course, the key question is, does it feel like anything to be Samantha in the movie Her? Or does it feel like anything to be Watson? And there one has to very, very strongly think there are two different concepts here that we co mingle. There is the concept of intelligence, natural or artificial, and there is a concept of consciousness, of experience, natural or artificial. Those are very, very different things. Now, historically, we associate consciousness with intelligence. Why? Because we live in a world, leaving aside computers, of natural selection, where we're surrounded by creatures, either our own kin that are less or more intelligent, or we go across species. Some are more adapted to a particular environment. Others are less adapted, whether it's a whale or dog, or you go talk about a paramecium or a little worm. And we see the complexity of the nervous system goes from one cell to specialized cells, to a worm that has three nets, that has 30 percent of its cells are nerve cells, to creature like us or like a blue whale that has 100 billion, even more nerve cells. And so based on behavioral evidence and based on the underlying neuroscience, we believe that as these creatures become more complex, they are better adapted to their particular ecological niche, and they become more conscious, partly because their brain grows. And we believe consciousness, unlike the ancient, ancient people thought most, almost every culture thought that consciousness with intelligence has to do with your heart. And you still see that today. You see, honey, I love you with all my heart. But what you should actually say is, no, honey, I love you with all my lateral hypothalamus. And for Valentine's Day, you should give your sweetheart, you know, hypothalamus, a piece of chocolate and not a heart shaped chocolate. Anyway, so we still have this language, but now we believe it's a brain. And so we see brains of different complexity and we think, well, they have different levels of consciousness. They're capable of different experiences. But now we confront the world where we know where we're beginning to engineer intelligence. And it's radical unclear whether the intelligence we're engineering has anything to do with consciousness and whether it can experience anything. Because fundamentally, what's the difference? Intelligence is about function. Intelligence no matter exactly how you define it, sort of adaptation to new environments, being able to learn and quickly understand, you know, the setup of this and what's going on and who are the actors and what's going to happen next. That's all about function. Consciousness is not about function. Consciousness is about being. It's in some sense much fundamental. You can see this in several cases. You can see it, for instance, in the case of the clinic. When you're dealing with patients who are, let's say, had a stroke or had were in traffic accident, et cetera, they're pretty much immobile. Terri Schiavo, you may have heard historically, she was a person here in the 90s in Florida. Her heart stood still. She was reanimated. And then for the next 14 years, she was what's called in a vegetative state. So there are thousands of people in a vegetative state. So they're, you know, they're, you know, they're like this. Occasionally, they open their eyes for two, three, four, five, six, eight hours, and then close their eyes. They have sleep wake cycle. Occasionally, they have behaviors. They do like, you know, but there's no way that you can establish a lawful relationship between what you say or the doctor says or the mom says and what the patient does. So there isn't any behavior, yet in some of these people, there is still experience. You can design and build brain machine interfaces where you can see there's still experience something. And of course, these cases of locked in state, there's this famous book called The Diving Bell and the Butterfly, where you had an editor, a French editor, he had a stroke in the brainstem, unable to move except his vertical eyes, eye movement. He could just move his eyes up and down. And he dictated an entire book. And some people even lose this at the end. All the evidence seems to suggest that they're still in there. In this case, you have no behavior, you have consciousness. Second case is tonight, like all of us, you're going to go to sleep, close your eyes, you go to sleep, you will wake up inside your sleeping body, and you will have conscious experiences. They are different from everyday experience. You might fly, you might not be surprised that you're flying, you might meet a long dead pet, childhood dog, and you're not surprised that you're meeting them. But you have conscious experience of love, of hate, they can be very emotional. Your body during this state, typically it's REM state, sends an active signal to your motor neurons to paralyze you. It's called atonia. Because if you don't have that, like some patients, what do you do? You act out your dreams. You get, for example, REM behavioral disorder, which is bad juju to get. Okay. Third case is pure experience. So I recently had this, what some people call a mystical experience. I went to Singapore and went into a flotation tank. Yeah. All right. So this is a big tub filled with water, that's body temperature and Epsom salt. You strip completely naked, you lie inside of it, you close the lid. Darkness. Complete darkness, soundproof. So very quickly, you become bodiless because you're floating and you're naked. You have no rings, no watch, no nothing. You don't feel your body anymore. There's no sound, soundless. There's no photon, sightless, timeless, because after a while, early on you actually hear your heart, but then you sort of adapt to that and then sort of the passage of time ceases. Yeah. And if you train yourself, like in a meditation, not to think, early on you think a lot. It's a little bit spooky. You feel somewhat uncomfortable or you think, well, I'm going to get bored. And if you try to not to think actively, you become mindless. There you are, bodiless, timeless, you know, soundless, sightless, mindless, but you're in a conscious experience. You're not asleep. Yeah. You're not asleep. You are a being of pure, you're a pure being. There isn't any function. You aren't doing any computation. You're not remembering. You're not projecting. You're not planning. Yet you are fully conscious. You're fully conscious. There's something going on there. It could be just a side effect. So what is the... You mean epiphenomena. So what's the select, meaning why, what is the function of you being able to lay in this sensory free deprivation tank and still have a conscious experience? Evolutionary? Evolutionary. Obviously we didn't evolve with flotation tanks in our environment. I mean, so biology is notoriously bad at asking why question, telenormical question. Why do we have two eyes? Why don't we have four eyes like some teachers or three eyes or something? Well, no, there's probably, there is a function to that, but we're not very good at answering those questions. We can speculate endlessly where biology is very, or science is very good about mechanistic question. Why is there a charge in the universe? Right? We find a certain universe where there are positive and negative charges. Why? Why does quantum mechanics hold? You know, why doesn't some other theory hold? Quantum mechanics holding our universe is very unclear why. So telenormical question, why questions are difficult to answer. There's some relationship between complexity, brain processing power and consciousness. But however, in these cases, in these three examples I gave, one is an everyday experience at night. The other one is trauma. And third one is in principle, you can, everybody can have these sort of mystical experiences. You have a dissociation of function from, of intelligence from consciousness. You caught me asking a why question. Let me ask a question that's not a why question. You're giving a talk later today on the Turing test for intelligence and consciousness, drawing lines between the two. So is there a scientific way to say there's consciousness present in this entity or not? And to anticipate your answer, cause you, you will also, there's a neurobiological answer. So we can test the human brain, but if you take a machine brain that you don't know tests for yet, how would you even begin to approach a test if there's consciousness present in this thing? Okay. That's a really good question. So let me take it in two steps. So as you point out for, for, for, for humans, let's just stick with humans. There's now a test called the Zap and Zip is a procedure where you ping the brain using transcranial magnetic stimulation. You look at the electrical reverberations essentially using EG, and then you can measure the complexity of this brain response. And you can do this in awake people, in asleep, normal people, you can do it in awake people and then anesthetize them. You can do it in patients. And it, it, it has a hundred percent accuracy that in all those cases, when you're clear, the patient or the person is either conscious or unconscious, the complexity is either high or low. And then you can adopt these techniques to similar creatures like monkeys and dogs and, and, and mice that have very similar brains. Now of course you, you point out that may not help you because we don't have a cortex, you know, and if I send a magnetic pulse into my iPhone or my computer, it's probably going to break something. So we don't have that. So what we need ultimately, we need a theory of consciousness. We can't just rely on our intuition. Our intuition is, well, yeah, if somebody talks, they're conscious. However, then there are all these patients, children, babies don't talk, right? But we believe that, that the babies also have conscious experiences, right? And then there are all these patients I mentioned and they don't talk. When you dream, you can't talk because you're paralyzed. So what we ultimately need, we can't just rely on our intuition. We need a theory of conscience that tells us what is it about a piece of matter? What is it about a piece of highly excitable matter like the brain or like a computer that gives rise to conscious experience? We all believe, none of us believes anymore in the old story. It's a soul, right? That used to be the most common explanation that most people accept that instill a lot of people today believe, well, there's, there's God endowed only us with a special thing that animals don't have. Rene Descartes famously said, a dog, if you hit it with your carriage may yell, may cry, but it doesn't have this special thing. It doesn't have the magic, the magic soul. It doesn't have res cogitans, the soul. Now we believe that isn't the case anymore. So what is the difference between brains and, and these guys, silicon? And in particular, once their behavior matches. So if you have Siri or Alexa in 20 years from now that she can talk just as good as any possible human, what grounds do you have to say she's not conscious in particular, if she says it's of course she will, well, of course I'm conscious. You ask her how are you doing? And she'll say, well, you know, they, they'll generate some way to, of course she'll behave like a, like a person. Now there's several differences. One is, so this relates to the problem, the very hard, why is consciousness a hard problem? It's because it's subjective, right? Only I have it, for only I know I have direct experience of my own consciousness. I don't have experience in your consciousness. Now I assume as a sort of a Bayesian person who believes in probability theory and all of that, you know, I can do, I can do an abduction to the, to the best available facts. I deduce your brain is very similar to mine. If I put you in a scanner, your brain is roughly going to behave the same way as I do. If, if, if, you know, if I give you this muesli and ask you, how does it taste? You tell me things that, you know, that, that I would also say more or less, right? So I infer based on all of that, that you're conscious. Now with theory, I can't do that. So there I really need a theory that tells me what is it about, about any system, this or this, that makes it conscious. We have such a theory. Yes. So the integrated information theory, but let me first, maybe as an introduction for people who are not familiar, Descartes, can you, you talk a lot about pan, panpsychism. Can you describe what, uh, physicalism versus dualism? This you, you mentioned the soul, what, what is the history of that idea? What is the idea of panpsychism or no, the debate really, uh, out of which panpsychism can, um, emerge of, of, of, um, dualism versus, uh, physicalism or do you not see panpsychism as fitting into that? No, you can argue there's some, okay, so let's step back. So panpsychism is a very ancient belief that's been around, uh, I mean, Plato and Aristotle talks about it, uh, modern philosophers talk about it. Of course, in Buddhism, the idea is very prevalent that, I mean, there are different versions of it. One version says everything is ensouled, everything, rocks and stones and dogs and people and forest and iPhones, all of us all, right? All matter is ensouled. That's sort of one version. Another version is that all biology, all creatures, small or large, from a single cell to a giant sequoia tree feel like something. This one I think is somewhat more realistic. Um, so the different versions, what do you mean by feel like something, have, have feelings, have some kind of, it feels like something, it may well be possible that it feels like something to be a paramecium. I think it's pretty likely it feels like something to be a bee or a mouse or a dog. Sure. So, okay. So, so that you can see that's also, so panpsychism is very broad and you can, so some people, for example, Bertrand Russell, tried to advocate this, this idea, it's called Rasselian Monism, that that panpsychism is really physics viewed from the inside. So the idea is that physics is very good at describing relationship among objects like charges or like gravity, right? You know, describe the relationship between curvature and mass distribution, okay? That's the relationship among things. Physics doesn't really describe the ultimate reality itself. It's just relationship among, you know, quarks or all these other stuff from like a third person observer. Yes. Yes. Yes. And consciousness is what physics feels from the inside. So my conscious experience, it's the way the physics of my brain, particularly my cortex feels from the inside. And so if you are paramecium, you got to remember, you say paramecium, well, that's a pretty dumb creature. It is, but it has already a billion different molecules, probably, you know, 5,000 different proteins assembled in a highly, highly complex system that no single person, no computer system so far on this planet has ever managed to accurately simulate. Its complexity vastly escapes us. Yes. And it may well be that that little thing feels like a tiny bit. Now, it doesn't have a voice in the head like me. It doesn't have expectations. You know, it doesn't have all that complex things, but it may well feel like something. Yeah. So this is really interesting. Can we draw some lines and maybe try to understand the difference between life, intelligence and consciousness? How do you see all of those? If you had to define what is a living thing, what is a conscious thing and what is an intelligent thing? Do those intermix for you or are they totally separate? Okay. So A, that's a question that we don't have a full answer to. A lot of the stuff we're talking about today is full of mysteries and fascinating ones, right? For example, you can go to Aristotle, who's probably the most important scientist and philosopher who's ever lived in, certainly in Western culture. He had this idea, it's called hylomorphism. It's quite popular these days, that there are different forms of soul. The soul is really the form of something. He says, all biological creatures have a vegetative soul. That's life principle. Today, we think we understand something more than it is biochemistry and nonlinear thermodynamics. Then he said they have a sensitive soul. Only animals and humans have also a sensitive soul or a petitive soul. They can see, they can smell, and they have drives. They want to reproduce, they want to eat, et cetera. And then only humans have what he called a rational soul, okay? And that idea then made it into Christendom and then the rational soul is the one that lives forever. He was very unclear. He wasn't really, I mean, different readings of Aristotle give different, whether did he believe that rational soul was immortal or not. I probably think he didn't. But then, of course, that made it through Plato into Christianity, and then this soul became immortal and then became the connection to God. So you ask me, essentially, what is our modern conception of these three, Aristotle would have called them different forms. Life, we think we know something about it, at least life on this planet, right? Although we don't understand how to originate it, but it's been difficult to rigorously pin down. You see this in modern definitions of death. In fact, right now, there's a conference ongoing, again, that tries to define legally and medically what is death. It used to be very simple. Death is you stop breathing, your heart stops beating, you're dead, totally uncontroversial. If you're unsure, you wait another 10 minutes. If the patient doesn't breathe, he's dead. Well, now we have ventilators, we have heart pacemakers, so it's much more difficult to define what death is. Typically, death is defined as the end of life and life is defined before death. Okay, so we don't have really very good definitions. Intelligence, we don't have a rigorous definition. We know something how to measure, it's called IQ or G factors, right? And we're beginning to build it in a narrow sense, right? Like go, AlphaGo and Watson and, you know, Google cars and Uber cars and all of that, it's still narrow AI and some people are thinking about artificial general intelligence. But roughly, as we said before, it's something to do with ability to learn and to adapt to new environments. But that is, as I said, also, it's radical difference from experience. And it's very unclear if you build a machine that has AGI, it's not at all a priori, it's not at all clear that this machine will have consciousness, it may or may not. So let's ask it the other way, do you think if you were to try to build an artificial general intelligence system, do you think figuring out how to build artificial consciousness would help you get to an AGI? So or put another way, do you think intelligent requires consciousness? In human, it goes hand in hand. In human, or I think in biology, consciousness, intelligence goes hand in hand, quay is illusion because the brain evolved to be highly complex, complexity via the theory integrated information theory is sort of ultimately is what is closely tied to consciousness. Ultimately it's causal power upon itself. And so in evolved systems, they go together. In artificial system, particularly in digital machines, they do not go together. And if you ask me point blank, is Alexa 20.0 in the year 2040, when she can easily pass every Turing test, is she conscious? No, even if she claims she's conscious. In fact, you could even do a more radical version of this thought experiment. You can build a computer simulation of the human brain. You know what Henry Markham in the Blue Brain Project or the Human Brain Project in Switzerland is trying to do. Let's grant them all the success. So in 10 years, we have this perfect simulation of the human brain. Every neuron is simulated and it has a larynx and it has motor neurons. It has a Broca's area and of course they'll talk and they'll say, hi, I just woke up. I feel great. OK, even that computer simulation that can in principle map onto your brain will not be conscious. Why? Because it simulates, it's a difference between the simulated and the real. So it simulates the behavior associated with consciousness. It might be, it will, if it's done properly, will have all the intelligence that that particular person they're simulating has. But simulating intelligence is not the same as having conscious experiences. And I give you a really nice metaphor that engineers and physicists typically get. I can write down Einstein's field equation, nine or ten equations that describe the link in general relativity between curvature and mass. I can do that. I can run this on my laptop to predict that the central, the black hole at the center of our galaxy will be so massive that it will twist space time around it so no light can escape. It's a black hole. But funny, have you ever wondered why doesn't this computer simulation suck me in? It simulates gravity, but it doesn't have the causal power of gravity. That's a huge difference. So it's a difference between the real and the simulator, just like it doesn't get wet inside a computer when the computer runs code that simulates a weather storm. And so in order to have, to have artificial consciousness, you have to give it the same causal power as the human brain. You have to build so called a neuromorphic machine that has hardware that is very similar to the human brain, not a digital clocked phenomenon computer. So that's, just to clarify though, you think that consciousness is not required to create human level intelligence. It seems to accompany in the human brain, but for machine not. That's correct. So maybe just because this is AGI, let's dig in a little bit about what we mean by intelligence. So one thing is the G factor, these kind of IQ tests of intelligence. But I think if you, maybe another way to say, so in 2040, 2050, people will have Siri that is just really impressive. Do you think people will say Siri is intelligent? Yes. Intelligence is this amorphous thing. So to be intelligent, it seems like you have to have some kind of connections with other human beings in a sense that you have to impress them with your intelligence. And there feels, you have to somehow operate in this world full of humans. And for that, there feels like there has to be something like consciousness. So you think you can have just the world's best natural NLP system, natural language understanding generation, and that will be, that will get us happy and say, you know what, we've created an AGI. I don't know happy, but yes, I do believe we can get what we call high level functional intelligence, particular sort of the G, you know, this fluid like intelligence that we cherish, particularly at a place like MIT, right, in machines. I see a priori no reasons, and I see a lot of reason to believe it's going to happen very, you know, over the next 50 years or 30 years. So for beneficial AI, for creating an AI system that's, so you mentioned ethics, that is exceptionally intelligent but also does not do, does, you know, aligns its values with our values as humanity. Do you think then it needs consciousness? Yes, I think that that is a very good argument that if we're concerned about AI and the threat of AI, a la Nick Bostrom, existentialist threat, I think having an intelligence that has empathy, right, why do we find abusing a dog, why do most of us find that abhorrent, abusing any animal, right? Why do we find that abhorrent because we have this thing called empathy, which if you look at the Greek really means feeling with, I feel a path of empathy, I have feeling with you. I see somebody else suffer that isn't even my conspecific, it's not a person, it's not my wife or my kids, it's a dog, but I feel naturally most of us, not all of us, most of us will feel emphatic. And so it may well be in the long term interest of survival of homo sapiens sapiens that if we do build AGI and it really becomes very powerful that it has an emphatic response and doesn't just exterminate humanity. So as part of the full conscious experience to create a consciousness, artificial or in our human consciousness, do you think fear, maybe we're going to get into the earlier days with Nietzsche and so on, but do you think fear and suffering are essential to have consciousness? Do you have to have the full range of experience to have a system that has experience or can you have a system that only has very particular kinds of very positive experiences? Look you can have in principle, people have done this in the rat where you implant an electrode in the hypothalamus, the pleasure center of the rat and the rat stimulates itself above and beyond anything else. It doesn't care about food or natural sex or drink anymore, it just stimulates itself because it's such a pleasurable feeling. I guess it's like an orgasm just you have all day long. And so a priori I see no reason why you need a great variety. Now clearly to survive that wouldn't work, right? But if I'd engineered artificially, I don't think you need a great variety of conscious experience. You could have just pleasure or just fear. It might be a terrible existence, but I think that's possible at least on conceptual logical ground. Because any real creature whether artificially engineered, you want to give it fear, the fear of extinction that we all have. And you also want to give it positive repetitive states, states that you want the machine encouraged to do because they give the machine positive feedback. So you mentioned panpsychism, to jump back a little bit, everything having some kind of mental property. How do you go from there to something like human consciousness? So everything having some elements of consciousness, is there something special about human consciousness? So it's not everything. Like a spoon, the form of panpsychism I think about doesn't ascribe consciousness to anything like this, the spoon on my liver. However, the theory, the integrated information theory does say that the system, even one that looks from the outside relatively simple, at least if they have this internal causal power, it does feel like something. The theory a priori doesn't say anything what's special about human. Biologically we know the one thing that's special about human is we speak and we have an overblown sense of our own importance. We believe we're exceptional and we're just God's gift to the universe. But behaviorally the main thing that we have, we can plan over the long term, we have language and that gives us an enormous amount of power and that's why we are the current dominant species on the planet. So you mentioned God, you grew up a devout Roman Catholic family, so with consciousness you're sort of exploring some really deeply fundamental human things that religion also touches on. Where does religion fit into your thinking about consciousness? You've grown throughout your life and changed your views on religion as far as I understand. Yeah, I mean I'm now much closer to, I'm not a Roman Catholic anymore, I don't believe there's sort of this God, the God I was educated to believe in, sits somewhere in the fullness of time, I'll be united in some sort of everlasting bliss, I just don't see any evidence for that. Look, the world, the night is large and full of wonders, there are many things that I don't understand, I think many things that we as a cult, look we don't even understand more than 4% of all the universe, dark matter, dark energy, we have no idea what it is, maybe it's lost socks, what do I know? So all I can tell you is it's sort of my current religious or spiritual sentiment is much closer to some form of Buddhism, without the reincarnation unfortunately, there's no evidence for it than reincarnation. So can you describe the way Buddhism sees the world a little bit? Well so they talk about, so when I spent several meetings with the Dalai Lama and what always impressed me about him, he really, unlike for example let's say the Pope or some Cardinal, he always emphasized minimizing the suffering of all creatures. So they have this, from the early beginning they look at suffering in all creatures, not just in people, but in everybody, this universal and of course by degrees, an animal in general is less capable of suffering than a well developed, normally developed human and they think consciousness pervades in this universe and they have these techniques, you can think of them like mindfulness etc. and meditation that tries to access what they claim of this more fundamental aspect of reality. I'm not sure it's more fundamental, I think about it, there's the physical and then there's this inside view, consciousness and those are the two aspects that's the only thing I have access to in my life and you've got to remember my conscious experience and your conscious experience comes prior to anything you know about physics, comes prior to knowledge about the universe and atoms and super strings and molecules and all of that. The only thing you directly are acquainted with is this world that's populated with things in images and sounds in your head and touches and all of that. I actually have a question, so it sounds like you kind of have a rich life, you talk about rock climbing and it seems like you really love literature and consciousness is all about experiencing things, so do you think that has helped your research on this topic? Yes, particularly if you think about it, the various states, so for example when you do rock climbing or now I do rowing, crew rowing and a bike every day, you can get into this thing called the zone and I've always wanted about it, particularly with respect to consciousness because it's a strangely addictive state. Once people have it once, they want to keep on going back to it and you wonder what is it so addicting about it and I think it's the experience of almost close to pure experience because in this zone, you're not conscious of inner voice anymore, there's always inner voice nagging you, you have to do this, you have to do that, you have to pay your taxes, you have to fight with your ex and all of those things, they're always there. But when you're in the zone, all of that is gone and you're just in this wonderful state where you're fully out in the world, you're climbing or you're rowing or biking or doing soccer or whatever you're doing and sort of consciousness is this, you're all action or in this case of pure experience, you're not action at all but in both cases, you experience some aspect of conscious, you touch some basic part of conscious existence that is so basic and so deeply satisfying. You I think you touch the root of being, that's really what you're touching there, you're getting close to the root of being and that's very different from intelligence. So what do you think about the simulation hypothesis, simulation theory, the idea that we all live in a computer simulation? Rapture for nerds. Rapture for nerds. I think it's as likely as the hypothesis had engaged hundreds of scholars for many centuries, are we all just existing in the mind of God? And this is just a modern version of it, it's equally plausible. People love talking about these sort of things, I know they're book written about this simulation hypothesis, if that's what people want to do, that's fine, it seems rather esoteric, it's never testable. But it's not useful for you to think of in those terms, so maybe connecting to the questions of free will which you've talked about, I vaguely remember you saying that the idea that there's no free will, it makes you very uncomfortable. So what do you think about free will from a physics perspective, from a conscious perspective, what does it all fit? Okay, so from the physics perspective, leaving aside quantum mechanics, we believe we live in a fully deterministic world, right? But then comes of course quantum mechanics, so now we know that certain things are in principle not predictable, which as you said I prefer, because the idea that the initial condition of the universe and then everything else, we're just acting out the initial condition of the universe, that doesn't… It's not a romantic notion. Certainly not. Now when it comes to consciousness, I think we do have certain freedom. We are much more constrained by physics of course and by our past and by our own conscious desires and what our parents told us and what our environment tells us. We all know that, right? There's hundreds of experiments that show how we can be influenced. But finally in the final analysis, when you make a life – and I'm talking really about critical decision where you really think, should I marry, should I go to this school or that school, should I take this job or that job, should I cheat on my taxes or not? These are things where you really deliberate and I think under those conditions, you are as free as you can be. When you bring your entire being, your entire conscious being to that question and try to analyze it under all the various conditions, then you make a decision, you are as free as you can ever be. That is I think what free will is. It's not a will that's totally free to do anything it wants. That's not possible. Right. So as Jack mentioned, you actually write a blog about books you've read, amazing books from, I'm Russian, from Bulgakov, Neil Gaiman, Carl Sagan, Murakami. So what is a book that early in your life transformed the way you saw the world, something that changed your life? Nietzsche I guess did. That's Brooks R. Truster because he talks about some of these problems. He was one of the first discoverer of the unconscious. This is a little bit before Freud when he was in the air. He makes all these claims that people sort of under the guise or under the mass of charity actually are very noncharitable. So he is sort of really the first discoverer of the great land of the unconscious and that really struck me. And what do you think about the unconscious, what do you think about Freud, what do you think about these ideas? Just like dark matter in the universe, what's over there in that unconscious? A lot. I mean much more than we think. This is what a lot of last 100 years of research has shown. So I think he was a genius, misguided towards the end, but he started out as a neuroscientist. He contributed, he did the studies on the lamprey, he contributed himself to the neuron hypothesis, the idea that there are discrete units that we call nerve cells now. And then he wrote about the unconscious and I think it's true, there's lots of stuff happening. You feel this particular when you're in a relationship and it breaks asunder, right? And then you have this terrible, you can have love and hate and lust and anger and all of it's mixed in. And when you try to analyze yourself, why am I so upset? It's very, very difficult to penetrate to those basements, those caverns in your mind because the prying eyes of conscious doesn't have access to those, but they're there in the amygdala or lots of other places. They make you upset or angry or sad or depressed and it's very difficult to try to actually uncover the reason. You can go to a shrink, you can talk with your friend endlessly, you construct finally a story why this happened, why you love her or don't love her or whatever, but you don't really know whether that actually happened because you simply don't have access to those parts of the brain and they're very powerful. Do you think that's a feature or a bug of our brain? The fact that we have this deep, difficult to dive into subconscious? I think it's a feature because otherwise, look, we are like any other brain or nervous system or computer, we are severely band limited. If everything I do, every emotion I feel, every eye movements I make, if all of that had to be under the control of consciousness, I wouldn't be here. What you do early on, your brain, you have to be conscious when you learn things like typing or like riding on a bike, but then what you do, you train up routes, I think that involve basal ganglia and striatum. You train up different parts of your brain and then once you do it automatically like typing, you can show you do it much faster without even thinking about it because you've got these highly specialized, what Frans Krik and I call zombie agents, they're taking care of that while your consciousness can sort of worry about the abstract sense of the text you want to write. I think that's true for many, many things. But for the things like all the fights you had with an ex girlfriend, things that you would think are not useful to still linger somewhere in the subconscious. So that seems like a bug that it would stick to there. You think it would be better if you can analyze it and then get it out of the system. Better to get it out of the system or just forget it ever happened. That seems a very buggy kind of. Well yeah, in general we don't have, and that's probably functional, we don't have an ability unless it's extreme, there are cases, clinical dissociations, right? When people are heavily abused, when they completely repress the memory, but that doesn't happen in normal people. We don't have an ability to remove traumatic memories and of course we suffer from that. On the other hand, probably if you had the ability to constantly wipe your memory, you'd probably do it to an extent that isn't useful to you. So yeah, it's a good question to balance. So on the books, as Jack mentioned, correct me if I'm wrong, but broadly speaking, academia and the different scientific disciplines, certainly in engineering, reading literature seems to be a rare pursuit. So I'm wrong on this, but that's in my experience, most people read much more technical text and do not sort of escape or seek truth in literature. It seems like you do. So what do you think is the value, what do you think literature adds to the pursuit of scientific truth? Do you think it's good, it's useful for everybody? Gives you access to a much wider array of human experiences. How valuable do you think it is? Well if you want to understand human nature and nature in general, then I think you have to better understand a wide variety of experiences, not just sitting in a lab staring at a screen and having a face flashed onto you for a hundred milliseconds and pushing a button. That's what I used to do, that's what most psychologists do. There's nothing wrong with that, but you need to consider lots of other strange states. And literature is a shortcut for this. Well yeah, because literature, that's what literature is all about, all sorts of interesting experiences that people have, the contingency of it, the fact that women experience the world different, black people experience the world different. The one way to experience that is reading all these different literature and try to find out. You see, everything is so relative. You read a book 300 years ago, they thought about certain problems very, very differently than us today. We today, like any culture, think we know it all. That's common to every culture. Every culture believes at its heyday they know it all. And then you realize, well, there's other ways of viewing the universe and some of them may have lots of things in their favor. So this is a question I wanted to ask about time scale or scale in general. When you, with IIT or in general, try to think about consciousness, try to think about these ideas, we kind of naturally think in human time scales, and also entities that are sized close to humans. Do you think of things that are much larger and much smaller as containing consciousness? And do you think of things that take, you know, eons to operate in their conscious cause effect? That's a very good question. So I think a lot about small creatures because experimentally, you know, a lot of people work on flies and bees, right? So most people just think they are automata, they're just bugs for heaven's sake, right? But if you look at their behavior, like bees, they can recognize individual humans. They have this very complicated way to communicate. If you've ever been involved or you know your parents when they bought a house, what sort of agonizing decision that is. And bees have to do that once a year, right, when they swarm in the spring. And then they have this very elaborate way, they have free and scouts, they go to the individual sites, they come back, they have this power, this dance, literally, where they dance for several days, they try to recruit other deets, this very complicated decision rate, when they finally, once they make a decision, the entire swarm, the scouts warm up the entire swarm and then go to one location. They don't go to 50 locations, they go to one location that the scouts have agreed upon by themselves. That's awesome. If we look at the circuit complexity, it's 10 times more denser than anything we have in our brain. Now they only have a million neurons, but the neurons are amazingly complex. Complex behavior, very complicated circuitry, so there's no question they experience something, their life is very different, they're tiny, they only live, you know, for, well, workers live maybe for two months. So I think, and IIT tells you this, in principle, the substrate of consciousness is the substrate that maximizes the cause effect power over all possible spatial temporal grains. So when I think about, for example, do you know the science fiction story, The Black Cloud? Okay, it's a classic by Fred Hoyle, the astronomer. He has this cloud intervening between the earth and the sun and leading to some sort of, to global cooling, this is written in the 50s. It turns out you can, using the radio dish, they communicate with actually an entity, it's actually an intelligent entity, and they sort of, they convince it to move away. So here you have a radical different entity, and in principle, IIT says, well, you can measure the integrated information, in principle at least, and yes, if the maximum of that occurs at a time scale of months, rather than in assets for a fraction of a second, yes, then they would experience life where each moment is a month rather than, or microsecond, right, rather than a fraction of a second in the human case. And so there may be forms of consciousness that we simply don't recognize for what they are because they are so radical different from anything you and I are used to. Again, that's why it's good to read or to watch science fiction movies, well, to think about this. Do you know Stanislav Lem, this Polish science fiction writer, he wrote Solaris and was turned into a Hollywood movie? Yes. His best novel is in the 60s, a very engineer, he's an engineer in background. His most interesting novel is called The Victorious, where human civilization, they have this mission to this planet and everything is destroyed and they discover machines, humans got killed and then these machines took over and there was this machine evolution, Darwinian evolution, he talks about this very vividly. And finally, the dominant machine intelligence organism that survived were gigantic clouds of little hexagonal universal cellular automata. This was written in the 60s, so typically they're all lying on the ground individual by themselves, but in times of crisis, they can communicate, they assemble into gigantic nets into clouds of trillions of these particles and then they become hyper intelligent and they can beat anything that humans can throw at it. It's very beautiful and compelling where you have an intelligence where finally the humans leave the planet, they're simply unable to understand and comprehend this creature. They can say, well, either we can nuke the entire planet and destroy it or we just have to leave because fundamentally it's an alien, it's so alien from us and our ideas that we cannot communicate with them. Yeah, actually in conversation, so you're talking to us, Steven Wolf from Brought Up is that there could be ideas that you already have these artificial general intelligence like super smart or maybe conscious beings in the cellular automata, we just don't know how to talk to them. So it's the language of communication, but you don't know what to do with it. So that's one sort of view is consciousness is only something you can measure. So it's not conscious if you can't measure it. So you're making an ontological and an epistemic statement. One is it's just like seeing the multiverses, that might be true, but I can't communicate with them. I can't have any knowledge of them. That's an epistemic argument. Right? So those are two different things. So it may well be possible. Look, in another case that's happening right now, people are building these mini organoids. Do you know what this is? So you can take stem cells from under your arm, put it in a dish, add four transcription factors and then you can induce them to grow into large, well, large, they're a few millimeters. They're like a half a million neurons that look like nerve cells in a dish called mini organoids at Harvard, at Stanford, everywhere they're building them. It may well be possible that they're beginning to feel like something, but we can't really communicate with them right now. So people are beginning to think about the ethics of this. So yes, he may be perfectly right, but it's one question, are they conscious or not? It's a totally separate question. How would I know? Those are two different things. If you could give advice to a young researcher, sort of dreaming of understanding or creating human level intelligence or consciousness, what would you say? Just follow your dreams. Read widely. No, I mean, I suppose with discipline, what is the pursuit that they should take on? Is it neuroscience? Is it computational cognitive science? Is it philosophy? Is it computer science or robotics? No, in a sense that, okay, so the only known system that have high level of intelligence is homo sapiens. So if you wanted to build it, it's probably good to continue to study closely what humans do. So cognitive neuroscience, you know, somewhere between cognitive neuroscience on the one hand and some philosophy of mind and then AI, AI computer science. You can look at all the original ideas in your network, they all came from neuroscience, right? Reinforce whether it's Snarky, Minsky building is Snarky or whether it's, you know, the early Hubel and Wiesel experiments at Harvard that then gave rise to networks and then multi layer networks. So it may well be possible, in fact, some people argue that to make the next big step in AI once we realize the limits of deep convolutional networks, they can do certain things, but they can't really understand. They don't, they can't really, I can't really show them one image. I can show you a single image of somebody, a pickpocket who steals a wallet from a purse. You immediately know that's a pickpocket. Now computer system would just say, well, it's a man, it's a woman, it's a purse, right? Unless you train this machine on showing it a hundred thousand pickpockets, right? So it doesn't have this easy understanding that you have, right? So some people make the argument in order to go to the next step or you really want to build machines that understand in a way you and I, we have to go to psychology. We need to understand how we do it and how our brains enable us to do it. And so therefore being on the cusp, it's also so exciting to try to understand better our nature and then to build, to take some of those inside and build them. So I think the most exciting thing is somewhere in the interface between cognitive science, neuroscience, AI, computer science and philosophy of mind. Beautiful. Yeah. I'd say if there is from the machine learning, from our, from the computer science, computer vision perspective, many of the researchers kind of ignore the way the human brain works or even psychology or literature or studying the brain, I would hope Josh Tenenbaum talks about bringing that in more and more. And that's, yeah, so you've worked on some amazing stuff throughout your life. What's the thing that you're really excited about? What's the mystery that you would love to uncover in the near term beyond, beyond all the mysteries that you're already surrounded by? Well, so there's a structure called the claustrum. This is a structure, it's underneath our cortex, it's yay big. You have one on the left, on the right, underneath this, underneath the insula, it's very thin, it's like one millimeter, it's embedded in, in wiring, in white matter, so it's very difficult to image. And it has, it has connection to every cortical region. And Francis Crick, the last paper he ever wrote, he dictated corrections the day he died in hospital on this paper. You know, we hypothesize, well, because it has this unique anatomy, it gets input from every cortical area and projects back to every, every cortical area. That the function of this structure is similar, it's just a metaphor to the role of a conductor in a symphony orchestra. You have all the different cortical players. You have some that do motion, some that do theory of mind, some that infer social interaction and color and hearing and all the different modules in cortex. But of course, what consciousness is, consciousness puts it all together into one package, right? The binding problem, all of that. And this is really the function because it has relatively few neurons compared to cortex, but it talks, it receives input from all of them and it projects back to all of them. And so we're testing that right now. We've got this beautiful neuronal reconstruction in the mouse called crown of thorns, crown of thorns neurons that are in the claustrum that have the most widespread connection of any neuron I've ever seen. They're very, you have individual neurons that sit in the claustrum tiny, but then they have this single neuron, they have this huge axonal tree that cover both ipsy and contralateral cortex and trying to turn using, you know, fancy tools like optogenetics, trying to turn those neurons on or off and study it, what happens in the, in the mouse. So this thing is perhaps where the parts become the whole. Perhaps it's one of the structures, it's a very good way of putting it, where the individual parts turn into the whole of the whole of the conscious experience. Well, with that, thank you very much for being here today. Thank you very much. Thank you very much. All right, thank you very much.",mit course artificial general intelligence get chance sit christoph koch seminal figure neurobiology neuroscience generally study consciousness president chief scientific officer allen institute brain science seattle professor caltech mit extremely cite citation research writing idea big impact scientific community general public way think consciousness way human being author book quest consciousness neurobiological approach recent book consciousness confessions romantic reductionist enjoy conversation course subscribe click little bell icon sure miss video comment leave suggestion people like course idea like explore thank hope enjoy okay delve beautiful mystery consciousness let zoom little bit let ask think intelligent life universe yes believe evidence think probability overwhelming favor give universe galaxy galaxy star know star planet feel make feel special experience feel world experience world independent creature feel world access world strange compelling way core human existence say human think intelligent creature think experience world yes evolve product natural evolution experience world consciousness human right wide spread biology thing special talk course people talk baby little child talk patient stroke left inferior frontal gyrus talk normal adult people talk think make special compare let monkey dog cat mouse creature share planet evidence suggest experience world overwhelmingly likely alien experience world course differently different sensorium different sensor different environment fact strongly suppose experience feel pain pleasure sort spectrum hear sense course language different able understand poetry experience correct talk video hear mention siputzo dachshund come grow family young technically midwestern boy technically yes travel bit little bit accent talk siputzo dachshund have element humanness consciousness discover want ask look childhood remember time realize sort person perspective conscious idea step outside see special go brain actually good question sure recall discrete moment mean grant world know world know know world see hear voice touching thing later early underguided day enrol physics philosophy think think fundamentally mysterious physics right explain transition physics brain feeling feeling come look foundational equation quantum mechanic general relativity look periodic table element look endless atgc chat gene consciousness wake morning world experience heart ancient mind body problem experience world consciousness experience experience people subjective feeling people phenomenology people qualia philosopher denote thing feel like famous word philosopher thomas nagel feel like bat american angry sad love pain experience possible experience mundane sit chair exalt have mystical moment deep meditation different form experience experience sit maybe skip couple generation ibm watson win jeopardy gap guess question watson smart human alive experience gap big big question occupy people certainly year know advent birth computer question alan turing try answer course indirect way propose test operational test know try mean person think test right lock away communication try guess person computer system question soon know alexa siri know google pass test right game know ultimately certainly generation machine speak complete poise remember say remember email like samantha remember movie yeah question go happen course key question feel like samantha movie feel like watson strongly think different concept co mingle concept intelligence natural artificial concept consciousness experience natural artificial different thing historically associate consciousness intelligence live world leave aside computer natural selection surround creature kin intelligent specie adapted particular environment adapted whale dog talk paramecium little worm complexity nervous system go cell specialized cell worm net percent cell nerve cell creature like like blue whale billion nerve cell base behavioral evidence base underlie neuroscience believe creature complex well adapt particular ecological niche conscious partly brain grow believe consciousness unlike ancient ancient people think culture think consciousness intelligence heart today honey love heart actually honey love lateral hypothalamus valentine day sweetheart know hypothalamus piece chocolate heart shape chocolate language believe brain brain different complexity think different level consciousness capable different experience confront world know begin engineer intelligence radical unclear intelligence engineer consciousness experience fundamentally difference intelligence function intelligence matter exactly define sort adaptation new environment able learn quickly understand know setup go actor go happen function consciousness function consciousness sense fundamental case instance case clinic deal patient let stroke traffic accident et cetera pretty immobile terri schiavo hear historically person florida heart stand reanimate year call vegetative state thousand people vegetative state know know like occasionally open eye hour close eye sleep wake cycle occasionally behavior like know way establish lawful relationship doctor say mom say patient behavior people experience design build brain machine interface experience course case lock state famous book call diving bell butterfly editor french editor stroke brainstem unable vertical eye eye movement eye dictate entire book people lose end evidence suggest case behavior consciousness second case tonight like go sleep close eye sleep wake inside sleeping body conscious experience different everyday experience fly surprised fly meet long dead pet childhood dog surprised meet conscious experience love hate emotional body state typically rem state send active signal motor neuron paralyze call atonia like patient act dream example rem behavioral disorder bad juju okay case pure experience recently people mystical experience go singapore go flotation tank yeah right big tub fill water body temperature epsom salt strip completely naked lie inside close lid darkness complete darkness soundproof quickly bodiless float naked ring watch feel body anymore sound soundless photon sightless timeless early actually hear heart sort adapt sort passage time cease yeah train like meditation think early think lot little bit spooky feel somewhat uncomfortable think go bored try think actively mindless bodiless timeless know soundless sightless mindless conscious experience asleep yeah asleep pure pure function computation remembering project plan fully conscious fully conscious go effect mean epiphenomena select mean function able lay sensory free deprivation tank conscious experience evolutionary evolutionary obviously evolve flotation tank environment mean biology notoriously bad ask question telenormical question eye eye like teacher eye probably function good answer question speculate endlessly biology science good mechanistic question charge universe right find certain universe positive negative charge quantum mechanic hold know theory hold quantum mechanic hold universe unclear telenormical question question difficult answer relationship complexity brain processing power consciousness case example give everyday experience night trauma principle everybody sort mystical experience dissociation function intelligence consciousness catch ask question let ask question question give talk later today ture test intelligence consciousness draw line scientific way consciousness present entity anticipate answer cause neurobiological answer test human brain machine brain know test begin approach test consciousness present thing okay good question let step point human let stick human test call zap zip procedure ping brain transcranial magnetic stimulation look electrical reverberation essentially eg measure complexity brain response awake people asleep normal people awake people anesthetize patient percent accuracy case clear patient person conscious unconscious complexity high low adopt technique similar creature like monkey dog mouse similar brain course point help cortex know send magnetic pulse iphone computer probably go break need ultimately need theory consciousness rely intuition intuition yeah somebody talk conscious patient child baby talk right believe baby conscious experience right patient mention talk dream talk paralyze ultimately need rely intuition need theory conscience tell piece matter piece highly excitable matter like brain like computer give rise conscious experience believe believe anymore old story soul right common explanation people accept instill lot people today believe god endow special thing animal rene descartes famously say dog hit carriage yell cry special thing magic magic soul re cogitan soul believe case anymore difference brain guy silicon particular behavior match siri alexa year talk good possible human ground conscious particular say course course conscious ask know generate way course behave like like person difference relate problem hard consciousness hard problem subjective right know direct experience consciousness experience consciousness assume sort bayesian person believe probability theory know abduction good available fact deduce brain similar scanner brain roughly go behave way know muesli ask taste tell thing know right infer base conscious theory need theory tell system make conscious theory yes integrate information theory let maybe introduction people familiar descartes talk lot pan panpsychism describe uh physicalism versus dualism mention soul history idea idea panpsychism debate uh panpsychism um emerge um dualism versus uh physicalism panpsychism fit argue okay let step panpsychism ancient belief uh mean plato aristotle talk uh modern philosopher talk course buddhism idea prevalent mean different version version say ensoule rock stone dog people forest iphones right matter ensoule sort version version biology creature small large single cell giant sequoia tree feel like think somewhat realistic um different version mean feel like feeling kind feel like possible feel like paramecium think pretty likely feel like bee mouse dog sure okay panpsychism broad people example bertrand russell try advocate idea call rasselian monism panpsychism physics view inside idea physics good describe relationship object like charge like gravity right know describe relationship curvature mass distribution okay relationship thing physics describe ultimate reality relationship know quark stuff like person observer yes yes yes consciousness physics feel inside conscious experience way physics brain particularly cortex feel inside paramecium get remember paramecium pretty dumb creature billion different molecule probably know different protein assemble highly highly complex system single person computer system far planet manage accurately simulate complexity vastly escape yes little thing feel like tiny bit voice head like expectation know complex thing feel like yeah interesting draw line maybe try understand difference life intelligence consciousness define live thing conscious thing intelligent thing intermix totally separate okay question answer lot stuff talk today mystery fascinating one right example aristotle probably important scientist philosopher live certainly western culture idea call hylomorphism popular day different form soul soul form say biological creature vegetative soul life principle today think understand biochemistry nonlinear thermodynamic say sensitive soul animal human sensitive soul petitive soul smell drive want reproduce want eat et cetera human call rational soul okay idea christendom rational soul live forever unclear mean different reading aristotle different believe rational soul immortal probably think course plato christianity soul immortal connection god ask essentially modern conception aristotle call different form life think know life planet right understand originate difficult rigorously pin modern definition death fact right conference ongoing try define legally medically death simple death stop breathe heart stop beat dead totally uncontroversial unsure wait minute patient breathe dead ventilator heart pacemaker difficult define death typically death define end life life define death okay good definition intelligence rigorous definition know measure call iq g factor right begin build narrow sense right like alphago watson know google car uber car narrow ai people think artificial general intelligence roughly say ability learn adapt new environment say radical difference experience unclear build machine agi priori clear machine consciousness let ask way think try build artificial general intelligence system think figure build artificial consciousness help agi way think intelligent require consciousness human go hand hand human think biology consciousness intelligence go hand hand quay illusion brain evolve highly complex complexity theory integrate information theory sort ultimately closely tie consciousness ultimately causal power evolve system artificial system particularly digital machine ask point blank alexa year easily pass ture test conscious claim conscious fact radical version think experiment build computer simulation human brain know henry markham blue brain project human brain project switzerland try let grant success year perfect simulation human brain neuron simulate larynx motor neuron broca area course talk hi wake feel great ok computer simulation principle map brain conscious simulate difference simulate real simulate behavior associate consciousness properly intelligence particular person simulate simulate intelligence have conscious experience nice metaphor engineer physicist typically write einstein field equation equation describe link general relativity curvature mass run laptop predict central black hole center galaxy massive twist space time light escape black hole funny wonder computer simulation suck simulate gravity causal power gravity huge difference difference real simulator like wet inside computer computer run code simulate weather storm order artificial consciousness causal power human brain build call neuromorphic machine hardware similar human brain digital clocked phenomenon computer clarify think consciousness require create human level intelligence accompany human brain machine correct maybe agi let dig little bit mean intelligence thing g factor kind iq test intelligence think maybe way people siri impressive think people siri intelligent yes intelligence amorphous thing intelligent like kind connection human being sense impress intelligence feel operate world human feel like like consciousness think world good natural nlp system natural language understanding generation happy know create agi know happy yes believe high level functional intelligence particular sort g know fluid like intelligence cherish particularly place like mit right machine priori reason lot reason believe go happen know year year beneficial ai create ai system mention ethic exceptionally intelligent know align value value humanity think need consciousness yes think good argument concerned ai threat ai la nick bostrom existentialist threat think have intelligence empathy right find abuse dog find abhorrent abuse animal right find abhorrent thing call empathy look greek mean feel feel path empathy feel somebody suffer conspecific person wife kid dog feel naturally feel emphatic long term interest survival homo sapiens sapien build agi powerful emphatic response exterminate humanity conscious experience create consciousness artificial human consciousness think fear maybe go early day nietzsche think fear suffering essential consciousness range experience system experience system particular kind positive experience look principle people rat implant electrode hypothalamus pleasure center rat rat stimulate care food natural sex drink anymore stimulate pleasurable feeling guess like orgasm day long priori reason need great variety clearly survive work right engineer artificially think need great variety conscious experience pleasure fear terrible existence think possible conceptual logical ground real creature artificially engineer want fear fear extinction want positive repetitive state state want machine encourage machine positive feedback mention panpsychism jump little bit have kind mental property like human consciousness have element consciousness special human consciousness like spoon form panpsychism think ascribe consciousness like spoon liver theory integrate information theory system look outside relatively simple internal causal power feel like theory priori special human biologically know thing special human speak overblown sense importance believe exceptional god gift universe behaviorally main thing plan long term language give enormous power current dominant specie planet mention god grow devout roman catholic family consciousness sort explore deeply fundamental human thing religion touch religion fit thinking consciousness grow life change view religion far understand yeah mean close roman catholic anymore believe sort god god educate believe sit fullness time unite sort everlasting bliss evidence look world night large wonder thing understand think thing cult look understand universe dark matter dark energy idea maybe lose sock know tell sort current religious spiritual sentiment close form buddhism reincarnation unfortunately evidence reincarnation describe way buddhism see world little bit talk spend meeting dalai lama impress unlike example let pope cardinal emphasize minimize suffering creature early beginning look suffer creature people everybody universal course degree animal general capable suffering develop normally develop human think consciousness pervade universe technique think like mindfulness etc meditation try access claim fundamental aspect reality sure fundamental think physical inside view consciousness aspect thing access life get remember conscious experience conscious experience come prior know physic come prior knowledge universe atom super string molecule thing directly acquaint world populate thing image sound head touch actually question sound like kind rich life talk rock climbing like love literature consciousness experience thing think help research topic yes particularly think state example rock climbing rowing crew rowing bike day thing call zone want particularly respect consciousness strangely addictive state people want go wonder addict think experience close pure experience zone conscious inner voice anymore inner voice nag pay taxis fight ex thing zone go wonderful state fully world climb row bike soccer sort consciousness action case pure experience action case experience aspect conscious touch basic conscious existence basic deeply satisfying think touch root touch get close root different intelligence think simulation hypothesis simulation theory idea live computer simulation rapture nerd rapture nerd think likely hypothesis engage hundred scholar century exist mind god modern version equally plausible people love talk sort thing know book write simulation hypothesis people want fine esoteric testable useful think term maybe connect question free talk vaguely remember say idea free make uncomfortable think free physics perspective conscious perspective fit okay physics perspective leave aside quantum mechanic believe live fully deterministic world right come course quantum mechanic know certain thing principle predictable say prefer idea initial condition universe act initial condition universe romantic notion certainly come consciousness think certain freedom constrain physic course past conscious desire parent tell environment tell know right hundred experiment influence finally final analysis life talk critical decision think marry school school job job cheat taxis thing deliberate think condition free bring entire entire conscious question try analyze condition decision free think free totally free want possible right jack mention actually write blog book read amazing book russian bulgakov neil gaiman carl sagan murakami book early life transform way see world change life nietzsche guess brooks truster talk problem discoverer unconscious little bit freud air make claim people sort guise mass charity actually noncharitable sort discoverer great land unconscious strike think unconscious think freud think idea like dark matter universe unconscious lot mean think lot year research show think genius misguide end start neuroscientist contribute study lamprey contribute neuron hypothesis idea discrete unit nerve cell write unconscious think true lot stuff happen feel particular relationship break asunder right terrible love hate lust anger mixed try analyze upset difficult penetrate basement cavern mind pry eye conscious access amygdala lot place upset angry sad depressed difficult try actually uncover reason shrink talk friend endlessly construct finally story happen love love know actually happen simply access part brain powerful think feature bug brain fact deep difficult dive subconscious think feature look like brain nervous system computer severely band limited emotion feel eye movement control consciousness early brain conscious learn thing like type like ride bike train route think involve basal ganglia striatum train different part brain automatically like type fast think get highly specialize frans krik zombie agent take care consciousness sort worry abstract sense text want write think true thing thing like fight ex girlfriend thing think useful linger subconscious like bug stick think well analyze system well system forget happen buggy kind yeah general probably functional ability extreme case clinical dissociation right people heavily abuse completely repress memory happen normal people ability remove traumatic memory course suffer hand probably ability constantly wipe memory probably extent useful yeah good question balance book jack mention correct wrong broadly speak academia different scientific discipline certainly engineering read literature rare pursuit wrong experience people read technical text sort escape seek truth literature like think value think literature add pursuit scientific truth think good useful everybody give access wide array human experience valuable think want understand human nature nature general think well understand wide variety experience sit lab stare screen have face flash millisecond push button psychologist wrong need consider lot strange state literature shortcut yeah literature literature sort interesting experience people contingency fact woman experience world different black people experience world different way experience read different literature try find relative read book year ago think certain problem differently today today like culture think know common culture culture believe heyday know realize way view universe lot thing favor question want ask time scale scale general iit general try think consciousness try think idea kind naturally think human time scale entity size close human think thing large small contain consciousness think thing know eon operate conscious cause effect good question think lot small creature experimentally know lot people work fly bee right people think automata bug heaven sake right look behavior like bee recognize individual human complicated way communicate involve know parent buy house sort agonizing decision bee year right swarm spring elaborate way free scout individual site come power dance literally dance day try recruit deet complicated decision rate finally decision entire swarm scout warm entire swarm location location location scout agree awesome look circuit complexity time denser brain million neuron neuron amazingly complex complex behavior complicated circuitry question experience life different tiny live know worker live maybe month think iit tell principle substrate consciousness substrate maximize cause effect power possible spatial temporal grain think example know science fiction story black cloud okay classic fred hoyle astronomer cloud intervene earth sun lead sort global cooling write turn radio dish communicate actually entity actually intelligent entity sort convince away radical different entity principle iit say measure integrate information principle yes maximum occur time scale month asset fraction second yes experience life moment month microsecond right fraction second human case form consciousness simply recognize radical different good read watch science fiction movie think know stanislav lem polish science fiction writer write solaris turn hollywood movie yes good novel engineer engineer background interesting novel call victorious human civilization mission planet destroy discover machine human get kill machine take machine evolution darwinian evolution talk vividly finally dominant machine intelligence organism survive gigantic cloud little hexagonal universal cellular automata write typically lie ground individual time crisis communicate assemble gigantic net cloud trillion particle hyper intelligent beat human throw beautiful compelling intelligence finally human leave planet simply unable understand comprehend creature nuke entire planet destroy leave fundamentally alien alien idea communicate yeah actually conversation talk steven wolf brought idea artificial general intelligence like super smart maybe conscious being cellular automata know talk language communication know sort view consciousness measure conscious measure make ontological epistemic statement like see multiverse true communicate knowledge epistemic argument right different thing possible look case happen right people build mini organoid know stem cell arm dish add transcription factor induce grow large large millimeter like half million neuron look like nerve cell dish call mini organoid harvard stanford build possible begin feel like communicate right people begin think ethic yes perfectly right question conscious totally separate question know different thing advice young researcher sort dream understanding create human level intelligence consciousness follow dream read widely mean suppose discipline pursuit neuroscience computational cognitive science philosophy computer science robotic sense okay know system high level intelligence homo sapiens want build probably good continue study closely human cognitive neuroscience know cognitive neuroscience hand philosophy mind ai ai computer science look original idea network come neuroscience right reinforce snarky minsky building snarky know early hubel wiesel experiment harvard give rise network multi layer network possible fact people argue big step ai realize limit deep convolutional network certain thing understand image single image somebody pickpocket steal wallet purse immediately know pickpocket computer system man woman purse right train machine show thousand pickpocket right easy understanding right people argument order step want build machine understand way psychology need understand brain enable cusp exciting try understand well nature build inside build think exciting thing interface cognitive science neuroscience ai computer science philosophy mind beautiful yeah machine learning computer science computer vision perspective researcher kind ignore way human brain work psychology literature study brain hope josh tenenbaum talk bring yeah work amazing stuff life thing excited mystery love uncover near term mystery surround structure call claustrum structure underneath cortex yay big left right underneath underneath insula thin like millimeter embed wiring white matter difficult image connection cortical region francis crick paper write dictate correction day die hospital paper know hypothesize unique anatomy get input cortical area project cortical area function structure similar metaphor role conductor symphony orchestra different cortical player motion theory mind infer social interaction color hearing different module cortex course consciousness consciousness put package right bind problem function relatively neuron compare cortex talk receive input project test right get beautiful neuronal reconstruction mouse call crown thorn crown thorn neuron claustrum widespread connection neuron see individual neuron sit claustrum tiny single neuron huge axonal tree cover ipsy contralateral cortex try turn know fancy tool like optogenetic try turn neuron study happen mouse thing part structure good way put individual part turn conscious experience thank today thank thank right thank,"['Christoph Koch', 'Thomas Nagel', 'Alan Turing', 'Terri Schiavo', 'Rene Descartes', 'Bertrand Russell', 'Henry Markham', 'Nick Bostrom', 'Neil Gaiman', 'Carl Sagan', 'Brooks R. Truster', 'Frans Krik', 'Fred Hoyle', 'Stanislav Lem', 'Steven Wolf', 'Josh Tenenbaum', 'Francis Crick']","['Allen Institute for Brain Science', 'MIT', 'Stanford University']","['Brain-Computer Interfaces', 'Computer Vision Systems', 'Quantum Computing']","['Consciousness and AI', 'Neuroscience and Cognition', 'Computational Neuroscience', 'Philosophy of Mind and AI', 'Human-AI Interaction']"
3,Steven Pinker,AI in the Age of Reason,"You've studied the human mind, cognition, language, vision, evolution, psychology, from child to adult, from the level of individual to the level of our entire civilization. So I feel like I can start with a simple multiple choice question. What is the meaning of life? Is it A. to attain knowledge as Plato said, B. to attain power as Nietzsche said, C. to escape death as Ernest Becker said, D. to propagate our genes as Darwin and others have said, E. there is no meaning as the nihilists have said, F. knowing the meaning of life is beyond our cognitive capabilities as Stephen Pinker said, based on my interpretation 20 years ago, and G. none of the above. I'd say A. comes closest, but I would amend that to C. to attaining not only knowledge but fulfillment more generally, that is life, health, stimulation, access to the living cultural and social world. Now this is our meaning of life. It's not the meaning of life if you were to ask our genes. Their meaning is to propagate copies of themselves, but that is distinct from the meaning that the brain that they lead to sets for itself. So to you knowledge is a small subset or a large subset? It's a large subset, but it's not the entirety of human striving because we also want to interact with people. We want to experience beauty. We want to experience the richness of the natural world, but understanding what makes the universe tick is way up there. For some of us more than others, certainly for me that's one of the top five. So is that a fundamental aspect? Are you just describing your own preference or is this a fundamental aspect of human nature is to seek knowledge? In your latest book you talk about the power, the usefulness of rationality and reason and so on. Is that a fundamental nature of human beings or is it something we should just strive for? Both. We're capable of striving for it because it is one of the things that make us what we are, homo sapiens, wise men. We are unusual among animals in the degree to which we acquire knowledge and use it to survive. We make tools. We strike agreements via language. We extract poisons. We predict the behavior of animals. We try to get at the workings of plants. And when I say we, I don't just mean we in the modern West, but we as a species everywhere, which is how we've managed to occupy every niche on the planet, how we've managed to drive other animals to extinction. And the refinement of reason in pursuit of human wellbeing, of health, happiness, social richness, cultural richness is our main challenge in the present. That is using our intellect, using our knowledge to figure out how the world works, how we work in order to make discoveries and strike agreements that make us all better off in the long run. Right. And you do that almost undeniably and in a data driven way in your recent book, but I'd like to focus on the artificial intelligence aspect of things and not just artificial intelligence, but natural intelligence too. So 20 years ago in a book you've written on how the mind works, you conjecture again, am I right to interpret things? You can correct me if I'm wrong, but you conjecture that human thought in the brain may be a result of a massive network of highly interconnected neurons. So from this interconnectivity emerges thought compared to artificial neural networks, which we use for machine learning today, is there something fundamentally more complex, mysterious, even magical about the biological neural networks versus the ones we've been starting to use over the past 60 years and have become to success in the past 10? There is something a little bit mysterious about the human neural networks, which is that each one of us who is a neural network knows that we ourselves are conscious. Conscious not in the sense of registering our surroundings or even registering our internal state, but in having subjective first person, present tense experience. That is when I see red, it's not just different from green, but there's a redness to it that I feel. Whether an artificial system would experience that or not, I don't know and I don't think I can know. That's why it's mysterious. If we had a perfectly lifelike robot that was behaviorally indistinguishable from a human, would we attribute consciousness to it or ought we to attribute consciousness to it? And that's something that it's very hard to know. But putting that aside, putting aside that largely philosophical question, the question is, is there some difference between the human neural network and the ones that we're building in artificial intelligence will mean that we're on the current trajectory, not going to reach the point where we've got a lifelike robot indistinguishable from a human because the way their so called neural networks are organized are different from the way ours are organized. I think there's overlap, but I think there are some big differences that current neural networks, current so called deep learning systems are in reality not all that deep. That is, they are very good at extracting high order statistical regularities, but most of the systems don't have a semantic level, a level of actual understanding of who did what to whom, why, where, how things work, what causes what else. Do you think that kind of thing can emerge as it does? So artificial neural networks are much smaller, the number of connections and so on than the current human biological networks, but do you think sort of to go to consciousness or to go to this higher level semantic reasoning about things, do you think that can emerge with just a larger network with a more richly weirdly interconnected network? Separate it in consciousness because consciousness is even a matter of complexity. A really weird one. Yeah, you could sensibly ask the question of whether shrimp are conscious, for example, they're not terribly complex, but maybe they feel pain. So let's just put that part of it aside. But I think sheer size of a neural network is not enough to give it structure and knowledge, but if it's suitably engineered, then why not? That is, we're neural networks, natural selection did a kind of equivalent of engineering of our brains. So I don't think there's anything mysterious in the sense that no system made out of silicon could ever do what a human brain can do. I think it's possible in principle. Whether it'll ever happen depends not only on how clever we are in engineering these systems, but whether we even want to, whether that's even a sensible goal. That is, you can ask the question, is there any locomotion system that is as good as a human? Well, we kind of want to do better than a human ultimately in terms of legged locomotion. There's no reason that humans should be our benchmark. They're tools that might be better in some ways. It may be that we can't duplicate a natural system because at some point it's so much cheaper to use a natural system that we're not going to invest more brainpower and resources. So for example, we don't really have an exact substitute for wood. We still build houses out of wood. We still build furniture out of wood. We like the look. We like the feel. It has certain properties that synthetics don't. It's not that there's anything magical or mysterious about wood. It's just that the extra steps of duplicating everything about wood is something we just haven't bothered because we have wood. Likewise, say cotton. I'm wearing cotton clothing now. It feels much better than polyester. It's not that cotton has something magic in it. It's not that we couldn't ever synthesize something exactly like cotton, but at some point it's just not worth it. We've got cotton. Likewise, in the case of human intelligence, the goal of making an artificial system that is exactly like the human brain is a goal that we probably know is going to pursue to the bitter end, I suspect, because if you want tools that do things better than humans, you're not going to care whether it does something like humans. So for example, diagnosing cancer or predicting the weather, why set humans as your benchmark? But in general, I suspect you also believe that even if the human should not be a benchmark and we don't want to imitate humans in their system, there's a lot to be learned about how to create an artificial intelligence system by studying the human. Yeah, I think that's right. In the same way that to build flying machines, we want to understand the laws of aerodynamics, including birds, but not mimic the birds, but they're the same laws. You have a view on AI, artificial intelligence, and safety that, from my perspective, is refreshingly rational or perhaps more importantly, has elements of positivity to it, which I think can be inspiring and empowering as opposed to paralyzing. For many people, including AI researchers, the eventual existential threat of AI is obvious, not only possible, but obvious. And for many others, including AI researchers, the threat is not obvious. So Elon Musk is famously in the highly concerned about AI camp, saying things like AI is far more dangerous than nuclear weapons, and that AI will likely destroy human civilization. Human civilization. So in February, he said that if Elon was really serious about AI, the threat of AI, he would stop building self driving cars that he's doing very successfully as part of Tesla. Then he said, wow, if even Pinker doesn't understand the difference between narrow AI, like a car and general AI, when the latter literally has a million times more compute power and an open ended utility function, humanity is in deep trouble. So first, what did you mean by the statement about Elon Musk should stop building self driving cars if he's deeply concerned? Not the last time that Elon Musk has fired off an intemperate tweet. Well, we live in a world where Twitter has power. Yes. Yeah, I think there are two kinds of existential threat that have been discussed in connection with artificial intelligence, and I think that they're both incoherent. One of them is a vague fear of AI takeover, that just as we subjugated animals and less technologically advanced peoples, so if we build something that's more advanced than us, it will inevitably turn us into pets or slaves or domesticated animal equivalents. I think this confuses intelligence with a will to power, that it so happens that in the intelligence system we are most familiar with, namely homo sapiens, we are products of natural selection, which is a competitive process, and so bundled together with our problem solving capacity are a number of nasty traits like dominance and exploitation and maximization of power and glory and resources and influence. There's no reason to think that sheer problem solving capability will set that as one of its goals. Its goals will be whatever we set its goals as, and as long as someone isn't building a megalomaniacal artificial intelligence, then there's no reason to think that it would naturally evolve in that direction. Now, you might say, well, what if we gave it the goal of maximizing its own power source? That's a pretty stupid goal to give an autonomous system. You don't give it that goal. I mean, that's just self evidently idiotic. So if you look at the history of the world, there's been a lot of opportunities where engineers could instill in a system destructive power and they choose not to because that's the natural process of engineering. Well, except for weapons. I mean, if you're building a weapon, its goal is to destroy people, and so I think there are good reasons to not build certain kinds of weapons. I think building nuclear weapons was a massive mistake. You do. So maybe pause on that because that is one of the serious threats. Do you think that it was a mistake in a sense that it should have been stopped early on? Or do you think it's just an unfortunate event of invention that this was invented? Do you think it's possible to stop? I guess is the question. It's hard to rewind the clock because of course it was invented in the context of World War II and the fear that the Nazis might develop one first. Then once it was initiated for that reason, it was hard to turn off, especially since winning the war against the Japanese and the Nazis was such an overwhelming goal of every responsible person that there's just nothing that people wouldn't have done then to ensure victory. It's quite possible if World War II hadn't happened that nuclear weapons wouldn't have been invented. We can't know, but I don't think it was by any means a necessity, any more than some of the other weapon systems that were envisioned but never implemented, like planes that would disperse poison gas over cities like crop dusters or systems to try to create earthquakes and tsunamis in enemy countries, to weaponize the weather, weaponize solar flares, all kinds of crazy schemes that we thought the better of. I think analogies between nuclear weapons and artificial intelligence are fundamentally misguided because the whole point of nuclear weapons is to destroy things. The point of artificial intelligence is not to destroy things. So the analogy is misleading. So there's two artificial intelligence you mentioned. The first one I guess is highly intelligent or power hungry. Yeah, it's a system that we design ourselves where we give it the goals. Goals are external to the means to attain the goals. If we don't design an artificially intelligent system to maximize dominance, then it won't maximize dominance. It's just that we're so familiar with homo sapiens where these two traits come bundled together, particularly in men, that we are apt to confuse high intelligence with a will to power, but that's just an error. The other fear is that will be collateral damage that will give artificial intelligence a goal like make paper clips and it will pursue that goal so brilliantly that before we can stop it, it turns us into paper clips. We'll give it the goal of curing cancer and it will turn us into guinea pigs for lethal experiments or give it the goal of world peace and its conception of world peace is no people, therefore no fighting and so it will kill us all. Now I think these are utterly fanciful. In fact, I think they're actually self defeating. They first of all assume that we're going to be so brilliant that we can design an artificial intelligence that can cure cancer, but so stupid that we don't specify what we mean by curing cancer in enough detail that it won't kill us in the process and it assumes that the system will be so smart that it can cure cancer, but so idiotic that it can't figure out that what we mean by curing cancer is not killing everyone. I think that the collateral damage scenario, the value alignment problem is also based on a misconception. So one of the challenges, of course, we don't know how to build either system currently or are we even close to knowing? Of course, those things can change overnight, but at this time, theorizing about it is very challenging in either direction. So that's probably at the core of the problem is without that ability to reason about the real engineering things here at hand is your imagination runs away with things. Exactly. But let me sort of ask, what do you think was the motivation, the thought process of Elon Musk? I build autonomous vehicles, I study autonomous vehicles, I study Tesla autopilot. I think it is one of the greatest currently large scale application of artificial intelligence in the world. It has potentially a very positive impact on society. So how does a person who's creating this very good quote unquote narrow AI system also seem to be so concerned about this other general AI? What do you think is the motivation there? What do you think is the thing? Well, you probably have to ask him, but there, and he is notoriously flamboyant, impulsive to the, as we have just seen, to the detriment of his own goals of the health of the company. So I don't know what's going on in his mind. You probably have to ask him, but I don't think the, and I don't think the distinction between special purpose AI and so called general AI is relevant that in the same way that special purpose AI is not going to do anything conceivable in order to attain a goal. All engineering systems are designed to trade off across multiple goals. When we build cars in the first place, we didn't forget to install brakes because the goal of a car is to go fast. It occurred to people, yes, you want it to go fast, but not always. So you would build in brakes too. Likewise, if a car is going to be autonomous and program it to take the shortest route to the airport, it's not going to take the diagonal and mow down people and trees and fences because that's the shortest route. That's not what we mean by the shortest route when we program it. And that's just what an intelligence system is by definition. It takes into account multiple constraints. The same is true, in fact, even more true of so called general intelligence. That is, if it's genuinely intelligent, it's not going to pursue some goal singlemindedly, omitting every other consideration and collateral effect. That's not artificial and general intelligence. That's artificial stupidity. I agree with you, by the way, on the promise of autonomous vehicles for improving human welfare. I think it's spectacular. And I'm surprised at how little press coverage notes that in the United States alone, something like 40,000 people die every year on the highways, vastly more than are killed by terrorists. And we spent a trillion dollars on a war to combat deaths by terrorism, about half a dozen a year. Whereas year in, year out, 40,000 people are massacred on the highways, which could be brought down to very close to zero. So I'm with you on the humanitarian benefit. Let me just mention that as a person who's building these cars, it is a little bit offensive to me to say that engineers would be clueless enough not to engineer safety into systems. I often stay up at night thinking about those 40,000 people that are dying. And everything I tried to engineer is to save those people's lives. So every new invention that I'm super excited about, in all the deep learning literature and CVPR conferences and NIPS, everything I'm super excited about is all grounded in making it safe and help people. So I just don't see how that trajectory can all of a sudden slip into a situation where intelligence will be highly negative. You and I certainly agree on that. And I think that's only the beginning of the potential humanitarian benefits of artificial intelligence. There's been enormous attention to what are we going to do with the people whose jobs are made obsolete by artificial intelligence, but very little attention given to the fact that the jobs that are going to be made obsolete are horrible jobs. The fact that people aren't going to be picking crops and making beds and driving trucks and mining coal, these are soul deadening jobs. And we have a whole literature sympathizing with the people stuck in these menial, mind deadening, dangerous jobs. If we can eliminate them, this is a fantastic boon to humanity. Now granted, you solve one problem and there's another one, namely, how do we get these people a decent income? But if we're smart enough to invent machines that can make beds and put away dishes and handle hospital patients, I think we're smart enough to figure out how to redistribute income to apportion some of the vast economic savings to the human beings who will no longer be needed to make beds. Okay. Sam Harris says that it's obvious that eventually AI will be an existential risk. He's one of the people who says it's obvious. We don't know when the claim goes, but eventually it's obvious. And because we don't know when, we should worry about it now. This is a very interesting argument in my eyes. So how do we think about timescale? How do we think about existential threats when we don't really, we know so little about the threat, unlike nuclear weapons perhaps, about this particular threat, that it could happen tomorrow, right? So, but very likely it won't. Very likely it'd be a hundred years away. So how do we ignore it? How do we talk about it? Do we worry about it? How do we think about those? What is it? A threat that we can imagine. It's within the limits of our imagination, but not within our limits of understanding to accurately predict it. But what is the it that we're afraid of? Sorry. AI being the existential threat. AI. How? Like enslaving us or turning us into paperclips? I think the most compelling from the Sam Harris perspective would be the paperclip situation. Yeah. I mean, I just think it's totally fanciful. I mean, that is don't build a system. Don't give a, don't, first of all, the code of engineering is you don't implement a system with massive control before testing it. Now, perhaps the culture of engineering will radically change. Then I would worry, but I don't see any signs that engineers will suddenly do idiotic things, like put a electric power plant in control of a system that they haven't tested first. Or all of these scenarios, not only imagine almost a magically powered intelligence, including things like cure cancer, which is probably an incoherent goal because there's so many different kinds of cancer or bring about world peace. I mean, how do you even specify that as a goal? But the scenarios also imagine some degree of control of every molecule in the universe, which not only is itself unlikely, but we would not start to connect these systems to infrastructure without testing as we would any kind of engineering system. Now, maybe some engineers will be irresponsible and we need legal and regulatory and legal responsibility implemented so that engineers don't do things that are stupid by their own standards. But the, I've never seen enough of a plausible scenario of existential threat to devote large amounts of brain power to, to forestall it. So you believe in the sort of the power on mass of the engineering of reason, as you argue in your latest book of Reason and Science, to sort of be the very thing that guides the development of new technology so it's safe and also keeps us safe. You know, granted the same culture of safety that currently is part of the engineering mindset for airplanes, for example. So yeah, I don't think that that should be thrown out the window and that untested all powerful systems should be suddenly implemented, but there's no reason to think they are. And in fact, if you look at the progress of artificial intelligence, it's been, you know, it's been impressive, especially in the last 10 years or so, but the idea that suddenly there'll be a step function that all of a sudden before we know it, it will be all powerful, that there'll be some kind of recursive self improvement, some kind of fume is also fanciful. We, certainly by the technology that we, that we're now impresses us, such as deep learning, where you train something on hundreds of thousands or millions of examples, they're not hundreds of thousands of problems of which curing cancer is a typical example. And so the kind of techniques that have allowed AI to increase in the last five years are not the kind that are going to lead to this fantasy of exponential sudden self improvement. I think it's kind of a magical thinking. It's not based on our understanding of how AI actually works. Now give me a chance here. So you said fanciful, magical thinking. In his TED talk, Sam Harris says that thinking about AI killing all human civilization is somehow fun, intellectually. Now I have to say as a scientist engineer, I don't find it fun, but when I'm having beer with my non AI friends, there is indeed something fun and appealing about it. Like talking about an episode of Black Mirror, considering if a large meteor is headed towards Earth, we were just told a large meteor is headed towards Earth, something like this. And can you relate to this sense of fun? And do you understand the psychology of it? Yes. Good question. I personally don't find it fun. I find it kind of actually a waste of time because there are genuine threats that we ought to be thinking about like pandemics, like cyber security vulnerabilities, like the possibility of nuclear war and certainly climate change. You know, this is enough to fill many conversations. And I think Sam did put his finger on something, namely that there is a community, sometimes called the rationality community, that delights in using its brainpower to come up with scenarios that would not occur to mere mortals, to less cerebral people. So there is a kind of intellectual thrill in finding new things to worry about that no one has worried about yet. I actually think, though, that it's not only is it a kind of fun that doesn't give me particular pleasure, but I think there can be a pernicious side to it, namely that you overcome people with such dread, such fatalism, that there are so many ways to die, to annihilate our civilization, that we may as well enjoy life while we can. There's nothing we can do about it. If climate change doesn't do us in, then runaway robots will. So let's enjoy ourselves now. We've got to prioritize. We have to look at threats that are close to certainty, such as climate change, and distinguish those from ones that are merely imaginable but with infinitesimal probabilities. And we have to take into account people's worry budget. You can't worry about everything. And if you sow dread and fear and terror and fatalism, it can lead to a kind of numbness. Well, these problems are overwhelming, and the engineers are just going to kill us all. So let's either destroy the entire infrastructure of science, technology, or let's just enjoy life while we can. So there's a certain line of worry, which I'm worried about a lot of things in engineering. There's a certain line of worry when you cross, you're allowed to cross, that it becomes paralyzing fear as opposed to productive fear. And that's kind of what you're highlighting. Exactly right. And we've seen some, we know that human effort is not well calibrated against risk in that because a basic tenet of cognitive psychology is that perception of risk and hence perception of fear is driven by imaginability, not by data. And so we misallocate vast amounts of resources to avoiding terrorism, which kills on average about six Americans a year with one exception of 9 11. We invade countries, we invent entire new departments of government with massive, massive expenditure of resources and lives to defend ourselves against a trivial risk. Whereas guaranteed risks, one of them you mentioned traffic fatalities and even risks that are not here, but are plausible enough to worry about like pandemics, like nuclear war, receive far too little attention. In presidential debates, there's no discussion of how to minimize the risk of nuclear war. Lots of discussion of terrorism, for example. And so I think it's essential to calibrate our budget of fear, worry, concern, planning to the actual probability of harm. Yep. So let me ask this question. So speaking of imaginability, you said it's important to think about reason and one of my favorite people who likes to dip into the outskirts of reason through fascinating exploration of his imagination is Joe Rogan. Oh yes. So who has through reason used to believe a lot of conspiracies and through reason has stripped away a lot of his beliefs in that way. So it's fascinating actually to watch him through rationality kind of throw away the ideas of Bigfoot and 9 11. I'm not sure exactly. Kim Trails. I don't know what he believes in. Yes. Okay. But he no longer believed in. No, that's right. No, he's become a real force for good. Yep. So you were on the Joe Rogan podcast in February and had a fascinating conversation, but as far as I remember, didn't talk much about artificial intelligence. I will be on his podcast in a couple of weeks. Joe is very much concerned about existential threat of AI. I'm not sure if you're, this is why I was hoping that you would get into that topic. And in this way, he represents quite a lot of people who look at the topic of AI from 10,000 foot level. So as an exercise of communication, you said it's important to be rational and reason about these things. Let me ask, if you were to coach me as an AI researcher about how to speak to Joe and the general public about AI, what would you advise? Well, the short answer would be to read the sections that I wrote in enlightenment now about AI, but a longer reason would be I think to emphasize, and I think you're very well positioned as an engineer to remind people about the culture of engineering, that it really is safety oriented, that another discussion in enlightenment now, I plot rates of accidental death from various causes, plane crashes, car crashes, occupational accidents, even death by lightning strikes. And they all plummet because the culture of engineering is how do you squeeze out the lethal risks, death by fire, death by drowning, death by asphyxiation, all of them drastically declined because of advances in engineering that I got to say, I did not appreciate until I saw those graphs. And it is because exactly, people like you who stay up at night thinking, oh my God, is what I'm inventing likely to hurt people and to deploy ingenuity to prevent that from happening. Now, I'm not an engineer, although I spent 22 years at MIT, so I know something about the culture of engineering. My understanding is that this is the way you think if you're an engineer. And it's essential that that culture not be suddenly switched off when it comes to artificial intelligence. So, I mean, that could be a problem, but is there any reason to think it would be switched off? I don't think so. And one, there's not enough engineers speaking up for this way, for the excitement, for the positive view of human nature, what you're trying to create is positivity. Like everything we try to invent is trying to do good for the world. But let me ask you about the psychology of negativity. It seems just objectively, not considering the topic, it seems that being negative about the future makes you sound smarter than being positive about the future, irregardless of topic. Am I correct in this observation? And if so, why do you think that is? Yeah, I think there is that phenomenon that, as Tom Lehrer, the satirist said, always predict the worst and you'll be hailed as a prophet. It may be part of our overall negativity bias. We are as a species more attuned to the negative than the positive. We dread losses more than we enjoy gains. And that might open up a space for prophets to remind us of harms and risks and losses that we may have overlooked. So I think there is that asymmetry. So you've written some of my favorite books all over the place. So starting from Enlightenment Now to The Better Ages of Our Nature, Blank Slate, How the Mind Works, the one about language, Language Instinct. Bill Gates, big fan too, said of your most recent book that it's my new favorite book of all time. So for you as an author, what was a book early on in your life that had a profound impact on the way you saw the world? Certainly this book, Enlightenment Now, was influenced by David Deutsch's The Beginning of Infinity, a rather deep reflection on knowledge and the power of knowledge to improve the human condition. And with bits of wisdom such as that problems are inevitable but problems are solvable given the right knowledge and that solutions create new problems that have to be solved in their turn. That's I think a kind of wisdom about the human condition that influenced the writing of this book. There are some books that are excellent but obscure, some of which I have on a page on my website. I read a book called The History of Force, self published by a political scientist named James Payne on the historical decline of violence and that was one of the inspirations for The Better Angels of Our Nature. What about early on? If you look back when you were maybe a teenager? I loved a book called One, Two, Three, Infinity. When I was a young adult I read that book by George Gamow, the physicist, which had very accessible and humorous explanations of relativity, of number theory, of dimensionality, high multiple dimensional spaces in a way that I think is still delightful 70 years after it was published. I like the Time Life Science series. These are books that would arrive every month that my mother subscribed to, each one on a different topic. One would be on electricity, one would be on forests, one would be on evolution and then one was on the mind. I was just intrigued that there could be a science of mind and that book I would cite as an influence as well. Then later on... That's when you fell in love with the idea of studying the mind? Was that the thing that grabbed you? It was one of the things I would say. I read as a college student the book Reflections on Language by Noam Chomsky. I spent most of his career here at MIT. Richard Dawkins, two books, The Blind Watchmaker and The Selfish Gene, were enormously influential, mainly for the content but also for the writing style, the ability to explain abstract concepts in lively prose. Stephen Jay Gould's first collection, Ever Since Darwin, also an excellent example of lively writing. George Miller, a psychologist that most psychologists are familiar with, came up with the idea that human memory has a capacity of seven plus or minus two chunks. That's probably his biggest claim to fame. But he wrote a couple of books on language and communication that I read as an undergraduate. Again, beautifully written and intellectually deep. Wonderful. Stephen, thank you so much for taking the time today. My pleasure. Thanks a lot, Lex.",study human mind cognition language vision evolution psychology child adult level individual level entire civilization feel like start simple multiple choice question meaning life attain knowledge plato say attain power nietzsche say escape death ernest becker say propagate gene darwin say meaning nihilist say know meaning life cognitive capability stephen pinker say base interpretation year ago come close amend attain knowledge fulfillment generally life health stimulation access live cultural social world meaning life meaning life ask gene meaning propagate copy distinct meaning brain lead set knowledge small subset large subset large subset entirety human striving want interact people want experience beauty want experience richness natural world understand make universe tick way certainly fundamental aspect describe preference fundamental aspect human nature seek knowledge late book talk power usefulness rationality reason fundamental nature human being strive capable strive thing homo sapiens wise man unusual animal degree acquire knowledge use survive tool strike agreement language extract poison predict behavior animal try working plant mean modern west species manage occupy niche planet manage drive animal extinction refinement reason pursuit human wellbeing health happiness social richness cultural richness main challenge present intellect knowledge figure world work work order discovery strike agreement well long run right undeniably datum drive way recent book like focus artificial intelligence aspect thing artificial intelligence natural intelligence year ago book write mind work conjecture right interpret thing correct wrong conjecture human thought brain result massive network highly interconnect neuron interconnectivity emerge think compare artificial neural network use machine learning today fundamentally complex mysterious magical biological neural network versus one start use past year success past little bit mysterious human neural network neural network know conscious conscious sense register surrounding register internal state have subjective person present tense experience red different green redness feel artificial system experience know think know mysterious perfectly lifelike robot behaviorally indistinguishable human attribute consciousness ought attribute consciousness hard know put aside put aside largely philosophical question question difference human neural network one build artificial intelligence mean current trajectory go reach point get lifelike robot indistinguishable human way call neural network organize different way organize think overlap think big difference current neural network current call deep learning system reality deep good extract high order statistical regularity system semantic level level actual understanding thing work cause think kind thing emerge artificial neural network small number connection current human biological network think sort consciousness high level semantic reasoning thing think emerge large network richly weirdly interconnect network separate consciousness consciousness matter complexity weird yeah sensibly ask question shrimp conscious example terribly complex maybe feel pain let aside think sheer size neural network structure knowledge suitably engineer neural network natural selection kind equivalent engineering brain think mysterious sense system silicon human brain think possible principle happen depend clever engineer system want sensible goal ask question locomotion system good human kind want well human ultimately term legged locomotion reason human benchmark tool well way duplicate natural system point cheap use natural system go invest brainpower resource example exact substitute wood build house wood build furniture wood like look like feel certain property synthetic magical mysterious wood extra step duplicate wood bother wood likewise cotton wear cotton clothing feel well polyester cotton magic synthesize exactly like cotton point worth get cotton likewise case human intelligence goal make artificial system exactly like human brain goal probably know go pursue bitter end suspect want tool thing well human go care like human example diagnose cancer predict weather set human benchmark general suspect believe human benchmark want imitate human system lot learn create artificial intelligence system study human yeah think right way build fly machine want understand law aerodynamic include bird mimic bird law view ai artificial intelligence safety perspective refreshingly rational importantly element positivity think inspire empower oppose paralyzing people include ai researcher eventual existential threat ai obvious possible obvious include ai researcher threat obvious elon musk famously highly concerned ai camp say thing like ai far dangerous nuclear weapon ai likely destroy human civilization human civilization february say elon ai threat ai stop build self drive car successfully tesla say wow pinker understand difference narrow ai like car general ai literally million time compute power open ended utility function humanity deep trouble mean statement elon musk stop build self drive car deeply concerned time elon musk fire intemperate tweet live world twitter power yes yeah think kind existential threat discuss connection artificial intelligence think incoherent vague fear ai takeover subjugate animal technologically advanced people build advanced inevitably turn pet slave domesticate animal equivalent think confuse intelligence power happen intelligence system familiar homo sapiens product natural selection competitive process bundle problem solve capacity number nasty trait like dominance exploitation maximization power glory resource influence reason think sheer problem solve capability set goal goal set goal long build megalomaniacal artificial intelligence reason think naturally evolve direction give goal maximize power source pretty stupid goal autonomous system goal mean self evidently idiotic look history world lot opportunity engineer instill system destructive power choose natural process engineering weapon mean build weapon goal destroy people think good reason build certain kind weapon think build nuclear weapon massive mistake maybe pause threat think mistake sense stop early think unfortunate event invention invent think possible stop guess question hard rewind clock course invent context world war ii fear nazis develop initiate reason hard turn especially win war japanese nazis overwhelming goal responsible person people ensure victory possible world war ii happen nuclear weapon invent know think mean necessity weapon system envision implement like plane disperse poison gas city like crop duster system try create earthquake tsunamis enemy country weaponize weather weaponize solar flare kind crazy scheme think well think analogy nuclear weapon artificial intelligence fundamentally misguide point nuclear weapon destroy thing point artificial intelligence destroy thing analogy misleading artificial intelligence mention guess highly intelligent power hungry yeah system design goal goal external mean attain goal design artificially intelligent system maximize dominance will maximize dominance familiar homo sapiens trait come bundled particularly man apt confuse high intelligence power error fear collateral damage artificial intelligence goal like paper clip pursue goal brilliantly stop turn paper clip goal cure cancer turn guinea pig lethal experiment goal world peace conception world peace people fighting kill think utterly fanciful fact think actually self defeat assume go brilliant design artificial intelligence cure cancer stupid specify mean cure cancer detail will kill process assume system smart cure cancer idiotic figure mean cure cancer kill think collateral damage scenario value alignment problem base misconception challenge course know build system currently close knowing course thing change overnight time theorize challenging direction probably core problem ability reason real engineering thing hand imagination run away thing exactly let sort ask think motivation think process elon musk build autonomous vehicle study autonomous vehicle study tesla autopilot think great currently large scale application artificial intelligence world potentially positive impact society person create good quote unquote narrow ai system concerned general ai think motivation think thing probably ask notoriously flamboyant impulsive see detriment goal health company know go mind probably ask think think distinction special purpose ai call general ai relevant way special purpose ai go conceivable order attain goal engineering system design trade multiple goal build car place forget install brake goal car fast occur people yes want fast build brake likewise car go autonomous program short route airport go diagonal mow people tree fence short route mean short route program intelligence system definition take account multiple constraint true fact true call general intelligence genuinely intelligent go pursue goal singlemindedly omit consideration collateral effect artificial general intelligence artificial stupidity agree way promise autonomous vehicle improve human welfare think spectacular surprised little press coverage note united states like people die year highway vastly kill terrorist spend trillion dollar war combat death terrorism half dozen year year year people massacre highway bring close zero humanitarian benefit let mention person build car little bit offensive engineer clueless engineer safety system stay night think people die try engineer save people life new invention super excited deep learn literature cvpr conference nips super excited ground make safe help people trajectory sudden slip situation intelligence highly negative certainly agree think beginning potential humanitarian benefit artificial intelligence enormous attention go people job obsolete artificial intelligence little attention give fact job go obsolete horrible job fact people go pick crop make bed drive truck mining coal soul deaden job literature sympathizing people stick menial mind deadening dangerous job eliminate fantastic boon humanity grant solve problem people decent income smart invent machine bed away dish handle hospital patient think smart figure redistribute income apportion vast economic saving human being long need bed okay sam harris say obvious eventually ai existential risk people say obvious know claim go eventually obvious know worry interesting argument eye think timescale think existential threat know little threat unlike nuclear weapon particular threat happen tomorrow right likely will likely year away ignore talk worry think threat imagine limit imagination limit understanding accurately predict afraid sorry ai existential threat ai like enslave turn paperclip think compelling sam harris perspective paperclip situation yeah mean think totally fanciful mean build system code engineering implement system massive control test culture engineering radically change worry sign engineer suddenly idiotic thing like electric power plant control system test scenario imagine magically powered intelligence include thing like cure cancer probably incoherent goal different kind cancer bring world peace mean specify goal scenario imagine degree control molecule universe unlikely start connect system infrastructure testing kind engineering system maybe engineer irresponsible need legal regulatory legal responsibility implement engineer thing stupid standard see plausible scenario existential threat devote large amount brain power forestall believe sort power mass engineering reason argue late book reason science sort thing guide development new technology safe keep safe know grant culture safety currently engineering mindset airplane example yeah think throw window untested powerful system suddenly implement reason think fact look progress artificial intelligence know impressive especially year idea suddenly step function sudden know powerful kind recursive self improvement kind fume fanciful certainly technology impress deep learning train hundred thousand million example hundred thousand problem cure cancer typical example kind technique allow ai increase year kind go lead fantasy exponential sudden self improvement think kind magical thinking base understanding ai actually work chance say fanciful magical thinking ted talk sam harris say think ai kill human civilization fun intellectually scientist engineer find fun have beer non ai friend fun appeal like talk episode black mirror consider large meteor head earth tell large meteor head earth like relate sense fun understand psychology yes good question personally find fun find kind actually waste time genuine threat ought think like pandemic like cyber security vulnerability like possibility nuclear war certainly climate change know fill conversation think sam finger community call rationality community delight brainpower come scenario occur mere mortal cerebral people kind intellectual thrill find new thing worry worry actually think kind fun particular pleasure think pernicious overcome people dread fatalism way die annihilate civilization enjoy life climate change runaway robot let enjoy get prioritize look threat close certainty climate change distinguish one merely imaginable infinitesimal probability account people worry budget worry sow dread fear terror fatalism lead kind numbness problem overwhelming engineer go kill let destroy entire infrastructure science technology let enjoy life certain line worry worried lot thing engineering certain line worry cross allow cross paralyze fear oppose productive fear kind highlight exactly right see know human effort calibrate risk basic tenet cognitive psychology perception risk perception fear drive imaginability datum misallocate vast amount resource avoid terrorism kill average americans year exception invade country invent entire new department government massive massive expenditure resource life defend trivial risk guarantee risk mention traffic fatality risk plausible worry like pandemic like nuclear war receive far little attention presidential debate discussion minimize risk nuclear war lot discussion terrorism example think essential calibrate budget fear worry concern plan actual probability harm yep let ask question speak imaginability say important think reason favorite people like dip outskirt reason fascinating exploration imagination joe rogan oh yes reason believe lot conspiracy reason strip away lot belief way fascinating actually watch rationality kind throw away idea bigfoot sure exactly kim trails know believe yes okay long believe right real force good yep joe rogan podcast february fascinating conversation far remember talk artificial intelligence podcast couple week joe concerned existential threat ai sure hope topic way represent lot people look topic ai foot level exercise communication say important rational reason thing let ask coach ai researcher speak joe general public ai advise short answer read section write enlightenment ai long reason think emphasize think position engineer remind people culture engineering safety orient discussion enlightenment plot rate accidental death cause plane crash car crash occupational accident death lightning strike plummet culture engineering squeeze lethal risk death fire death drown death asphyxiation drastically decline advance engineering get appreciate see graph exactly people like stay night thinking oh god invent likely hurt people deploy ingenuity prevent happen engineer spend year mit know culture engineering understanding way think engineer essential culture suddenly switch come artificial intelligence mean problem reason think switch think engineer speak way excitement positive view human nature try create positivity like try invent try good world let ask psychology negativity objectively consider topic negative future make sound smart positive future irregardless topic correct observation think yeah think phenomenon tom lehrer satirist say predict bad hail prophet overall negativity bias specie attuned negative positive dread loss enjoy gain open space prophet remind harm risk loss overlook think asymmetry write favorite book place start enlightenment better ages nature blank slate mind works language language instinct bill gates big fan say recent book new favorite book time author book early life profound impact way see world certainly book enlightenment influence david deutsch beginning infinity deep reflection knowledge power knowledge improve human condition bit wisdom problem inevitable problem solvable give right knowledge solution create new problem solve turn think kind wisdom human condition influence writing book book excellent obscure page website read book call history force self publish political scientist name james payne historical decline violence inspiration better angels nature early look maybe teenager love book call infinity young adult read book george gamow physicist accessible humorous explanation relativity number theory dimensionality high multiple dimensional space way think delightful year publish like time life science series book arrive month mother subscribe different topic electricity forest evolution mind intrigue science mind book cite influence later fall love idea study mind thing grab thing read college student book reflections language noam chomsky spend career mit richard dawkins book blind watchmaker selfish gene enormously influential mainly content writing style ability explain abstract concept lively prose stephen jay gould collection darwin excellent example lively writing george miller psychologist psychologist familiar come idea human memory capacity seven plus minus chunk probably big claim fame write couple book language communication read undergraduate beautifully write intellectually deep wonderful stephen thank take time today pleasure thank lot lex,"['Ernest Becker', 'Stephen Pinker', 'Elon Musk', 'Sam Harris', 'Joe Rogan', 'Kim Trails', 'Tom Lehrer', 'Bill Gates', 'David Deutsch', 'James Payne', 'George Gamow', 'Richard Dawkins', 'Stephen Jay Gould', 'George Miller']","['Harvard University', 'MIT', 'Google']","['Natural Language Processing Models', 'Deep Neural Networks', 'Big Data Analytics']","['Artificial General Intelligence (AGI)', 'Human-AI Interaction', 'Natural Language Processing', 'AI Safety and Ethics', 'Neuroscience and Cognition']"
4,Yoshua Bengio,Deep Learning,"What difference between biological neural networks and artificial neural networks is most mysterious, captivating, and profound for you? First of all, there's so much we don't know about biological neural networks, and that's very mysterious and captivating because maybe it holds the key to improving artificial neural networks. One of the things I studied recently is something that we don't know how biological neural networks do but would be really useful for artificial ones is the ability to do credit assignment through very long time spans. There are things that we can in principle do with artificial neural nets, but it's not very convenient and it's not biologically plausible. And this mismatch, I think this kind of mismatch may be an interesting thing to study to, A, understand better how brains might do these things because we don't have good corresponding theories with artificial neural nets, and B, maybe provide new ideas that we could explore about things that brain do differently and that we could incorporate in artificial neural nets. So let's break credit assignment up a little bit. Yes. So what, it's a beautifully technical term, but it could incorporate so many things. So is it more on the RNN memory side, that thinking like that, or is it something about knowledge, building up common sense knowledge over time? Or is it more in the reinforcement learning sense that you're picking up rewards over time for a particular, to achieve a certain kind of goal? So I was thinking more about the first two meanings whereby we store all kinds of memories, episodic memories in our brain, which we can access later in order to help us both infer causes of things that we are observing now and assign credit to decisions or interpretations we came up with a while ago when those memories were stored. And then we can change the way we would have reacted or interpreted things in the past, and now that's credit assignment used for learning. So in which way do you think artificial neural networks, the current LSTM, the current architectures are not able to capture the, presumably you're thinking of very long term? Yes. So current, the current nets are doing a fairly good jobs for sequences with dozens or say hundreds of time steps. And then it gets harder and harder and depending on what you have to remember and so on, as you consider longer durations. Whereas humans seem to be able to do credit assignment through essentially arbitrary times, like I could remember something I did last year. And then now because I see some new evidence, I'm going to change my mind about the way I was thinking last year. And hopefully not do the same mistake again. I think a big part of that is probably forgetting. You're only remembering the really important things. It's very efficient forgetting. Yes. So there's a selection of what we remember. And I think there are really cool connection to higher level cognition here regarding consciousness, deciding and emotions, so deciding what comes to consciousness and what gets stored in memory, which are not trivial either. So you've been at the forefront there all along, showing some of the amazing things that neural networks, deep neural networks can do in the field of artificial intelligence is just broadly in all kinds of applications. But we can talk about that forever. But what, in your view, because we're thinking towards the future, is the weakest aspect of the way deep neural networks represent the world? What is that? What is in your view is missing? So current state of the art neural nets trained on large quantities of images or texts have some level of understanding of, you know, what explains those data sets, but it's very basic, it's it's very low level. And it's not nearly as robust and abstract and general as our understanding. Okay, so that doesn't tell us how to fix things. But I think it encourages us to think about how we can maybe train our neural nets differently, so that they would focus, for example, on causal explanation, something that we don't do currently with neural net training. Also, one thing I'll talk about in my talk this afternoon is the fact that instead of learning separately from images and videos on one hand and from texts on the other hand, we need to do a better job of jointly learning about language and about the world to which it refers. So that, you know, both sides can help each other. We need to have good world models in our neural nets for them to really understand sentences, which talk about what's going on in the world. And I think we need language input to help provide clues about what high level concepts like semantic concepts should be represented at the top levels of our neural nets. In fact, there is evidence that the purely unsupervised learning of representations doesn't give rise to high level representations that are as powerful as the ones we're getting from supervised learning. And so the clues we're getting just with the labels, not even sentences, is already very, very high level. And I think that's a very important thing to keep in mind. It's already very powerful. Do you think that's an architecture challenge or is it a data set challenge? Neither. I'm tempted to just end it there. Can you elaborate slightly? Of course, data sets and architectures are something you want to always play with. But I think the crucial thing is more the training objectives, the training frameworks. For example, going from passive observation of data to more active agents, which learn by intervening in the world, the relationships between causes and effects, the sort of objective functions, which could be important to allow the highest level explanations to rise from the learning, which I don't think we have now, the kinds of objective functions, which could be used to reward exploration, the right kind of exploration. So these kinds of questions are neither in the data set nor in the architecture, but more in how we learn, under what objectives and so on. Yeah, I've heard you mention in several contexts, the idea of sort of the way children learn, they interact with objects in the world. And it seems fascinating because in some sense, except with some cases in reinforcement learning, that idea is not part of the learning process in artificial neural networks. So it's almost like, do you envision something like an objective function saying, you know what, if you poke this object in this kind of way, it would be really helpful for me to further learn. Right, right. Sort of almost guiding some aspect of the learning. Right, right, right. So I was talking to Rebecca Sacks just a few minutes ago, and she was talking about lots and lots of evidence from infants seem to clearly pick what interests them in a directed way. And so they're not passive learners, they focus their attention on aspects of the world, which are most interesting, surprising in a non trivial way. That makes them change their theories of the world. So that's a fascinating view of the future progress. But on a more maybe boring question, do you think going deeper and larger, so do you think just increasing the size of the things that have been increasing a lot in the past few years, is going to be a big thing? I think increasing the size of the things that have been increasing a lot in the past few years will also make significant progress. So some of the representational issues that you mentioned, they're kind of shallow, in some sense. Oh, shallow in the sense of abstraction. In the sense of abstraction, they're not getting some... I don't think that having more depth in the network in the sense of instead of 100 layers, you're going to have more layers. I don't think so. Is that obvious to you? Yes. What is clear to me is that engineers and companies and labs and grad students will continue to tune architectures and explore all kinds of tweaks to make the current state of the art slightly ever slightly better. But I don't think that's going to be nearly enough. I think we need changes in the way that we're considering learning to achieve the goal that these learners actually understand in a deep way the environment in which they are, you know, observing and acting. But I guess I was trying to ask a question that's more interesting than just more layers. It's basically, once you figure out a way to learn through interacting, how many parameters it takes to store that information. So I think our brain is quite bigger than most neural networks. Right, right. Oh, I see what you mean. Oh, I'm with you there. So I agree that in order to build neural nets with the kind of broad knowledge of the world that typical adult humans have, probably the kind of computing power we have now is going to be insufficient. So the good news is there are hardware companies building neural net chips. And so it's going to get better. However, the good news in a way, which is also a bad news, is that even our state of the art, deep learning methods fail to learn models that understand even very simple environments, like some grid worlds that we have built. Even these fairly simple environments, I mean, of course, if you train them with enough examples, eventually they get it. But it's just like, instead of what humans might need just dozens of examples, these things will need millions for very, very, very simple tasks. And so I think there's an opportunity for academics who don't have the kind of computing power that, say, Google has to do really important and exciting research to advance the state of the art in training frameworks, learning models, agent learning in even simple environments that are synthetic, that seem trivial, but yet current machine learning fails on. We talked about priors and common sense knowledge. It seems like we humans take a lot of knowledge for granted. So what's your view of these priors of forming this broad view of the world, this accumulation of information and how we can teach neural networks or learning systems to pick that knowledge up? So knowledge, for a while, the artificial intelligence was maybe in the 80s, like there's a time where knowledge representation, knowledge, acquisition, expert systems, I mean, the symbolic AI was a view, was an interesting problem set to solve and it was kind of put on hold a little bit, it seems like. Because it doesn't work. It doesn't work. That's right. But that's right. But the goals of that remain important. Yes. Remain important. And how do you think those goals can be addressed? Right. So first of all, I believe that one reason why the classical expert systems approach failed is because a lot of the knowledge we have, so you talked about common sense intuition, there's a lot of knowledge like this, which is not consciously accessible. There are lots of decisions we're taking that we can't really explain, even if sometimes we make up a story. And that knowledge is also necessary for machines to take good decisions. And that knowledge is hard to codify in expert systems, rule based systems and classical AI formalism. And there are other issues, of course, with the old AI, like not really good ways of handling uncertainty, I would say something more subtle, which we understand better now, but I think still isn't enough in the minds of people. There's something really powerful that comes from distributed representations, the thing that really makes neural nets work so well. And it's hard to replicate that kind of power in a symbolic world. The knowledge in expert systems and so on is nicely decomposed into like a bunch of rules. Whereas if you think about a neural net, it's the opposite. You have this big blob of parameters which work intensely together to represent everything the network knows. And it's not sufficiently factorized. It's not sufficiently factorized. And so I think this is one of the weaknesses of current neural nets, that we have to take lessons from classical AI in order to bring in another kind of compositionality, which is common in language, for example, and in these rules, but that isn't so native to neural nets. And on that line of thinking, disentangled representations. Yes. So let me connect with disentangled representations, if you might, if you don't mind. So for many years, I've thought, and I still believe that it's really important that we come up with learning algorithms, either unsupervised or supervised, but reinforcement, whatever, that build representations in which the important factors, hopefully causal factors are nicely separated and easy to pick up from the representation. So that's the idea of disentangled representations. It says transform the data into a space where everything becomes easy. We can maybe just learn with linear models about the things we care about. And I still think this is important, but I think this is missing out on a very important ingredient, which classical AI systems can remind us of. So let's say we have these disentangled representations. You still need to learn about the relationships between the variables, those high level semantic variables. They're not going to be independent. I mean, this is like too much of an assumption. They're going to have some interesting relationships that allow to predict things in the future, to explain what happened in the past. The kind of knowledge about those relationships in a classical AI system is encoded in the rules. Like a rule is just like a little piece of knowledge that says, oh, I have these two, three, four variables that are linked in this interesting way, then I can say something about one or two of them given a couple of others, right? In addition to disentangling the elements of the representation, which are like the variables in a rule based system, you also need to disentangle the mechanisms that relate those variables to each other. So like the rules. So the rules are neatly separated. Like each rule is, you know, living on its own. And when I change a rule because I'm learning, it doesn't need to break other rules. Whereas current neural nets, for example, are very sensitive to what's called catastrophic forgetting, where after I've learned some things and then I learn new things, they can destroy the old things that I had learned, right? If the knowledge was better factorized and separated, disentangled, then you would avoid a lot of that. Now, you can't do this in the sensory domain. What do you mean by sensory domain? Like in pixel space. But my idea is that when you project the data in the right semantic space, it becomes possible to now represent this extra knowledge beyond the transformation from inputs to representations, which is how representations act on each other and predict the future and so on in a way that can be neatly disentangled. So now it's the rules that are disentangled from each other and not just the variables that are disentangled from each other. And you draw a distinction between semantic space and pixel, like does there need to be an architectural difference? Well, yeah. So there's the sensory space like pixels, which where everything is entangled. The information, like the variables are completely interdependent in very complicated ways. And also computation, like it's not just the variables, it's also how they are related to each other is all intertwined. But I'm hypothesizing that in the right high level representation space, both the variables and how they relate to each other can be disentangled. And that will provide a lot of generalization power. Generalization power. Yes. Distribution of the test set is assumed to be the same as the distribution of the training set. Right. This is where current machine learning is too weak. It doesn't tell us anything, is not able to tell us anything about how our neural nets, say, are going to generalize to a new distribution. And, you know, people may think, well, but there's nothing we can say if we don't know what the new distribution will be. The truth is humans are able to generalize to new distributions. Yeah. How are we able to do that? Yeah. Because there is something, these new distributions, even though they could look very different from the training distributions, they have things in common. So let me give you a concrete example. You read a science fiction novel. The science fiction novel, maybe, you know, brings you in some other planet where things look very different on the surface, but it's still the same laws of physics. And so you can read the book and you understand what's going on. So the distribution is very different. But because you can transport a lot of the knowledge you had from Earth about the underlying cause and effect relationships and physical mechanisms and all that, and maybe even social interactions, you can now make sense of what is going on on this planet where, like, visually, for example, things are totally different. Taking that analogy further and distorting it, let's enter a science fiction world of, say, Space Odyssey, 2001, with Hal. Or maybe, which is probably one of my favorite AI movies. Me too. And then there's another one that a lot of people love that may be a little bit outside of the AI community is Ex Machina. I don't know if you've seen it. Yes. Yes. By the way, what are your views on that movie? Are you able to enjoy it? Are there things I like and things I hate? So you could talk about that in the context of a question I want to ask, which is, there's quite a large community of people from different backgrounds, often outside of AI, who are concerned about existential threat of artificial intelligence. You've seen this community develop over time. You've seen you have a perspective. So what do you think is the best way to talk about AI safety, to think about it, to have discourse about it within AI community and outside and grounded in the fact that Ex Machina is one of the main sources of information for the general public about AI? So I think you're putting it right. There's a big difference between the sort of discussion we ought to have within the AI community and the sort of discussion that really matter in the general public. So I think the picture of Terminator and AI loose and killing people and super intelligence that's going to destroy us, whatever we try, isn't really so useful for the public discussion. Because for the public discussion, the things I believe really matter are the short term and medium term, very likely negative impacts of AI on society, whether it's from security, like, you know, big brother scenarios with face recognition or killer robots, or the impact on the job market, or concentration of power and discrimination, all kinds of social issues, which could actually, some of them could really threaten democracy, for example. Just to clarify, when you said killer robots, you mean autonomous weapon, weapon systems. Yes, I don't mean that's right. So I think these short and medium term concerns should be important parts of the public debate. Now, existential risk, for me is a very unlikely consideration, but still worth academic investigation in the same way that you could say, should we study what could happen if meteorite, you know, came to earth and destroyed it. So I think it's very unlikely that this is going to happen in or happen in a reasonable future. The sort of scenario of an AI getting loose goes against my understanding of at least current machine learning and current neural nets and so on. It's not plausible to me. But of course, I don't have a crystal ball and who knows what AI will be in 50 years from now. So I think it is worth that scientists study those problems. It's just not a pressing question as far as I'm concerned. So before I continue down that line, I have a few questions there. But what do you like and not like about Ex Machina as a movie? Because I actually watched it for the second time and enjoyed it. I hated it the first time, and I enjoyed it quite a bit more the second time when I sort of learned to accept certain pieces of it, see it as a concept movie. What was your experience? What were your thoughts? So the negative is the picture it paints of science is totally wrong. Science in general and AI in particular. Science is not happening in some hidden place by some, you know, really smart guy, one person. This is totally unrealistic. This is not how it happens. Even a team of people in some isolated place will not make it. Science moves by small steps, thanks to the collaboration and community of a large number of people interacting. And all the scientists who are expert in their field kind of know what is going on, even in the industrial labs. It's information flows and leaks and so on. And the spirit of it is very different from the way science is painted in this movie. Yeah, let me ask on that point. It's been the case to this point that kind of even if the research happens inside Google or Facebook, inside companies, it still kind of comes out, ideas come out. Do you think that will always be the case with AI? Is it possible to bottle ideas to the point where there's a set of breakthroughs that go completely undiscovered by the general research community? Do you think that's even possible? It's possible, but it's unlikely. It's not how it is done now. It's not how I can foresee it in the foreseeable future. But of course, I don't have a crystal ball and science is a crystal ball. And so who knows? This is science fiction after all. I think it's ominous that the lights went off during that discussion. So the problem, again, there's one thing is the movie and you could imagine all kinds of science fiction. The problem for me, maybe similar to the question about existential risk, is that this kind of movie paints such a wrong picture of what is the actual science and how it's going on that it can have unfortunate effects on people's understanding of current science. And so that's kind of sad. There's an important principle in research, which is diversity. So in other words, research is exploration. Research is exploration in the space of ideas. And different people will focus on different directions. And this is not just good, it's essential. So I'm totally fine with people exploring directions that are contrary to mine or look orthogonal to mine. I am more than fine. I think it's important. I and my friends don't claim we have universal truth about what will, especially about what will happen in the future. Now that being said, we have our intuitions and then we act accordingly according to where we think we can be most useful and where society has the most to gain or to lose. We should have those debates and not end up in a society where there's only one voice and one way of thinking and research money is spread out. So disagreement is a sign of good research, good science. Yes. The idea of bias in the human sense of bias. How do you think about instilling in machine learning something that's aligned with human values in terms of bias? We intuitively as human beings have a concept of what bias means, of what fundamental respect for other human beings means. But how do we instill that into machine learning systems, do you think? So I think there are short term things that are already happening and then there are long term things that we need to do. In the short term, there are techniques that have been proposed and I think will continue to be improved and maybe alternatives will come up to take data sets in which we know there is bias, we can measure it. Pretty much any data set where humans are being observed taking decisions will have some sort of bias, discrimination against particular groups and so on. And we can use machine learning techniques to try to build predictors, classifiers that are going to be less biased. We can do it, for example, using adversarial methods to make our systems less sensitive to these variables we should not be sensitive to. So these are clear, well defined ways of trying to address the problem. Maybe they have weaknesses and more research is needed and so on. But I think in fact they are sufficiently mature that governments should start regulating companies where it matters, say like insurance companies, so that they use those techniques. Because those techniques will probably reduce the bias but at a cost. For example, maybe their predictions will be less accurate and so companies will not do it until you force them. All right, so this is short term. Long term, I'm really interested in thinking how we can instill moral values into computers. Obviously, this is not something we'll achieve in the next five or 10 years. How can we, you know, there's already work in detecting emotions, for example, in images, in sounds, in texts, and also studying how different agents interacting in different ways may correspond to patterns of, say, injustice, which could trigger anger. So these are things we can do in the medium term and eventually train computers to model, for example, how humans react emotionally. I would say the simplest thing is unfair situations which trigger anger. This is one of the most basic emotions that we share with other animals. I think it's quite feasible within the next few years that we can build systems that can detect these kinds of things to the extent, unfortunately, that they understand enough about the world around us, which is a long time away. But maybe we can initially do this in virtual environments. So you can imagine a video game where agents interact in some ways and then some situations trigger an emotion. I think we could train machines to detect those situations and predict that the particular emotion will likely be felt if a human was playing one of the characters. You have shown excitement and done a lot of excellent work with unsupervised learning. But there's been a lot of success on the supervised learning side. Yes, yes. And one of the things I'm really passionate about is how humans and robots work together. And in the context of supervised learning, that means the process of annotation. Do you think about the problem of annotation put in a more interesting way as humans teaching machines? Yes. Is there? Yes. I think it's an important subject. Reducing it to annotation may be useful for somebody building a system tomorrow. But longer term, the process of teaching, I think, is something that deserves a lot more attention from the machine learning community. So there are people who have coined the term machine teaching. So what are good strategies for teaching a learning agent? And can we design and train a system that is going to be a good teacher? So in my group, we have a project called BBI or BBI game, where there is a game or scenario where there's a learning agent and a teaching agent. Presumably, the teaching agent would eventually be a human. But we're not there yet. And the role of the teacher is to use its knowledge of the environment, which it can acquire using whatever way brute force to help the learner learn as quickly as possible. So the learner is going to try to learn by itself, maybe using some exploration and whatever. But the teacher can choose, can have an influence on the interaction with the learner, so as to guide the learner, maybe teach it the things that the learner has most trouble with, or just add the boundary between what it knows and doesn't know, and so on. So there's a tradition of these kind of ideas from other fields and like tutorial systems, for example, and AI. And of course, people in the humanities have been thinking about these questions. But I think it's time that machine learning people look at this, because in the future, we'll have more and more human machine interaction with the human in the loop. And I think understanding how to make this work better, all the problems around that are very interesting and not sufficiently addressed. You've done a lot of work with language, too. What aspect of the traditionally formulated Turing test, a test of natural language understanding and generation in your eyes is the most difficult of conversation? What in your eyes is the hardest part of conversation to solve for machines? So I would say it's everything having to do with the non linguistic knowledge, which implicitly you need in order to make sense of sentences, things like the Winograd schema. So these sentences that are semantically ambiguous. In other words, you need to understand enough about the world in order to really interpret properly those sentences. I think these are interesting challenges for machine learning, because they point in the direction of building systems that both understand how the world works and this causal relationships in the world and associate that knowledge with how to express it in language, either for reading or writing. You speak French? Yes, it's my mother tongue. It's one of the romance languages. Do you think passing the Turing test and all the underlying challenges we just mentioned depend on language? Do you think it might be easier in French than it is in English, or is independent of language? I think it's independent of language. I would like to build systems that can use the same principles, the same learning mechanisms to learn from human agents, whatever their language. Well, certainly us humans can talk more beautifully and smoothly in poetry, some Russian originally. I know poetry in Russian is maybe easier to convey complex ideas than it is in English. But maybe I'm showing my bias and some people could say that about French. But of course, the goal ultimately is our human brain is able to utilize any kind of those languages to use them as tools to convey meaning. Yeah, of course, there are differences between languages, and maybe some are slightly better at some things, but in the grand scheme of things, where we're trying to understand how the brain works and language and so on, I think these differences are minute. So you've lived perhaps through an AI winter of sorts? Yes. How did you stay warm and continue your research? Stay warm with friends. With friends. Okay, so it's important to have friends. And what have you learned from the experience? Listen to your inner voice. Don't, you know, be trying to just please the crowds and the fashion. And if you have a strong intuition about something that is not contradicted by actual evidence, go for it. I mean, it could be contradicted by people. Not your own instinct of based on everything you've learned? Of course, you have to adapt your beliefs when your experiments contradict those beliefs. But you have to stick to your beliefs. Otherwise, it's what allowed me to go through those years. It's what allowed me to persist in directions that, you know, took time, whatever other people think, took time to mature and bring fruits. So history of AI is marked with these, of course, it's marked with technical breakthroughs, but it's also marked with these seminal events that capture the imagination of the community. Most recent, I would say, AlphaGo beating the world champion human Go player was one of those moments. What do you think the next such moment might be? Okay, so first of all, I think that these so called seminal events are overrated. As I said, science really moves by small steps. Now what happens is you make one more small step and it's like the drop that, you know, that fills the bucket and then you have drastic consequences because now you're able to do something you were not able to do before. Or now, say, the cost of building some device or solving a problem becomes cheaper than what existed and you have a new market that opens up, right? So especially in the world of commerce and applications, the impact of a small scientific progress could be huge. But in the science itself, I think it's very, very gradual. And where are these steps being taken now? So there's unsupervised learning. So if I look at one trend that I like in my community, so for example, at Milan, my institute, what are the two hardest topics? GANs and reinforcement learning. Even though in Montreal in particular, reinforcement learning was something pretty much absent just two or three years ago. So there's really a big interest from students and there's a big interest from people like me. So I would say this is something where we're going to see more progress, even though it hasn't yet provided much in terms of actual industrial fallout. Like even though there's AlphaGo, there's no, like Google is not making money on this right now. But I think over the long term, this is really, really important for many reasons. So in other words, I would say reinforcement learning may be more generally agent learning because it doesn't have to be with rewards. It could be in all kinds of ways that an agent is learning about its environment. Now reinforcement learning you're excited about, do you think GANs could provide something, at the moment? Well, GANs or other generative models, I believe, will be crucial ingredients in building agents that can understand the world. A lot of the successes in reinforcement learning in the past has been with policy gradient, where you just learn a policy, you don't actually learn a model of the world. But there are lots of issues with that. And we don't know how to do model based RL right now. But I think this is where we have to go in order to build models that can generalize faster and better like to new distributions that capture to some extent, at least the underlying causal mechanisms in the world. Last question. What made you fall in love with artificial intelligence? If you look back, what was the first moment in your life when you were fascinated by either the human mind or the artificial mind? You know, when I was an adolescent, I was reading a lot. And then I started reading science fiction. There you go. That's it. That's where I got hooked. And then, you know, I had one of the first personal computers and I got hooked in programming. And so it just, you know, Start with fiction and then make it a reality. That's right. Yoshua, thank you so much for talking to me. My pleasure.",difference biological neural network artificial neural network mysterious captivating profound know biological neural network mysterious captivate maybe hold key improve artificial neural network thing study recently know biological neural network useful artificial one ability credit assignment long time span thing principle artificial neural net convenient biologically plausible mismatch think kind mismatch interesting thing study understand well brain thing good corresponding theory artificial neural net b maybe provide new idea explore thing brain differently incorporate artificial neural net let break credit assignment little bit yes beautifully technical term incorporate thing rnn memory think like knowledge build common sense knowledge time reinforcement learning sense pick reward time particular achieve certain kind goal think meaning store kind memory episodic memory brain access later order help infer cause thing observe assign credit decision interpretation come ago memory store change way react interpret thing past credit assignment learn way think artificial neural network current lstm current architecture able capture presumably think long term yes current current net fairly good job sequence dozen hundred time step get hard hard depend remember consider long duration human able credit assignment essentially arbitrary time like remember year new evidence go change mind way think year hopefully mistake think big probably forget remember important thing efficient forgetting yes selection remember think cool connection high level cognition consciousness decide emotion decide come consciousness get store memory trivial forefront show amazing thing neural network deep neural network field artificial intelligence broadly kind application talk forever view think future weak aspect way deep neural network represent world view miss current state art neural net train large quantity image text level understanding know explain datum set basic low level nearly robust abstract general understanding okay tell fix thing think encourage think maybe train neural net differently focus example causal explanation currently neural net training thing talk talk afternoon fact instead learn separately image video hand text hand need well job jointly learn language world refer know side help need good world model neural net understand sentence talk go world think need language input help provide clue high level concept like semantic concept represent level neural net fact evidence purely unsupervised learning representation rise high level representation powerful one get supervised learning clue get label sentence high level think important thing mind powerful think architecture challenge data set challenge tempt end elaborate slightly course datum set architecture want play think crucial thing training objective training framework example go passive observation datum active agent learn intervene world relationship cause effect sort objective function important allow high level explanation rise learning think kind objective function reward exploration right kind exploration kind question datum set architecture learn objective yeah hear mention context idea sort way child learn interact object world fascinating sense case reinforcement learning idea learning process artificial neural network like envision like objective function say know poke object kind way helpful learn right right sort guide aspect learning right right right talk rebecca sack minute ago talk lot lot evidence infant clearly pick interest directed way passive learner focus attention aspect world interesting surprising non trivial way make change theory world fascinating view future progress maybe boring question think go deeply large think increase size thing increase lot past year go big thing think increase size thing increase lot past year significant progress representational issue mention kind shallow sense oh shallow sense abstraction sense abstraction get think have depth network sense instead layer go layer think obvious yes clear engineer company labs grad student continue tune architecture explore kind tweak current state art slightly slightly well think go nearly think need change way consider learn achieve goal learner actually understand deep way environment know observe act guess try ask question interesting layer basically figure way learn interact parameter take store information think brain big neural network right right oh mean oh agree order build neural net kind broad knowledge world typical adult human probably kind computing power go insufficient good news hardware company build neural net chip go well good news way bad news state art deep learning method fail learn model understand simple environment like grid world build fairly simple environment mean course train example eventually like instead human need dozen example thing need million simple task think opportunity academic kind compute power google important exciting research advance state art training framework learn model agent learn simple environment synthetic trivial current machine learning fail talk prior common sense knowledge like human lot knowledge grant view prior form broad view world accumulation information teach neural network learn system pick knowledge knowledge artificial intelligence maybe like time knowledge representation knowledge acquisition expert system mean symbolic ai view interesting problem set solve kind hold little bit like work work right right goal remain important yes remain important think goal address right believe reason classical expert system approach fail lot knowledge talk common sense intuition lot knowledge like consciously accessible lot decision take explain story knowledge necessary machine good decision knowledge hard codify expert system rule base system classical ai formalism issue course old ai like good way handle uncertainty subtle understand well think mind people powerful come distribute representation thing make neural net work hard replicate kind power symbolic world knowledge expert system nicely decompose like bunch rule think neural net opposite big blob parameter work intensely represent network know sufficiently factorize sufficiently factorize think weakness current neural net lesson classical ai order bring kind compositionality common language example rule native neural net line thinking disentangle representation yes let connect disentangle representation mind year think believe important come learning algorithm unsupervise supervised reinforcement build representation important factor hopefully causal factor nicely separate easy pick representation idea disentangle representation say transform datum space easy maybe learn linear model thing care think important think miss important ingredient classical ai system remind let disentangle representation need learn relationship variable high level semantic variable go independent mean like assumption go interesting relationship allow predict thing future explain happen past kind knowledge relationship classical ai system encode rule like rule like little piece knowledge say oh variable link interesting way give couple right addition disentangle element representation like variable rule base system need disentangle mechanism relate variable like rule rule neatly separate like rule know live change rule learn need break rule current neural net example sensitive call catastrophic forgetting learn thing learn new thing destroy old thing learn right knowledge well factorize separate disentangle avoid lot sensory domain mean sensory domain like pixel space idea project datum right semantic space possible represent extra knowledge transformation input representation representation act predict future way neatly disentangle rule disentangle variable disentangle draw distinction semantic space pixel like need architectural difference yeah sensory space like pixel entangle information like variable completely interdependent complicated way computation like variable related intertwine hypothesize right high level representation space variable relate disentangle provide lot generalization power generalization power yes distribution test set assume distribution training set right current machine learning weak tell able tell neural net go generalize new distribution know people think know new distribution truth human able generalize new distribution yeah able yeah new distribution look different training distribution thing common let concrete example read science fiction novel science fiction novel maybe know bring planet thing look different surface law physic read book understand go distribution different transport lot knowledge earth underlying cause effect relationship physical mechanism maybe social interaction sense go planet like visually example thing totally different take analogy distort let enter science fiction world space odyssey hal maybe probably favorite ai movie lot people love little bit outside ai community ex machina know see yes yes way view movie able enjoy thing like thing hate talk context question want ask large community people different background outside ai concerned existential threat artificial intelligence see community develop time see perspective think good way talk ai safety think discourse ai community outside ground fact ex machina main source information general public ai think put right big difference sort discussion ought ai community sort discussion matter general public think picture terminator ai loose kill people super intelligence go destroy try useful public discussion public discussion thing believe matter short term medium term likely negative impact ai society security like know big brother scenario face recognition killer robot impact job market concentration power discrimination kind social issue actually threaten democracy example clarify say killer robot mean autonomous weapon weapon system yes mean right think short medium term concern important part public debate existential risk unlikely consideration worth academic investigation way study happen meteorite know come earth destroy think unlikely go happen happen reasonable future sort scenario ai get loose go understanding current machine learning current neural net plausible course crystal ball know ai year think worth scientist study problem press question far concern continue line question like like ex machina movie actually watch second time enjoy hate time enjoy bit second time sort learn accept certain piece concept movie experience thought negative picture paint science totally wrong science general ai particular science happen hide place know smart guy person totally unrealistic happen team people isolated place science move small step thank collaboration community large number people interact scientist expert field kind know go industrial lab information flow leak spirit different way science paint movie yeah let ask point case point kind research happen inside google facebook inside company kind come idea come think case ai possible bottle idea point set breakthrough completely undiscovered general research community think possible possible unlikely foresee foreseeable future course crystal ball science crystal ball know science fiction think ominous light go discussion problem thing movie imagine kind science fiction problem maybe similar question existential risk kind movie paint wrong picture actual science go unfortunate effect people understanding current science kind sad important principle research diversity word research exploration research exploration space idea different people focus different direction good essential totally fine people explore direction contrary look orthogonal fine think important friend claim universal truth especially happen future say intuition act accordingly accord think useful society gain lose debate end society voice way thinking research money spread disagreement sign good research good science yes idea bias human sense bias think instill machine learn align human value term bias intuitively human being concept bias mean fundamental respect human being mean instill machine learning system think think short term thing happen long term thing need short term technique propose think continue improve maybe alternative come data set know bias measure pretty datum set human observe take decision sort bias discrimination particular group use machine learn technique try build predictor classifier go biased example adversarial method system sensitive variable sensitive clear define way try address problem maybe weakness research need think fact sufficiently mature government start regulate company matter like insurance company use technique technique probably reduce bias cost example maybe prediction accurate company force right short term long term interested think instill moral value computer obviously achieve year know work detect emotion example image sound text study different agent interact different way correspond pattern injustice trigger anger thing medium term eventually train computer model example human react emotionally simple thing unfair situation trigger anger basic emotion share animal think feasible year build system detect kind thing extent unfortunately understand world long time away maybe initially virtual environment imagine video game agent interact way situation trigger emotion think train machine detect situation predict particular emotion likely feel human play character show excitement lot excellent work unsupervised learning lot success supervised learning yes yes thing passionate human robot work context supervised learning mean process annotation think problem annotation interesting way human teach machine yes yes think important subject reduce annotation useful somebody build system tomorrow long term process teaching think deserve lot attention machine learn community people coin term machine teaching good strategy teach learning agent design train system go good teacher group project call bbi bbi game game scenario learn agent teaching agent presumably teaching agent eventually human role teacher use knowledge environment acquire way brute force help learner learn quickly possible learner go try learn maybe exploration teacher choose influence interaction learner guide learner maybe teach thing learner trouble add boundary know know tradition kind idea field like tutorial system example ai course people humanity think question think time machine learn people look future human machine interaction human loop think understand work well problem interesting sufficiently address lot work language aspect traditionally formulated turing test test natural language understanding generation eye difficult conversation eye hard conversation solve machine have non linguistic knowledge implicitly need order sense sentence thing like winograd schema sentence semantically ambiguous word need understand world order interpret properly sentence think interesting challenge machine learning point direction building system understand world work causal relationship world associate knowledge express language reading writing speak french yes mother tongue romance language think pass ture test underlying challenge mention depend language think easy french english independent language think independent language like build system use principle learning mechanism learn human agent language certainly human talk beautifully smoothly poetry russian originally know poetry russian maybe easy convey complex idea english maybe show bias people french course goal ultimately human brain able utilize kind language use tool convey meaning yeah course difference language maybe slightly well thing grand scheme thing try understand brain work language think difference minute live ai winter sort yes stay warm continue research stay warm friend friend okay important friend learn experience listen inner voice know try crowd fashion strong intuition contradict actual evidence mean contradict people instinct base learn course adapt belief experiment contradict belief stick belief allow year allow persist direction know take time people think take time mature bring fruit history ai mark course mark technical breakthrough mark seminal event capture imagination community recent alphago beat world champion human player moment think moment okay think call seminal event overrate say science move small step happen small step like drop know fill bucket drastic consequence able able cost build device solve problem cheap exist new market open right especially world commerce application impact small scientific progress huge science think gradual step take unsupervised learning look trend like community example milan institute hard topic gan reinforcement learning montreal particular reinforcement learning pretty absent year ago big interest student big interest people like go progress provide term actual industrial fallout like alphago like google make money right think long term important reason word reinforcement learning generally agent learning reward kind way agent learn environment reinforcement learn excited think gan provide moment gan generative model believe crucial ingredient build agent understand world lot success reinforcement learning past policy gradient learn policy actually learn model world lot issue know model base rl right think order build model generalize fast well like new distribution capture extent underlie causal mechanism world question fall love artificial intelligence look moment life fascinate human mind artificial mind know adolescent read lot start read science fiction get hook know personal computer get hook programming know start fiction reality right yoshua thank talk pleasure,"['Rebecca Sacks', 'Ex Machina']","['MILA', 'Google', 'Facebook AI Research']","['Deep Neural Networks', 'Convolutional Neural Networks', 'Recurrent Neural Networks', 'TensorFlow', 'PyTorch']","['Deep Learning', 'Machine Learning Fundamentals', 'Natural Language Processing', 'Artificial General Intelligence (AGI)', 'AI in Business and Industry']"
5,Vladimir Vapnik,Statistical Learning,"The following is a conversation with Vladimir Vapnik. He's the co inventor of support vector machines, support vector clustering, VC theory, and many foundational ideas in statistical learning. He was born in the Soviet Union and worked at the Institute of Control Sciences in Moscow. Then in the United States, he worked at AT&T, NEC Labs, Facebook Research, and now is a professor at Columbia University. His work has been cited over 170,000 times. He has some very interesting ideas about artificial intelligence and the nature of learning, especially on the limits of our current approaches and the open problems in the field. This conversation is part of MIT course on artificial general intelligence and the artificial intelligence podcast. If you enjoy it, please subscribe on YouTube or rate it on iTunes or your podcast provider of choice, or simply connect with me on Twitter or other social networks at Lex Friedman spelled F R I D. And now here's my conversation with Vladimir Vapnik. Einstein famously said that God doesn't play dice. Yeah. You have studied the world through the eyes of statistics. So let me ask you in terms of the nature of reality, fundamental nature of reality, does God play dice? We don't know some factors. And because we don't know some factors, which could be important, it looks like God plays dice. But we should describe it. In philosophy, they distinguish between two positions, positions of instrumentalism, where you're creating theory for prediction and position of realism, where you're trying to understand what God did. Can you describe instrumentalism and realism a little bit? For example, if you have some mechanical laws, what is that? Is it law which is true always and everywhere? Or it is law which allow you to predict position of moving element? What you believe. You believe that it is God's law, that God created the world, which obey to this physical law. Or it is just law for predictions. And which one is instrumentalism? For predictions. If you believe that this is law of God, and it's always true everywhere, that means that you're realist. So you're trying to really understand God's thought. So the way you see the world is as an instrumentalist? You know, I'm working for some models, model of machine learning. So in this model, we can see setting, and we try to solve, resolve the setting to solve the problem. And you can do in two different way. From the point of view of instrumentalist, and that's what everybody does now. Because they say that goal of machine learning is to find the rule for classification. That is true. But it is instrument for prediction. But I can say the goal of machine learning is to learn about conditional probability. So how God played use, and if he play, what is probability for one, what is probability for another, given situation. But for prediction, I don't need this. I need the rule. But for understanding, I need conditional probability. So let me just step back a little bit first to talk about, you mentioned, which I read last night, the parts of the 1960 paper by Eugene Wigner, Unreasonable Effectiveness of Mathematics and Natural Sciences. Such a beautiful paper, by the way. Made me feel, to be honest, to confess my own work in the past few years on deep learning, heavily applied. Made me feel that I was missing out on some of the beauty of nature in the way that math can uncover. So let me just step away from the poetry of that for a second. How do you see the role of math in your life? Is it a tool, is it poetry? Where does it sit? And does math for you have limits of what it can describe? Some people say that math is language which use God. Use God. So I believe that... Speak to God or use God or... Use God. Use God. Yeah. So I believe that this article about effectiveness, unreasonable effectiveness of math, is that if you're looking at mathematical structures, they know something about reality. And the most scientists from Natural Science, they're looking on equation and trying to understand reality. So the same in machine learning. If you try very carefully look on all equations which define conditional probability, you can understand something about reality more than from your fantasy. So math can reveal the simple underlying principles of reality perhaps. You know what means simple? It is very hard to discover them. But then when you discover them and look at them, you see how beautiful they are. And it is surprising why people did not see that before. You're looking on equation and derive it from equations. For example, I talked yesterday about least square method. And people had a lot of fantasy how to improve least square method. But if you're going step by step by solving some equations, you suddenly will get some term which after thinking, you understand that it describes position of observation point. In least square method, we throw out a lot of information. We don't look in composition of point of observations, we're looking only on residuals. But when you understood that, that's very simple idea, but it's not too simple to understand. And you can derive this just from equations. So some simple algebra, a few steps will take you to something surprising that when you think about, you understand. And that is proof that human intuition is not too rich and very primitive. And it does not see very simple situations. So let me take a step back. In general, yes. But what about human, as opposed to intuition, ingenuity? Moments of brilliance. Do you have to be so hard on human intuition? Are there moments of brilliance in human intuition? They can leap ahead of math and then the math will catch up? I don't think so. I think that the best human intuition, it is putting in axioms. And then it is technical. See where the axioms take you. But if they correctly take axioms. But it axiom polished during generations of scientists. And this is integral wisdom. That is beautifully put. But if you maybe look at, when you think of Einstein and special relativity, what is the role of imagination coming first there in the moment of discovery of an idea? So there is obviously a mix of math and out of the box imagination there. That I don't know. Whatever I did, I exclude any imagination. Because whatever I saw in machine learning that comes from imagination, like features, like deep learning, they are not relevant to the problem. When you are looking very carefully from mathematical equations, you are deriving very simple theory, which goes far beyond theoretically than whatever people can imagine. Because it is not good fantasy. It is just interpretation. It is just fantasy. But it is not what you need. You don't need any imagination to derive the main principle of machine learning. When you think about learning and intelligence, maybe thinking about the human brain and trying to describe mathematically the process of learning, that is something like what happens in the human brain. Do you think we have the tools currently? Do you think we will ever have the tools to try to describe that process of learning? It is not description what is going on. It is interpretation. It is your interpretation. Your vision can be wrong. You know, one guy invented microscope, Levenhuk, for the first time. Only he got this instrument and he kept secret about microscope. But he wrote a report in London Academy of Science. In his report, when he was looking at the blood, he looked everywhere, on the water, on the blood, on the sperm. But he described blood like fight between queen and king. So, he saw blood cells, red cells, and he imagined that it is army fighting each other. And it was his interpretation of situation. And he sent this report in Academy of Science. They very carefully looked because they believed that he is right. He saw something. Yes. But he gave wrong interpretation. And I believe the same can happen with brain. With brain, yeah. The most important part. You know, I believe in human language. In some proverbs, there is so much wisdom. For example, people say that it is better than thousand days of diligent studies one day with great teacher. But if I will ask you what teacher does, nobody knows. And that is intelligence. But we know from history and now from math and machine learning that teacher can do a lot. So, what from a mathematical point of view is the great teacher? I don't know. That's an open question. No, but we can say what teacher can do. He can introduce some invariants, some predicate for creating invariants. How he doing it? I don't know because teacher knows reality and can describe from this reality a predicate, invariants. But he knows that when you're using invariant, you can decrease number of observations hundred times. So, but maybe try to pull that apart a little bit. I think you mentioned like a piano teacher saying to the student, play like a butterfly. Yeah. I play piano. I play guitar for a long time. Yeah, maybe it's romantic, poetic, but it feels like there's a lot of truth in that statement. Like there is a lot of instruction in that statement. And so, can you pull that apart? What is that? The language itself may not contain this information. It is not blah, blah, blah. It is not blah, blah, blah. It affects you. It's what? It affects you. It affects your playing. Yes, it does, but it's not the laying. It feels like what is the information being exchanged there? What is the nature of information? What is the representation of that information? I believe that it is sort of predicate, but I don't know. That is exactly what intelligence and machine learning should be. Yes. Because the rest is just mathematical technique. I think that what was discovered recently is that there is two mechanism of learning. One called strong convergence mechanism and weak convergence mechanism. Before, people use only one convergence. In weak convergence mechanism, you can use predicate. That's what play like butterfly and it will immediately affect your playing. You know, there is English proverb, great. If it looks like a duck, swims like a duck, and quack like a duck, then it is probably duck. Yes. But this is exact about predicate. Looks like a duck, what it means. You saw many ducks that you're training data. So, you have description of how looks integral looks ducks. Yeah. The visual characteristics of a duck. Yeah. But you want and you have model for recognition. So, you would like so that theoretical description from model coincide with empirical description, which you saw on territory. So, about looks like a duck, it is general. But what about swims like a duck? You should know that duck swims. You can say it play chess like a duck. Okay. Duck doesn't play chess. And it is completely legal predicate, but it is useless. So, half teacher can recognize not useless predicate. So, up to now, we don't use this predicate in existing machine learning. So, why we need zillions of data. But in this English proverb, they use only three predicate. Looks like a duck, swims like a duck, and quack like a duck. So, you can't deny the fact that swims like a duck and quacks like a duck has humor in it, has ambiguity. Let's talk about swim like a duck. It doesn't say jump like a duck. Why? Because... It's not relevant. But that means that you know ducks, you know different birds, you know animals. And you derive from this that it is relevant to say swim like a duck. So, underneath, in order for us to understand swims like a duck, it feels like we need to know millions of other little pieces of information. Which we pick up along the way. You don't think so. There doesn't need to be this knowledge base in those statements carries some rich information that helps us understand the essence of duck. Yeah. How far are we from integrating predicates? You know that when you consider complete theory of machine learning. So, what it does, you have a lot of functions. And then you're talking it looks like a duck. You see your training data. From training data you recognize like expected duck should look. Then you remove all functions which does not look like you think it should look from training data. So, you decrease amount of function from which you pick up one. Then you give a second predicate and again decrease the set of function. And after that you pick up the best function you can find. It is standard machine learning. So, why you need not too many examples? Because your predicates aren't very good? That means that predicates are very good because every predicate is invented to decrease admissible set of function. So, you talk about admissible set of functions and you talk about good functions. So, what makes a good function? So, admissible set of function is set of function which has small capacity or small diversity, small VC dimension example. Which contain good function inside. So, by the way for people who don't know VC, you're the V in the VC. So, how would you describe to lay person what VC theory is? How would you describe VC? So, when you have a machine. So, machine capable to pick up one function from the admissible set of function. But set of admissible function can be big. So, it contain all continuous functions and it's useless. You don't have so many examples to pick up function. But it can be small. Small, we call it capacity but maybe better called diversity. So, not very different function in the set. It's infinite set of function but not very diverse. So, it is small VC dimension. When VC dimension is small, you need small amount of training data. So, the goal is to create admissible set of functions which is have small VC dimension and contain good function. Then you will be able to pick up the function using small amount of observations. So, that is the task of learning? Yeah. Is creating a set of admissible functions that has a small VC dimension and then you've figure out a clever way of picking up? No, that is goal of learning which I formulated yesterday. Statistical learning theory does not involve in creating admissible set of function. In classical learning theory, everywhere, 100% in textbook, the set of function, admissible set of function is given. But this is science about nothing because the most difficult problem to create admissible set of functions given, say, a lot of functions, continuum set of function, create admissible set of functions. That means that it has finite VC dimension, small VC dimension and contain good function. So, this was out of consideration. So, what's the process of doing that? I mean, it's fascinating. What is the process of creating this admissible set of functions? That is invariant. That's invariant. Yeah, you're looking of properties of training data and properties means that you have some function and you just count what is value, average value of function on training data. You have model and what is expectation of this function on the model and they should coincide. So, the problem is about how to pick up functions. It can be any function. In fact, it is true for all functions. But because when we're talking, say, duck does not jumping, so you don't ask question jump like a duck because it is trivial. It does not jumping and doesn't help you to recognize jump. But you know something, which question to ask and you're asking it seems like a duck, but looks like a duck at this general situation. Looks like, say, guy who have this illness, this disease. It is legal. So, there is a general type of predicate looks like and special type of predicate, which related to this specific problem. And that is intelligence part of all this business and that where teacher is involved. Incorporating the specialized predicates. What do you think about deep learning as neural networks, these arbitrary architectures as helping accomplish some of the tasks you're thinking about? Their effectiveness or lack thereof? What are the weaknesses and what are the possible strengths? You know, I think that this is fantasy, everything which like deep learning, like features. Let me give you this example. One of the greatest books is Churchill book about history of Second World War. And he started this book describing that in old time when war is over, so the great kings, they gathered together, almost all of them were relatives, and they discussed what should be done, how to create peace. And they came to agreement. And when happened First World War, the general public came in power. And they were so greedy that robbed Germany. And it was clear for everybody that it is not peace, that peace will last only 20 years because they were not professionals. And the same I see in machine learning. There are mathematicians who are looking for the problem from a very deep point of view, mathematical point of view. And there are computer scientists who mostly does not know mathematics. They just have interpretation of that. And they invented a lot of blah, blah, blah interpretations like deep learning. Why you need deep learning? Mathematic does not know deep learning. Mathematic does not know neurons. It is just function. If you like to say piecewise linear function, say that and do in class of piecewise linear function. But they invent something. And then they try to prove advantage of that through interpretations, which mostly wrong. And when it's not enough, they appeal to brain, which they know nothing about that. Nobody knows what's going on in the brain. So, I think that more reliable work on math. This is a mathematical problem. Do your best to solve this problem. Try to understand that there is not only one way of convergence, which is strong way of convergence. There is a weak way of convergence, which requires predicate. And if you will go through all this stuff, you will see that you don't need deep learning. Even more, I would say one of the theory, which called represented theory. It says that optimal solution of mathematical problem, which is described learning is on shadow network, not on deep learning. And a shallow network. Yeah. The ultimate problem is there. Absolutely. In the end, what you're saying is exactly right. The question is you have no value for throwing something on the table, playing with it, not math. It's like a neural network where you said throwing something in the bucket or the biological example and looking at kings and queens or the cells or the microscope. You don't see value in imagining the cells or kings and queens and using that as inspiration and imagination for where the math will eventually lead you. You think that interpretation basically deceives you in a way that's not productive. I think that if you're trying to analyze this business of learning and especially discussion about deep learning, it is discussion about interpretation, not about things, about what you can say about things. That's right. But aren't you surprised by the beauty of it? So not mathematical beauty, but the fact that it works at all or are you criticizing that very beauty, our human desire to interpret, to find our silly interpretations in these constructs? Let me ask you this. Are you surprised and does it inspire you? How do you feel about the success of a system like AlphaGo at beating the game of Go? Using neural networks to estimate the quality of a board and the quality of the position. That is your interpretation, quality of the board. Yeah, yes. Yeah. So it's not our interpretation. The fact is a neural network system, it doesn't matter, a learning system that we don't I think mathematically understand that well, beats the best human player, does something that was thought impossible. That means that it's not a very difficult problem. So you empirically, we've empirically have discovered that this is not a very difficult problem. Yeah. It's true. So maybe, can't argue. So even more I would say that if they use deep learning, it is not the most effective way of learning theory. And usually when people use deep learning, they're using zillions of training data. Yeah. But you don't need this. So I describe challenge, can we do some problems which do well deep learning method, this deep net, using hundred times less training data. Even more, some problems deep learning cannot solve because it's not necessary they create admissible set of function. To create deep architecture means to create admissible set of functions. You cannot say that you're creating good admissible set of functions. You just, it's your fantasy. It does not come from us. But it is possible to create admissible set of functions because you have your training data. That actually for mathematicians, when you consider a variant, you need to use law of large numbers. When you're making training in existing algorithm, you need uniform law of large numbers, which is much more difficult, it requires VC dimension and all this stuff. But nevertheless, if you use both weak and strong way of convergence, you can decrease a lot of training data. You could do the three, the swims like a duck and quacks like a duck. So let's step back and think about human intelligence in general. Clearly that has evolved in a non mathematical way. It wasn't, as far as we know, God or whoever didn't come up with a model and place in our brain of admissible functions. It kind of evolved. I don't know, maybe you have a view on this. So Alan Turing in the 50s, in his paper, asked and rejected the question, can machines think? It's not a very useful question, but can you briefly entertain this useful, useless question? Can machines think? So talk about intelligence and your view of it. I don't know that. I know that Turing described imitation. If computer can imitate human being, let's call it intelligent. And he understands that it is not thinking computer. He completely understands what he's doing. But he set up problem of imitation. So now we understand that the problem is not in imitation. I'm not sure that intelligence is just inside of us. It may be also outside of us. I have several observations. So when I prove some theorem, it's very difficult theorem, in couple of years, in several places, people prove the same theorem, say, Sawyer Lemma, after us was done, then another guys proved the same theorem. In the history of science, it's happened all the time. For example, geometry, it's happened simultaneously, first it did Lobachevsky and then Gauss and Boyai and another guys, and it's approximately in 10 times period, 10 years period of time. And I saw a lot of examples like that. And many mathematicians think that when they develop something, they develop something in general which affect everybody. So maybe our model that intelligence is only inside of us is incorrect. It's our interpretation. It might be there exists some connection with world intelligence. I don't know. You're almost like plugging in into... Yeah, exactly. And contributing to this... Into a big network. Into a big, maybe in your own network. On the flip side of that, maybe you can comment on big O complexity and how you see classifying algorithms by worst case running time in relation to their input. So that way of thinking about functions, do you think p equals np, do you think that's an interesting question? Yeah, it is an interesting question. But let me talk about complexity in about worst case scenario. There is a mathematical setting. When I came to United States in 1990, people did not know, they did not know statistical learning theory. So in Russia, it was published to monographs, our monographs, but in America they didn't know. Then they learned and somebody told me that it is worst case theory and they will create real case theory, but till now it did not. Because it is mathematical too. You can do only what you can do using mathematics. And which has a clear understanding and clear description. And for this reason, we introduce complexity. And we need this because using, actually it is diversity, I like this one more. You see the mention, you can prove some theorems. But we also create theory for case when you know probability measure. And that is the best case which can happen, it is entropy theory. So from mathematical point of view, you know the best possible case and the worst possible case. You can derive different model in medium, but it's not so interesting. You think the edges are interesting? The edges are interesting because it is not so easy to get good bound, exact bound. It's not many cases where you have the bound is not exact. But interesting principles which discover the mass. Do you think it's interesting because it's challenging and reveals interesting principles that allow you to get those bounds? Or do you think it's interesting because it's actually very useful for understanding the essence of a function of an algorithm? So it's like me judging your life as a human being by the worst thing you did and the best thing you did versus all the stuff in the middle. It seems not productive. I don't think so because you cannot describe situation in the middle. So it will be not general. So you can describe edges cases and it is clear it has some model, but you cannot describe model for every new case. So you will be never accurate when you're using model. But from a statistical point of view, the way you've studied functions and the nature of learning in the world, don't you think that the real world has a very long tail? That the edge cases are very far away from the mean, the stuff in the middle or no? I don't know that. I think that from my point of view, if you will use formal statistic, you need uniform law of large numbers. If you will use this invariance business, you will need just law of large numbers. And there's this huge difference between uniform law of large numbers and large numbers. Is it useful to describe that a little more or should we just take it to... For example, when I'm talking about duck, I give three predicates and that was enough. But if you will try to do formal distinguish, you will need a lot of observations. So that means that information about looks like a duck contain a lot of bit of information, formal bits of information. So we don't know that how much bit of information contain things from artificial and from intelligence. And that is the subject of analysis. Till now, all business, I don't like how people consider artificial intelligence. They consider us some codes which imitate activity of human being. It is not science, it is applications. You would like to imitate go ahead, it is very useful and a good problem. But you need to learn something more. How people try to do, how people can to develop, say, predicates seems like a duck or play like butterfly or something like that. Not the teacher says you, how it came in his mind, how he choose this image. So that process... That is problem of intelligence. That is the problem of intelligence and you see that connected to the problem of learning? Absolutely. Because you immediately give this predicate like specific predicate seems like a duck or quack like a duck. It was chosen somehow. So what is the line of work, would you say? If you were to formulate as a set of open problems, that will take us there, to play like a butterfly. We'll get a system to be able to... Let's separate two stories. One mathematical story that if you have predicate, you can do something. And another story how to get predicate. It is intelligence problem and people even did not start to understand intelligence. Because to understand intelligence, first of all, try to understand what do teachers. How teacher teach, why one teacher better than another one. Yeah. And so you think we really even haven't started on the journey of generating the predicates? No. We don't understand. We even don't understand that this problem exists. Because did you hear... You do. No, I just know name. I want to understand why one teacher better than another and how affect teacher, student. It is not because he repeating the problem which is in textbook. He makes some remarks. He makes some philosophy of reasoning. Yeah, that's a beautiful... So it is a formulation of a question that is the open problem. Why is one teacher better than another? Right. What he does better. Yeah. What... What... Why in... At every level? How do they get better? What does it mean to be better? The whole... Yeah. Yeah. From whatever model I have, one teacher can give a very good predicate. One teacher can say swims like a dog and another can say jump like a dog. And jump like a dog carries zero information. So what is the most exciting problem in statistical learning you've ever worked on or are working on now? I just finished this invariant story and I'm happy that... I believe that it is ultimate learning story. At least I can show that there are no another mechanism, only two mechanisms. But they separate statistical part from intelligent part and I know nothing about intelligent part. And if you will know this intelligent part, so it will help us a lot in teaching, in learning. In learning. Yeah. You will know it when we see it? So for example, in my talk, the last slide was a challenge. So you have say NIST digit recognition problem and deep learning claims that they did it very well, say 99.5% of correct answers. But they use 60,000 observations. Can you do the same using hundred times less? But incorporating invariants, what it means, you know, digit one, two, three. But looking on that, explain to me which invariant I should keep to use hundred examples or say hundred times less examples to do the same job. Yeah, that last slide, unfortunately your talk ended quickly, but that last slide was a powerful open challenge and a formulation of the essence here. What is the exact problem of intelligence? Because everybody, when machine learning started and it was developed by mathematicians, they immediately recognized that we use much more training data than humans needed. But now again, we came to the same story, have to decrease. That is the problem of learning. It is not like in deep learning, they use zillions of training data because maybe zillions are not enough if you have a good invariants. Maybe you will never collect some number of observations. But now it is a question to intelligence, how to do that? Because statistical part is ready, as soon as you supply us with predicate, we can do good job with small amount of observations. And the very first challenge is well known digit recognition. And you know digits, and please tell me invariants. I think about that, I can say for digit three, I would introduce concept of horizontal symmetry. So the digit three has horizontal symmetry, say more than, say, digit two or something like that. But as soon as I get the idea of horizontal symmetry, I can mathematically invent a lot of measure of horizontal symmetry, or then vertical symmetry, or diagonal symmetry, whatever, if I have idea of symmetry. But what else? I think on digit I see that it is meta predicate, which is not shape, it is something like symmetry, like how dark is whole picture, something like that, which can self rise a predicate. You think such a predicate could rise out of something that is not general, meaning it feels like for me to be able to understand the difference between two and three, I would need to have had a childhood of 10 to 15 years playing with kids, going to school, being yelled by parents, all of that, walking, jumping, looking at ducks, and then I would be able to generate the right predicate for telling the difference between two and a three. Or do you think there's a more efficient way? I don't know. I know for sure that you must know something more than digits. Yes. And that's a powerful statement. Yeah. But maybe there are several languages of description, these elements of digits. So I'm talking about symmetry, about some properties of geometry, I'm talking about something abstract. I don't know that. But this is a problem of intelligence. So in one of our articles, it is trivial to show that every example can carry not more than one bit of information in real. Because when you show example and you say this is one, you can remove, say, a function which does not tell you one, say, is the best strategy. If you can do it perfectly, it's remove half of the functions. But when you use one predicate, which looks like a duck, you can remove much more functions than half. And that means that it contains a lot of bit of information from formal point of view. But when you have a general picture of what you want to recognize and general picture of the world, can you invent this predicate? And that predicate carries a lot of information. Beautifully put. Maybe just me, but in all the math you show, in your work, which is some of the most profound mathematical work in the field of learning AI and just math in general, I hear a lot of poetry and philosophy. You really kind of talk about philosophy of science. There's a poetry and music to a lot of the work you're doing and the way you're thinking about it. So do you, where does that come from? Do you escape to poetry? Do you escape to music or not? I think that there exists ground truth. There exists ground truth? Yeah. And that can be seen everywhere. The smart guy, philosopher, sometimes I'm surprised how they deep see. Sometimes I see that some of them are completely out of subject. But the ground truth I see in music. Music is the ground truth? Yeah. And in poetry, many poets, they believe, they take dictation. So what piece of music as a piece of empirical evidence gave you a sense that they are touching something in the ground truth? It is structure. The structure of the math of music. Yeah, because when you're listening to Bach, you see the structure. Very clear, very classic, very simple, and the same in math when you have axioms in geometry, you have the same feeling. And in poetry, sometimes you see the same. And if you look back at your childhood, you grew up in Russia, you maybe were born as a researcher in Russia, you've developed as a researcher in Russia, you've came to United States and a few places. If you look back, what was some of your happiest moments as a researcher, some of the most profound moments, not in terms of their impact on society, but in terms of their impact on how damn good you feel that day and you remember that moment? You know, every time when you found something, it is great in the life, every simple things. But my general feeling is that most of my time was wrong. You should go again and again and again and try to be honest in front of yourself, not to make interpretation, but try to understand that it's related to ground truth, it is not my blah, blah, blah interpretation and something like that. But you're allowed to get excited at the possibility of discovery. Oh yeah. You have to double check it. No, but how it's related to another ground truth, is it just temporary or it is for forever? You know, you always have a feeling when you found something, how big is that? So 20 years ago when we discovered statistical learning theory, nobody believed, except for one guy, Dudley from MIT, and then in 20 years it became fashion, and the same with support vector machines, that is kernel machines. So with support vector machines and learning theory, when you were working on it, you had a sense, you had a sense of the profundity of it, how this seems to be right, this seems to be powerful. Right. Absolutely. Immediately. I recognized that it will last forever, and now when I found this invariant story, I have a feeling that it is complete learning, because I have proof that there are no different mechanisms. You can have some cosmetic improvement you can do, but in terms of invariants, you need both invariants and statistical learning, and they should work together. But also I'm happy that we can formulate what is intelligence from that, and to separate from technical part, and that is completely different. Absolutely. Well, Vladimir, thank you so much for talking today. Thank you. It's an honor.",following conversation vladimir vapnik co inventor support vector machine support vector clustering vc theory foundational idea statistical learning bear soviet union work institute control sciences moscow united states work nec labs facebook research professor columbia university work cite time interesting idea artificial intelligence nature learning especially limit current approach open problem field conversation mit course artificial general intelligence artificial intelligence podcast enjoy subscribe youtube rate itunes podcast provider choice simply connect twitter social network lex friedman spell f r conversation vladimir vapnik einstein famously say god play dice yeah study world eye statistic let ask term nature reality fundamental nature reality god play dice know factor know factor important look like god play dice describe philosophy distinguish position position instrumentalism create theory prediction position realism try understand god describe instrumentalism realism little bit example mechanical law law true law allow predict position move element believe believe god law god create world obey physical law law prediction instrumentalism prediction believe law god true mean realist try understand god thought way world instrumentalist know work model model machine learning model setting try solve resolve setting solve problem different way point view instrumentalist everybody goal machine learning find rule classification true instrument prediction goal machine learning learn conditional probability god play use play probability probability give situation prediction need need rule understanding need conditional probability let step little bit talk mention read night part paper eugene wigner unreasonable effectiveness mathematics natural sciences beautiful paper way feel honest confess work past year deep learning heavily apply feel miss beauty nature way math uncover let step away poetry second role math life tool poetry sit math limit describe people math language use god use god believe speak god use god use god use god yeah believe article effectiveness unreasonable effectiveness math look mathematical structure know reality scientist natural science look equation try understand reality machine learning try carefully look equation define conditional probability understand reality fantasy math reveal simple underlie principle reality know mean simple hard discover discover look beautiful surprising people look equation derive equation example talk yesterday square method people lot fantasy improve square method go step step solve equation suddenly term think understand describe position observation point square method throw lot information look composition point observation look residual understand simple idea simple understand derive equation simple algebra step surprising think understand proof human intuition rich primitive simple situation let step general yes human oppose intuition ingenuity moment brilliance hard human intuition moment brilliance human intuition leap ahead math math catch think think good human intuition put axiom technical axiom correctly axiom axiom polished generation scientist integral wisdom beautifully maybe look think einstein special relativity role imagination come moment discovery idea obviously mix math box imagination know exclude imagination see machine learning come imagination like feature like deep learning relevant problem look carefully mathematical equation derive simple theory go far theoretically people imagine good fantasy interpretation fantasy need need imagination derive main principle machine learning think learning intelligence maybe think human brain try describe mathematically process learning like happen human brain think tool currently think tool try describe process learn description go interpretation interpretation vision wrong know guy invent microscope levenhuk time get instrument keep secret microscope write report london academy science report look blood look water blood sperm describe blood like fight queen king see blood cell red cell imagine army fight interpretation situation send report academy science carefully look believe right see yes give wrong interpretation believe happen brain brain yeah important know believe human language proverb wisdom example people well thousand day diligent study day great teacher ask teacher know intelligence know history math machine learn teacher lot mathematical point view great teacher know open question teacher introduce invariant predicate create invariant know teacher know reality describe reality predicate invariant know invariant decrease number observation time maybe try pull apart little bit think mention like piano teacher say student play like butterfly yeah play piano play guitar long time yeah maybe romantic poetic feel like lot truth statement like lot instruction statement pull apart language contain information blah blah blah blah blah blah affect affect affect playing yes laying feel like information exchange nature information representation information believe sort predicate know exactly intelligence machine learning yes rest mathematical technique think discover recently mechanism learn call strong convergence mechanism weak convergence mechanism people use convergence weak convergence mechanism use predicate play like butterfly immediately affect playing know english proverb great look like duck swim like duck quack like duck probably duck yes exact predicate look like duck mean see duck train datum description look integral look duck yeah visual characteristic duck yeah want model recognition like theoretical description model coincide empirical description see territory look like duck general swim like duck know duck swim play chess like duck okay duck play chess completely legal predicate useless half teacher recognize useless predicate use predicate exist machine learning need zillion datum english proverb use predicate look like duck swim like duck quack like duck deny fact swim like duck quack like duck humor ambiguity let talk swim like duck jump like duck relevant mean know duck know different bird know animal derive relevant swim like duck underneath order understand swims like duck feel like need know million little piece information pick way think need knowledge base statement carry rich information help understand essence duck yeah far integrate predicate know consider complete theory machine learning lot function talk look like duck training datum training datum recognize like expect duck look remove function look like think look training datum decrease function pick second predicate decrease set function pick good function find standard machine learning need example predicate good mean predicate good predicate invent decrease admissible set function talk admissible set function talk good function make good function admissible set function set function small capacity small diversity small vc dimension example contain good function inside way people know vc v vc describe lay person vc theory describe vc machine machine capable pick function admissible set function set admissible function big contain continuous function useless example pick function small small capacity maybe well call diversity different function set infinite set function diverse small vc dimension vc dimension small need small training datum goal create admissible set function small vc dimension contain good function able pick function small observation task learning yeah create set admissible function small vc dimension figure clever way pick goal learn formulate yesterday statistical learning theory involve create admissible set function classical learning theory textbook set function admissible set function give science difficult problem create admissible set function give lot function continuum set function create admissible set function mean finite vc dimension small vc dimension contain good function consideration process mean fascinating process create admissible set function invariant invariant yeah look property training datum property mean function count value average value function training datum model expectation function model coincide problem pick function function fact true function talk duck jump ask question jump like duck trivial jump help recognize jump know question ask ask like duck look like duck general situation look like guy illness disease legal general type predicate look like special type predicate relate specific problem intelligence business teacher involve incorporate specialized predicate think deep learning neural network arbitrary architecture helping accomplish task think effectiveness lack thereof weakness possible strength know think fantasy like deep learning like feature let example great book churchill book history second world war start book describe old time war great king gather relative discuss create peace come agreement happen world war general public come power greedy rob germany clear everybody peace peace year professional machine learning mathematician look problem deep point view mathematical point view computer scientist know mathematic interpretation invent lot blah blah blah interpretation like deep learning need deep learning mathematic know deep learning mathematic know neuron function like piecewise linear function class piecewise linear function invent try prove advantage interpretation wrong appeal brain know know go brain think reliable work math mathematical problem good solve problem try understand way convergence strong way convergence weak way convergence require predicate stuff need deep learning theory call represent theory say optimal solution mathematical problem describe learning shadow network deep learning shallow network yeah ultimate problem absolutely end say exactly right question value throw table play math like neural network say throw bucket biological example look king queen cell microscope value imagine cell king queen inspiration imagination math eventually lead think interpretation basically deceive way productive think try analyze business learn especially discussion deep learning discussion interpretation thing thing right surprised beauty mathematical beauty fact work criticize beauty human desire interpret find silly interpretation construct let ask surprised inspire feel success system like alphago beat game neural network estimate quality board quality position interpretation quality board yeah yes yeah interpretation fact neural network system matter learning system think mathematically understand beat good human player think impossible mean difficult problem empirically empirically discover difficult problem yeah true maybe argue use deep learning effective way learn theory usually people use deep learning zillion training datum yeah need describe challenge problem deep learning method deep net time training datum problem deep learning solve necessary create admissible set function create deep architecture mean create admissible set function create good admissible set function fantasy come possible create admissible set function training datum actually mathematician consider variant need use law large number make training exist algorithm need uniform law large number difficult require vc dimension stuff use weak strong way convergence decrease lot training datum swim like duck quack like duck let step think human intelligence general clearly evolve non mathematical way far know god come model place brain admissible function kind evolve know maybe view alan ture paper ask reject question machine think useful question briefly entertain useful useless question machine think talk intelligence view know know ture describe imitation computer imitate human let intelligent understand think computer completely understand set problem imitation understand problem imitation sure intelligence inside outside observation prove theorem difficult theorem couple year place people prove theorem sawyer lemma guy prove theorem history science happen time example geometry happen simultaneously lobachevsky gauss boyai guy approximately time period year period time see lot example like mathematician think develop develop general affect everybody maybe model intelligence inside incorrect interpretation exist connection world intelligence know like plug yeah exactly contribute big network big maybe network flip maybe comment big o complexity classify algorithm bad case run time relation input way think function think p equal np think interesting question yeah interesting question let talk complexity bad case scenario mathematical setting come united states people know know statistical learning theory russia publish monograph monograph america know learn somebody tell bad case theory create real case theory till mathematical mathematic clear understanding clear description reason introduce complexity need actually diversity like mention prove theorem create theory case know probability measure good case happen entropy theory mathematical point view know well possible case bad possible case derive different model medium interesting think edge interesting edge interesting easy good bound exact bind case bind exact interesting principle discover mass think interesting challenge reveal interesting principle allow bound think interesting actually useful understand essence function algorithm like judge life human bad thing good thing versus stuff middle productive think describe situation middle general describe edge case clear model describe model new case accurate model statistical point view way study function nature learn world think real world long tail edge case far away mean stuff middle know think point view use formal statistic need uniform law large number use invariance business need law large number huge difference uniform law large number large number useful describe little example talk duck predicate try formal distinguish need lot observation mean information look like duck contain lot bit information formal bit information know bit information contain thing artificial intelligence subject analysis till business like people consider artificial intelligence consider code imitate activity human science application like imitate ahead useful good problem need learn people try people develop predicate like duck play like butterfly like teacher say come mind choose image process problem intelligence problem intelligence connect problem learn absolutely immediately predicate like specific predicate like duck quack like duck choose line work formulate set open problem play like butterfly system able let separate story mathematical story predicate story predicate intelligence problem people start understand intelligence understand intelligence try understand teacher teacher teach teacher well yeah think start journey generate predicate understand understand problem exist hear know want understand teacher well affect teacher student repeat problem textbook make remark make philosophy reasoning yeah beautiful formulation question open problem teacher well right well yeah level well mean well yeah yeah model teacher good predicate teacher swim like dog jump like dog jump like dog carry zero information exciting problem statistical learning work work finish invariant story happy believe ultimate learning story mechanism mechanism separate statistical intelligent know intelligent know intelligent help lot teaching learn learn yeah know example talk slide challenge nist digit recognition problem deep learning claim correct answer use observation time incorporate invariant mean know digit look explain invariant use example time example job yeah slide unfortunately talk end quickly slide powerful open challenge formulation essence exact problem intelligence everybody machine learning start develop mathematician immediately recognize use training datum human need come story decrease problem learn like deep learning use zillion training datum maybe zillion good invariant maybe collect number observation question intelligence statistical ready soon supply predicate good job small observation challenge know digit recognition know digit tell invariant think digit introduce concept horizontal symmetry digit horizontal symmetry digit like soon idea horizontal symmetry mathematically invent lot measure horizontal symmetry vertical symmetry diagonal symmetry idea symmetry think digit meta predicate shape like symmetry like dark picture like self rise predicate think predicate rise general mean feel like able understand difference need childhood year play kid go school yell parent walk jump look duck able generate right predicate tell difference think efficient way know know sure know digit yes powerful statement yeah maybe language description element digit talk symmetry property geometry talk abstract know problem intelligence article trivial example carry bit information real example remove function tell good strategy perfectly remove half function use predicate look like duck remove function half mean contain lot bit information formal point view general picture want recognize general picture world invent predicate predicate carry lot information beautifully maybe math work profound mathematical work field learn ai math general hear lot poetry philosophy kind talk philosophy science poetry music lot work way think come escape poetry escape music think exist ground truth exist ground truth yeah see smart guy philosopher surprised deep completely subject ground truth music music ground truth yeah poetry poet believe dictation piece music piece empirical evidence give sense touch ground truth structure structure math music yeah listen bach structure clear classic simple math axiom geometry feeling poetry look childhood grow russia maybe bear researcher russia develop researcher russia come united states place look happy moment researcher profound moment term impact society term impact damn good feel day remember moment know time find great life simple thing general feeling time wrong try honest interpretation try understand relate ground truth blah blah blah interpretation like allow excited possibility discovery oh yeah double check related ground truth temporary forever know feeling find big year ago discover statistical learning theory believe guy dudley mit year fashion support vector machine kernel machine support vector machine learn theory work sense sense profundity right powerful right absolutely immediately recognize forever find invariant story feeling complete learning proof different mechanism cosmetic improvement term invariant need invariant statistical learning work happy formulate intelligence separate technical completely different absolutely vladimir thank talk today thank honor,"['Vladimir Vapnik', 'Eugene Wigner', 'Alan Turing', 'Sawyer Lemma']","['Facebook AI Research', 'Columbia University', 'AT&T']","['Support Vector Machines', 'Deep Neural Networks', 'Big Data Analytics']","['Statistical Learning Theory', 'Machine Learning Fundamentals', 'Deep Learning', 'Computational Neuroscience', 'AI Safety and Ethics']"
6,Guido van Rossum,Python,"The following is a conversation with Guido van Rossum, creator of Python, one of the most popular programming languages in the world, used in almost any application that involves computers from web back end development to psychology, neuroscience, computer vision, robotics, deep learning, natural language processing, and almost any subfield of AI. This conversation is part of MIT course on artificial general intelligence and the artificial intelligence podcast. If you enjoy it, subscribe on YouTube, iTunes, or your podcast provider of choice, or simply connect with me on Twitter at Lex Friedman, spelled F R I D. And now, here's my conversation with Guido van Rossum. You were born in the Netherlands in 1956. Your parents and the world around you was deeply deeply impacted by World War Two, as was my family from the Soviet Union. So with that context, what is your view of human nature? Are some humans inherently good, and some inherently evil? Or do we all have both good and evil within us? Guido van Rossum Ouch, I did not expect such a deep one. I, I guess we all have good and evil potential in us. And a lot of it depends on circumstances and context. Peter Bell out of that world, at least on the Soviet Union side in Europe, sort of out of suffering, out of challenge, out of that kind of set of traumatic events, often emerges beautiful art, music, literature. In an interview I read or heard, you said you enjoyed Dutch literature when you were a child. Can you tell me about the books that had an influence on you in your childhood? Guido van Rossum Well, with as a teenager, my favorite writer was my favorite Dutch author was a guy named Willem Frederik Hermans, who's writing, certainly his early novels were all about sort of ambiguous things that happened during World War Two. I think he was a young adult during that time. And he wrote about it a lot, and very interesting, very good books, I thought, I think. Peter Bell In a nonfiction way? Guido van Rossum No, it was all fiction, but it was very much set in the ambiguous world of resistance against the Germans, where often you couldn't tell whether someone was truly in the resistance or really a spy for the Germans. And some of the characters in his novels sort of crossed that line, and you never really find out what exactly happened. Peter Bell And in his novels, there's always a good guy and a bad guy, the nature of good and evil. Is it clear there's a hero? Guido van Rossum No, his heroes are often more, his main characters are often anti heroes. And so they're not very heroic. They're often, they fail at some level to accomplish their lofty goals. Peter Bell And looking at the trajectory through the rest of your life, has literature, Dutch or English or translation had an impact outside the technical world that you existed in? Guido van Rossum I still read novels. I don't think that it impacts me that much directly. Peter Bell It doesn't impact your work. Guido van Rossum It's a separate world. My work is highly technical and sort of the world of art and literature doesn't really directly have any bearing on it. Peter Bell You don't think there's a creative element to the design? You know, some would say design of a language is art. Guido van Rossum I'm not disagreeing with that. I'm just saying that sort of I don't feel direct influences from more traditional art on my own creativity. Peter Bell Right. Of course, you don't feel doesn't mean it's not somehow deeply there in your subconscious. Guido van Rossum Who knows? Peter Bell Who knows? So let's go back to your early teens. Your hobbies were building electronic circuits, building mechanical models. What if you can just put yourself back in the mind of that young Guido 12, 13, 14, was that grounded in a desire to create a system? So to create something? Or was it more just tinkering? Just the joy of puzzle solving? Guido van Rossum I think it was more the latter, actually. I maybe towards the end of my high school period, I felt confident enough that that I designed my own circuits that were sort of interesting somewhat. But a lot of that time, I literally just took a model kit and follow the instructions, putting the things together. I mean, I think the first few years that I built electronics kits, I really did not have enough understanding of sort of electronics to really understand what I was doing. I mean, I could debug it, and I could sort of follow the instructions very carefully, which has always stayed with me. But I had a very naive model of, like, how do I build a circuit? Of, like, how a transistor works? And I don't think that in those days, I had any understanding of coils and capacitors, which actually sort of was a major problem when I started to build more complex digital circuits, because I was unaware of the sort of the analog part of the – how they actually work. And I would have things that – the schematic looked – everything looked fine, and it didn't work. And what I didn't realize was that there was some megahertz level oscillation that was throwing the circuit off, because I had a sort of – two wires were too close, or the switches were kind of poorly built. But through that time, I think it's really interesting and instructive to think about, because echoes of it are in this time now. So in the 1970s, the personal computer was being born. So did you sense, in tinkering with these circuits, did you sense the encroaching revolution in personal computing? So if at that point, we would sit you down and ask you to predict the 80s and the 90s, do you think you would be able to do so successfully to unroll the process that's happening? No, I had no clue. I remember, I think, in the summer after my senior year – or maybe it was the summer after my junior year – well, at some point, I think, when I was 18, I went on a trip to the Math Olympiad in Eastern Europe, and there was like – I was part of the Dutch team, and there were other nerdy kids that sort of had different experiences, and one of them told me about this amazing thing called a computer. And I had never heard that word. My own explorations in electronics were sort of about very simple digital circuits, and I had sort of – I had the idea that I somewhat understood how a digital calculator worked. And so there is maybe some echoes of computers there, but I never made that connection. I didn't know that when my parents were paying for magazine subscriptions using punched cards, that there was something called a computer that was involved that read those cards and transferred the money between accounts. I was also not really interested in those things. It was only when I went to university to study math that I found out that they had a computer, and students were allowed to use it. And there were some – you're supposed to talk to that computer by programming it. What did that feel like, finding – Yeah, that was the only thing you could do with it. The computer wasn't really connected to the real world. The only thing you could do was sort of – you typed your program on a bunch of punched cards. You gave the punched cards to the operator, and an hour later the operator gave you back your printout. And so all you could do was write a program that did something very abstract. And I don't even remember what my first forays into programming were, but they were sort of doing simple math exercises and just to learn how a programming language worked. Did you sense, okay, first year of college, you see this computer, you're able to have a program and it generates some output. Did you start seeing the possibility of this, or was it a continuation of the tinkering with circuits? Did you start to imagine that one, the personal computer, but did you see it as something that is a tool, like a word processing tool, maybe for gaming or something? Or did you start to imagine that it could be going to the world of robotics, like the Frankenstein picture that you could create an artificial being? There's like another entity in front of you. You did not see the computer. I don't think I really saw it that way. I was really more interested in the tinkering. It's maybe not a sort of a complete coincidence that I ended up sort of creating a programming language which is a tool for other programmers. I've always been very focused on the sort of activity of programming itself and not so much what happens with the program you write. Right. I do remember, and I don't remember, maybe in my second or third year, probably my second actually, someone pointed out to me that there was this thing called Conway's Game of Life. You're probably familiar with it. I think – In the 70s, I think is when they came up with it. So there was a Scientific American column by someone who did a monthly column about mathematical diversions. I'm also blanking out on the guy's name. It was very famous at the time and I think up to the 90s or so. And one of his columns was about Conway's Game of Life and he had some illustrations and he wrote down all the rules and sort of there was the suggestion that this was philosophically interesting, that that was why Conway had called it that. And all I had was like the two pages photocopy of that article. I don't even remember where I got it. But it spoke to me and I remember implementing a version of that game for the batch computer we were using where I had a whole Pascal program that sort of read an initial situation from input and read some numbers that said do so many generations and print every so many generations and then out would come pages and pages of sort of things. I remember much later I've done a similar thing using Python but that original version I wrote at the time I found interesting because I combined it with some trick I had learned during my electronics hobbyist times. I essentially first on paper I designed a simple circuit built out of logic gates that took nine bits of input which is sort of the cell and its neighbors and produced a new value for that cell and it's like a combination of a half adder and some other clipping. It's actually a full adder. And so I had worked that out and then I translated that into a series of Boolean operations on Pascal integers where you could use the integers as bitwise values. And so I could basically generate 60 bits of a generation in like eight instructions or so. Nice. So I was proud of that. It's funny that you mentioned, so for people who don't know Conway's Game of Life, it's a cellular automata where there's single compute units that kind of look at their neighbors and figure out what they look like in the next generation based on the state of their neighbors and this is deeply distributed system in concept at least. And then there's simple rules that all of them follow and somehow out of this simple rule when you step back and look at what occurs, it's beautiful. There's an emergent complexity. Even though the underlying rules are simple, there's an emergent complexity. Now the funny thing is you've implemented this and the thing you're commenting on is you're proud of a hack you did to make it run efficiently. When you're not commenting on, it's a beautiful implementation, you're not commenting on the fact that there's an emergent complexity that you've coded a simple program and when you step back and you print out the following generation after generation, that's stuff that you may have not predicted would happen is happening. And is that magic? I mean, that's the magic that all of us feel when we program. When you create a program and then you run it and whether it's Hello World or it shows something on screen, if there's a graphical component, are you seeing the magic in the mechanism of creating that? I think I went back and forth. As a student, we had an incredibly small budget of computer time that we could use. It was actually measured. I once got in trouble with one of my professors because I had overspent the department's budget. It's a different story. I actually wanted the efficient implementation because I also wanted to explore what would happen with a larger number of generations and a larger size of the board. Once the implementation was flawless, I would feed it different patterns and then I think maybe there was a follow up article where there were patterns that were like gliders, patterns that repeated themselves after a number of generations but translated one or two positions to the right or up or something like that. I remember things like glider guns. Well, you can Google Conway's Game of Life. People still go aww and ooh over it. For a reason because it's not really well understood why. I mean, this is what Stephen Wolfram is obsessed about. We don't have the mathematical tools to describe the kind of complexity that emerges in these kinds of systems. The only way you can do is to run it. I'm not convinced that it's sort of a problem that lends itself to classic mathematical analysis. One theory of how you create an artificial intelligence or artificial being is you kind of have to, same with the Game of Life, you kind of have to create a universe and let it run. That creating it from scratch in a design way, coding up a Python program that creates a fully intelligent system may be quite challenging. You might need to create a universe just like the Game of Life. You might have to experiment with a lot of different universes before there is a set of rules that doesn't essentially always just end up repeating itself in a trivial way. Yeah, and Stephen Wolfram works with these simple rules, says that it's kind of surprising how quickly you find rules that create interesting things. You shouldn't be able to, but somehow you do. And so maybe our universe is laden with rules that will create interesting things that might not look like humans, but emergent phenomena that's interesting may not be as difficult to create as we think. Sure. But let me sort of ask, at that time, some of the world, at least in popular press, was kind of captivated, perhaps at least in America, by the idea of artificial intelligence, that these computers would be able to think pretty soon. And did that touch you at all? In science fiction or in reality in any way? I didn't really start reading science fiction until much, much later. I think as a teenager I read maybe one bundle of science fiction stories. Was it in the background somewhere, like in your thoughts? That sort of the using computers to build something intelligent always felt to me, because And how did you try to design it into the language? There are different tasks and as a programmer, it's useful to have different tools available that sort of are suitable for different tasks. So I still write C code, I still write shell code, but I write most of my things in Python. Why do I still use those other languages, because sometimes the task just demands it. And well, I would say most of the time the task actually demands a certain language because the task is not write a program that solves problem X from scratch, but it's more like fix a bug in existing program X or add a small feature to an existing large program. But even if you're not constrained in your choice of language by context like that, there is still the fact that if you write it in a certain language, then you have this balance between how long does it take you to write the code and how long does the code run? And when you're in the phase of exploring solutions, you often spend much more time writing the code than running it because every time you've run it, you see that the output is not quite what you wanted and you spend some more time coding. And a language like Python just makes that iteration much faster because there are fewer details that you have to get right before your program compiles and runs. There are libraries that do all sorts of stuff for you, so you can sort of very quickly take a bunch of existing components, put them together, and get your prototype application running. Just like when I was building electronics, I was using a breadboard most of the time, so I had this sprawl out circuit that if you shook it, it would stop working because it was not put together very well, but it functioned and all I wanted was to see that it worked and then move on to the next schematic or design or add something to it. Once you've sort of figured out, oh, this is the perfect design for my radio or light sensor or whatever, then you can say, okay, how do we design a PCB for this? How do we solder the components in a small space? How do we make it so that it is robust against, say, voltage fluctuations or mechanical disruption? I know nothing about that when it comes to designing electronics, but I know a lot about that when it comes to writing code. So the initial steps are efficient, fast, and there's not much stuff that gets in the way, but you're kind of describing, like Darwin described the evolution of species, right? You're observing of what is true about Python. Now if you take a step back, if the act of creating languages is art and you had three months to do it, initial steps, so you just specified a bunch of goals, sort of things that you observe about Python, perhaps you had those goals, but how do you create the rules, the syntactic structure, the features that result in those? So I have in the beginning and I have follow up questions about through the evolution of Python too, but in the very beginning when you were sitting there creating the lexical analyzer or whatever. Python was still a big part of it because I sort of, I said to myself, I don't want to have to design everything from scratch, I'm going to borrow features from other languages that I like. Oh, interesting. So you basically, exactly, you first observe what you like. Yeah, and so that's why if you're 17 years old and you want to sort of create a programming language, you're not going to be very successful at it because you have no experience with other languages, whereas I was in my, let's say mid 30s, I had written parsers before, so I had worked on the implementation of ABC, I had spent years debating the design of ABC with its authors, with its designers, I had nothing to do with the design, it was designed fully as it ended up being implemented when I joined the team. But so you borrow ideas and concepts and very concrete sort of local rules from different languages like the indentation and certain other syntactic features from ABC, but I chose to borrow string literals and how numbers work from C and various other things. So in then, if you take that further, so yet you've had this funny sounding, but I think surprisingly accurate and at least practical title of benevolent dictator for life for quite, you know, for the last three decades or whatever, or no, not the actual title, but functionally speaking. So you had to make decisions, design decisions. Can you maybe, let's take Python 2, so releasing Python 3 as an example. It's not backward compatible to Python 2 in ways that a lot of people know. So what was that deliberation, discussion, decision like? Yeah. What was the psychology of that experience? Do you regret any aspects of how that experience undergone that? Well, yeah, so it was a group process really. At that point, even though I was BDFL in name and certainly everybody sort of respected my position as the creator and the current sort of owner of the language design, I was looking at everyone else for feedback. Sort of Python 3.0 in some sense was sparked by other people in the community pointing out, oh, well, there are a few issues that sort of bite users over and over. Can we do something about that? And for Python 3, we took a number of those Python words as they were called at the time and we said, can we try to sort of make small changes to the language that address those words? And we had sort of in the past, we had always taken backwards compatibility very seriously. And so many Python words in earlier versions had already been resolved because they could be resolved while maintaining backwards compatibility or sort of using a very gradual path of evolution of the language in a certain area. And so we were stuck with a number of words that were widely recognized as problems, not like roadblocks, but nevertheless sort of things that some people trip over and you know that that's always the same thing that people trip over when they trip. And we could not think of a backwards compatible way of resolving those issues. But it's still an option to not resolve the issues, right? And so yes, for a long time, we had sort of resigned ourselves to, well, okay, the language is not going to be perfect in this way and that way and that way. And we sort of, certain of these, I mean, there are still plenty of things where you can say, well, that particular detail is better in Java or in R or in Visual Basic or whatever. And we're okay with that because, well, we can't easily change it. It's not too bad. We can do a little bit with user education or we can have a static analyzer or warnings in the parse or something. But there were things where we thought, well, these are really problems that are not going away. They are getting worse in the future. We should do something about that. But ultimately there is a decision to be made, right? So was that the toughest decision in the history of Python you had to make as the benevolent dictator for life? Or if not, what are there, maybe even on the smaller scale, what was the decision where you were really torn up about? Well, the toughest decision was probably to resign. All right, let's go there. Hold on a second then. Let me just, because in the interest of time too, because I have a few cool questions for you and let's touch a really important one because it was quite dramatic and beautiful in certain kinds of ways. In July this year, three months ago, you wrote, now that PEP 572 is done, I don't ever want to have to fight so hard for a PEP and find that so many people despise my decisions. I would like to remove myself entirely from the decision process. I'll still be there for a while as an ordinary core developer and I'll still be available to mentor people, possibly more available. But I'm basically giving myself a permanent vacation from being BDFL, benevolent dictator for life. And you all will be on your own. First of all, it's almost Shakespearean. I'm not going to appoint a successor. So what are you all going to do? Create a democracy, anarchy, a dictatorship, a federation? So that was a very dramatic and beautiful set of statements. It's almost, it's open ended nature called the community to create a future for Python. It's just kind of a beautiful aspect to it. So what, and dramatic, you know, what was making that decision like? What was on your heart, on your mind, stepping back now a few months later? I'm glad you liked the writing because it was actually written pretty quickly. It was literally something like after months and months of going around in circles, I had finally approved PEP572, which I had a big hand in its design, although I didn't initiate it originally. I sort of gave it a bunch of nudges in a direction that would be better for the language. So sorry, just to ask, is async IO, that's the one or no? PEP572 was actually a small feature, which is assignment expressions. That had been, there was just a lot of debate where a lot of people claimed that they knew what was Pythonic and what was not Pythonic, and they knew that this was going to destroy the language. This was like a violation of Python's most fundamental design philosophy, and I thought that was all bullshit because I was in favor of it, and I would think I know something about Python's design philosophy. So I was really tired and also stressed of that thing, and literally after sort of announcing I was going to accept it, a certain Wednesday evening I had finally sent the email, it's accepted. I can just go implement it. So I went to bed feeling really relieved, that's behind me. And I wake up Thursday morning, 7 a.m., and I think, well, that was the last one that's going to be such a terrible debate, and that's the last time that I let myself be so stressed out about a pep decision. I should just resign. I've been sort of thinking about retirement for half a decade, I've been joking and sort of mentioning retirement, sort of telling the community at some point in the future I'm going to retire, don't take that FL part of my title too literally. And I thought, okay, this is it. I'm done, I had the day off, I wanted to have a good time with my wife, we were going to a little beach town nearby, and in I think maybe 15, 20 minutes I wrote that thing that you just called Shakespearean. The funny thing is I didn't even realize what a monumental decision it was, because five minutes later I read that link to my message back on Twitter, where people were already discussing on Twitter, Guido resigned as the BDFL. And I had posted it on an internal forum that I thought was only read by core developers, so I thought I would at least have one day before the news would sort of get out. The on your own aspects had also an element of quite, it was quite a powerful element of the uncertainty that lies ahead, but can you also just briefly talk about, for example I play guitar as a hobby for fun, and whenever I play people are super positive, super friendly, they're like, this is awesome, this is great. But sometimes I enter as an outside observer, I enter the programming community and there seems to sometimes be camps on whatever the topic, and the two camps, the two or plus camps, are often pretty harsh at criticizing the opposing camps. As an onlooker, I may be totally wrong on this, but what do you think of this? Yeah, holy wars are sort of a favorite activity in the programming community. And what is the psychology behind that? Is that okay for a healthy community to have? Is that a productive force ultimately for the evolution of a language? Well, if everybody is patting each other on the back and never telling the truth, it would not be a good thing. I think there is a middle ground where sort of being nasty to each other is not okay, but there is a middle ground where there is healthy ongoing criticism and feedback that is very productive. And you mean at every level you see that. I mean, someone proposes to fix a very small issue in a code base, chances are that some reviewer will sort of respond by saying, well, actually, you can do it better the other way. When it comes to deciding on the future of the Python core developer community, we now have, I think, five or six competing proposals for a constitution. So that future, do you have a fear of that future, do you have a hope for that future? I'm very confident about that future. By and large, I think that the debate has been very healthy and productive. And I actually, when I wrote that resignation email, I knew that Python was in a very good spot and that the Python core developer community, the group of 50 or 100 people who sort of write or review most of the code that goes into Python, those people get along very well most of the time. A large number of different areas of expertise are represented, different levels of experience in the Python core dev community, different levels of experience completely outside it in software development in general, large systems, small systems, embedded systems. So I felt okay resigning because I knew that the community can really take care of itself. And out of a grab bag of future feature developments, let me ask if you can comment, maybe on all very quickly, concurrent programming, parallel computing, async IO. These are things that people have expressed hope, complained about, whatever, have discussed on Reddit. Async IO, so the parallelization in general, packaging, I was totally clueless on this. I just used pip to install stuff, but apparently there's pipenv, poetry, there's these dependency packaging systems that manage dependencies and so on. They're emerging and there's a lot of confusion about what's the right thing to use. Then also functional programming, are we going to get more functional programming or not, this kind of idea. And of course the GIL connected to the parallelization, I suppose, the global interpreter lock problem. Can you just comment on whichever you want to comment on? Well, let's take the GIL and parallelization and async IO as one topic. I'm not that hopeful that Python will develop into a sort of high concurrency, high parallelism language. That's sort of the way the language is designed, the way most users use the language, the way the language is implemented, all make that a pretty unlikely future. So you think it might not even need to, really the way people use it, it might not be something that should be of great concern. I think async IO is a special case because it sort of allows overlapping IO and only IO and that is a sort of best practice of supporting very high throughput IO, many connections per second. I'm not worried about that. I think async IO will evolve. There are a couple of competing packages. We have some very smart people who are sort of pushing us to make async IO better. Parallel computing, I think that Python is not the language for that. There are ways to work around it, but you can't expect to write an algorithm in Python and have a compiler automatically parallelize that. What you can do is use a package like NumPy and there are a bunch of other very powerful packages that sort of use all the CPUs available because you tell the package, here's the data, here's the abstract operation to apply over it, go at it, and then we're back in the C++ world. Those packages are themselves implemented usually in C++. That's where TensorFlow and all these packages come in, where they parallelize across GPUs, for example, they take care of that for you. In terms of packaging, can you comment on the future of packaging in Python? Packaging has always been my least favorite topic. It's a really tough problem because the OS and the platform want to own packaging, but their packaging solution is not specific to a language. If you take Linux, there are two competing packaging solutions for Linux or for Unix in general, but they all work across all languages. Several languages like Node, JavaScript, Ruby, and Python all have their own packaging solutions that only work within the ecosystem of that language. What should you use? That is a tough problem. My own approach is I use the system packaging system to install Python, and I use the Python packaging system then to install third party Python packages. That's what most people do. Ten years ago, Python packaging was really a terrible situation. Nowadays, pip is the future, there is a separate ecosystem for numerical and scientific Python based on Anaconda. Those two can live together. I don't think there is a need for more than that. That's packaging. Well, at least for me, that's where I've been extremely happy. I didn't even know this was an issue until it was brought up. In the interest of time, let me sort of skip through a million other questions I have. So I watched the five and a half hour oral history that you've done with the Computer History Museum, and the nice thing about it, it gave this, because of the linear progression of the interview, it gave this feeling of a life, you know, a life well lived with interesting things in it, sort of a pretty, I would say a good spend of this little existence we have on Earth. So, outside of your family, looking back, what about this journey are you really proud of? Are there moments that stand out, accomplishments, ideas? Is it the creation of Python itself that stands out as a thing that you look back and say, damn, I did pretty good there? Well, I would say that Python is definitely the best thing I've ever done, and I wouldn't sort of say just the creation of Python, but the way I sort of raised Python, like a baby. I didn't just conceive a child, but I raised a child, and now I'm setting the child free in the world, and I've set up the child to sort of be able to take care of himself, and I'm very proud of that. And as the announcer of Monty Python's Flying Circus used to say, and now for something completely different, do you have a favorite Monty Python moment, or a moment in Hitchhiker's Guide, or any other literature show or movie that cracks you up when you think about it? You can always play me the dead parrot sketch. Oh, that's brilliant. That's my favorite as well. It's pushing up the daisies. Okay, Greta, thank you so much for talking with me today. Lex, this has been a great conversation. I felt I had so much understanding of what actually goes on inside a computer. I knew how many bits of memory it had and how difficult it was to program. And sort of, I didn't believe at all that you could just build something intelligent out of that, that would really sort of satisfy my definition of intelligence. I think the most influential thing that I read in my early twenties was Gödel Escherbach. That was about consciousness, and that was a big eye opener in some sense. In what sense? So, on your own brain, did you at the time or do you now see your own brain as a computer? Or is there a total separation of the way? So yeah, you're very pragmatically practically know the limits of memory, the limits of this sequential computing or weakly paralyzed computing, and you just know what we have now, and it's hard to see how it creates. But it's also easy to see, it was in the 40s, 50s, 60s, and now at least similarities between the brain and our computers. Oh yeah, I mean, I totally believe that brains are computers in some sense. I mean, the rules they use to play by are pretty different from the rules we can sort of implement in our current hardware, but I don't believe in, like, a separate thing that infuses us with intelligence or consciousness or any of that. There's no soul, I've been an atheist probably from when I was 10 years old, just by thinking a bit about math and the universe, and well, my parents were atheists. Now, I know that you could be an atheist and still believe that there is something sort of about intelligence or consciousness that cannot possibly emerge from a fixed set of rules. I am not in that camp. I totally see that, sort of, given how many millions of years evolution took its time, DNA is a particular machine that sort of encodes information and an unlimited amount of information in chemical form and has figured out a way to replicate itself. I thought that that was, maybe it's 300 million years ago, but I thought it was closer to half a billion years ago, that that's sort of originated and it hasn't really changed, that the sort of the structure of DNA hasn't changed ever since. That is like our binary code that we have in hardware. I mean... The basic programming language hasn't changed, but maybe the programming itself... Obviously, it did sort of, it happened to be a set of rules that was good enough to sort of develop endless variability and sort of the idea of self replicating molecules competing with each other for resources and one type eventually sort of always taking over. That happened before there were any fossils, so we don't know how that exactly happened, but I believe it's clear that that did happen. Can you comment on consciousness and how you see it? Because I think we'll talk about programming quite a bit. We'll talk about, you know, intelligence connecting to programming fundamentally, but consciousness is this whole other thing. Do you think about it often as a developer of a programming language and as a human? Those are pretty sort of separate topics. Sort of my line of work working with programming does not involve anything that goes in the direction of developing intelligence or consciousness, but sort of privately as an avid reader of popular science writing, I have some thoughts which is mostly that I don't actually believe that consciousness is an all or nothing thing. I have a feeling that, and I forget what I read that influenced this, but I feel that if you look at a cat or a dog or a mouse, they have some form of intelligence. If you look at a fish, it has some form of intelligence, and that evolution just took a long time, but I feel that the sort of evolution of more and more intelligence that led to sort of the human form of intelligence followed the evolution of the senses, especially the visual sense. I mean, there is an enormous amount of processing that's needed to interpret a scene, and humans are still better at that than computers are. And I have a feeling that there is a sort of, the reason that like mammals in particular developed the levels of consciousness that they have and that eventually sort of going from intelligence to self awareness and consciousness has to do with sort of being a robot that has very highly developed senses. Has a lot of rich sensory information coming in, so that's a really interesting thought that whatever that basic mechanism of DNA, whatever that basic building blocks of programming, if you just add more abilities, more high resolution sensors, more sensors, you just keep stacking those things on top that this basic programming in trying to survive develops very interesting things that start to us humans to appear like intelligence and consciousness. As far as robots go, I think that the self driving cars have that sort of the greatest opportunity of developing something like that, because when I drive myself, I don't just pay attention to the rules of the road. I also look around and I get clues from that, oh, this is a shopping district, oh, here's an old lady crossing the street, oh, here is someone carrying a pile of mail, there's a mailbox, I bet you they're going to cross the street to reach that mailbox. And I slow down, and I don't even think about that. And so, there is so much where you turn your observations into an understanding of what other consciousnesses are going to do, or what other systems in the world are going to be, oh, that tree is going to fall. I see sort of, I see much more of, I expect somehow that if anything is going to become unconscious, it's going to be the self driving car and not the network of a bazillion computers in a Google or Amazon data center that are all networked together to do whatever they do. So, in that sense, so you actually highlight, because that's what I work in Thomas Vehicles, you highlight the big gap between what we currently can't do and what we truly need to be able to do to solve the problem. Under that formulation, then consciousness and intelligence is something that basically a system should have in order to interact with us humans, as opposed to some kind of abstract notion of a consciousness. Consciousness is something that you need to have to be able to empathize, to be able to fear, understand what the fear of death is, all these aspects that are important for interacting with pedestrians, you need to be able to do basic computation based on our human desires and thoughts. And if you sort of, yeah, if you look at the dog, the dog clearly knows, I mean, I'm not the dog owner, but I have friends who have dogs, the dogs clearly know what the humans around them are going to do, or at least they have a model of what those humans are going to do and they learn. Some dogs know when you're going out and they want to go out with you, they're sad when you leave them alone, they cry, they're afraid because they were mistreated when they were younger. We don't assign sort of consciousness to dogs, or at least not all that much, but I also don't think they have none of that. So I think it's consciousness and intelligence are not all or nothing. The spectrum is really interesting. But in returning to programming languages and the way we think about building these kinds of things, about building intelligence, building consciousness, building artificial beings. So I think one of the exciting ideas came in the 17th century and with Leibniz, Hobbes, Descartes, where there's this feeling that you can convert all thought, all reasoning, all the thing that we find very special in our brains, you can convert all of that into logic. So you can formalize it, formal reasoning, and then once you formalize everything, all of knowledge, then you can just calculate and that's what we're doing with our brains is we're calculating. So there's this whole idea that this is possible, that this we can actually program. But they weren't aware of the concept of pattern matching in the sense that we are aware of it now. They sort of thought they had discovered incredible bits of mathematics like Newton's calculus and their sort of idealism, their sort of extension of what they could do with logic and math sort of went along those lines and they thought there's like, yeah, logic. There's like a bunch of rules and a bunch of input. They didn't realize that how you recognize a face is not just a bunch of rules but is a shit ton of data plus a circuit that sort of interprets the visual clues and the context and everything else and somehow can massively parallel pattern match against stored rules. I mean, if I see you tomorrow here in front of the Dropbox office, I might recognize you. Even if I'm wearing a different shirt, yeah, but if I see you tomorrow in a coffee shop in Belmont, I might have no idea that it was you or on the beach or whatever. I make those kind of mistakes myself all the time. I see someone that I only know as like, oh, this person is a colleague of my wife's and then I see them at the movies and I didn't recognize them. But do you see those, you call it pattern matching, do you see that rules is unable to encode that? Everything you see, all the pieces of information you look around this room, I'm wearing a black shirt, I have a certain height, I'm a human, all these, there's probably tens of thousands of facts you pick up moment by moment about this scene. You take them for granted and you aggregate them together to understand the scene. You don't think all of that could be encoded to where at the end of the day, you can just put it all on the table and calculate? I don't know what that means. I mean, yes, in the sense that there is no actual magic there, but there are enough layers of abstraction from the facts as they enter my eyes and my ears to the understanding of the scene that I don't think that AI has really covered enough of that distance. It's like if you take a human body and you realize it's built out of atoms, well, that is a uselessly reductionist view, right? The body is built out of organs, the organs are built out of cells, the cells are built out of proteins, the proteins are built out of amino acids, the amino acids are built out of atoms and then you get to quantum mechanics. So that's a very pragmatic view. I mean, obviously as an engineer, I agree with that kind of view, but you also have to consider the Sam Harris view of, well, intelligence is just information processing. Like you said, you take in sensory information, you do some stuff with it and you come up with actions that are intelligent. That makes it sound so easy. I don't know who Sam Harris is. Oh, well, it's a philosopher. So like this is how philosophers often think, right? And essentially that's what Descartes was, is wait a minute, if there is, like you said, no magic, so he basically says it doesn't appear like there's any magic, but we know so little about it that it might as well be magic. So just because we know that we're made of atoms, just because we know we're made of organs, the fact that we know very little how to get from the atoms to organs in a way that's recreatable means that you shouldn't get too excited just yet about the fact that you figured out that we're made of atoms. Right, and the same about taking facts as our sensory organs take them in and turning that into reasons and actions, that sort of, there are a lot of abstractions that we haven't quite figured out how to deal with those. I mean, sometimes, I don't know if I can go on a tangent or not, so if I take a simple program that parses, say I have a compiler that parses a program, in a sense the input routine of that compiler, of that parser, is a sensing organ, and it builds up a mighty complicated internal representation of the program it just saw, it doesn't just have a linear sequence of bytes representing the text of the program anymore, it has an abstract syntax tree, and I don't know how many of your viewers or listeners are familiar with compiler technology, but there's… Fewer and fewer these days, right? That's also true, probably. People want to take a shortcut, but there's sort of, this abstraction is a data structure that the compiler then uses to produce outputs that is relevant, like a translation of that program to machine code that can be executed by hardware, and then that data structure gets thrown away. When a fish or a fly sees, sort of gets visual impulses, I'm sure it also builds up some data structure, and for the fly that may be very minimal, a fly may have only a few, I mean, in the case of a fly's brain, I could imagine that there are few enough layers of abstraction that it's not much more than when it's darker here than it is here, well it can sense motion, because a fly sort of responds when you move your arm towards it, so clearly its visual processing is intelligent, well, not intelligent, but it has an abstraction for motion, and we still have similar things in, but much more complicated in our brains, I mean, otherwise you couldn't drive a car if you couldn't, if you didn't have an incredibly good abstraction for motion. Yeah, in some sense, the same abstraction for motion is probably one of the primary sources of our, of information for us, we just know what to do, I think we know what to do with that, we've built up other abstractions on top. We build much more complicated data structures based on that, and we build more persistent data structures, sort of after some processing, some information sort of gets stored in our memory pretty much permanently, and is available on recall, I mean, there are some things that you sort of, you're conscious that you're remembering it, like, you give me your phone number, I, well, at my age I have to write it down, but I could imagine, I could remember those seven numbers, or ten digits, and reproduce them in a while, if I sort of repeat them to myself a few times, so that's a fairly conscious form of memorization. On the other hand, how do I recognize your face, I have no idea. My brain has a whole bunch of specialized hardware that knows how to recognize faces, I don't know how much of that is sort of coded in our DNA, and how much of that is trained over and over between the ages of zero and three, but somehow our brains know how to do lots of things like that, that are useful in our interactions with other humans, without really being conscious of how it's done anymore. Right, so our actual day to day lives, we're operating at the very highest level of abstraction, we're just not even conscious of all the little details underlying it. There's compilers on top of, it's like turtles on top of turtles, or turtles all the way down, there's compilers all the way down, but that's essentially, you say that there's no magic, that's what I, what I was trying to get at, I think, is with Descartes started this whole train of saying that there's no magic, I mean, there's all this beforehand. Well didn't Descartes also have the notion though that the soul and the body were fundamentally separate? Separate, yeah, I think he had to write in God in there for political reasons, so I don't know actually, I'm not a historian, but there's notions in there that all of reasoning, all of human thought can be formalized. I think that continued in the 20th century with Russell and with Gadot's incompleteness theorem, this debate of what are the limits of the things that could be formalized, that's where the Turing machine came along, and this exciting idea, I mean, underlying a lot of computing that you can do quite a lot with a computer. You can encode a lot of the stuff we're talking about in terms of recognizing faces and so on, theoretically, in an algorithm that can then run on a computer. And in that context, I'd like to ask programming in a philosophical way, what does it mean to program a computer? So you said you write a Python program or compiled a C++ program that compiles to some byte code, it's forming layers, you're programming a layer of abstraction that's higher, how do you see programming in that context? Can it keep getting higher and higher levels of abstraction? I think at some point the higher levels of abstraction will not be called programming and they will not resemble what we call programming at the moment. There will not be source code, I mean, there will still be source code sort of at a lower level of the machine, just like there are still molecules and electrons and sort of proteins in our brains, but, and so there's still programming and system administration and who knows what, to keep the machine running, but what the machine does is a different level of abstraction in a sense, and as far as I understand the way that for the last decade or more people have made progress with things like facial recognition or the self driving cars is all by endless, endless amounts of training data where at least as a lay person, and I feel myself totally as a lay person in that field, it looks like the researchers who publish the results don't necessarily know exactly how their algorithms work, and I often get upset when I sort of read a sort of a fluff piece about Facebook in the newspaper or social networks and they say, well, algorithms, and that's like a totally different interpretation of the word algorithm, because for me, the way I was trained or what I learned when I was eight or ten years old, an algorithm is a set of rules that you completely understand that can be mathematically analyzed and you can prove things. You can like prove that Aristotelian sieve produces all prime numbers and only prime numbers. Yeah. So I don't know if you know who Andrej Karpathy is, I'm afraid not. So he's a head of AI at Tesla now, but he was at Stanford before and he has this cheeky way of calling this concept software 2.0. So let me disentangle that for a second. So kind of what you're referring to is the traditional, the algorithm, the concept of an algorithm, something that's there, it's clear, you can read it, you understand it, you can prove it's functioning as kind of software 1.0. And what software 2.0 is, is exactly what you described, which is you have neural networks, which is a type of machine learning that you feed a bunch of data and that neural network learns to do a function. All you specify is the inputs and the outputs you want and you can't look inside. You can't analyze it. All you can do is train this function to map the inputs to the outputs by giving a lot of data. And that's as programming becomes getting a lot of data. That's what programming is. Well, that would be programming 2.0. To programming 2.0. I wouldn't call that programming. It's just a different activity. Just like building organs out of cells is not called chemistry. Well, so let's just step back and think sort of more generally, of course. But you know, it's like as a parent teaching your kids, things can be called programming. In that same sense, that's how programming is being used. You're providing them data, examples, use cases. So imagine writing a function not by, not with for loops and clearly readable text, but more saying, well, here's a lot of examples of what this function should take. And here's a lot of examples of when it takes those functions, it should do this. And then figure out the rest. So that's the 2.0 concept. And so the question I have for you is like, it's a very fuzzy way. This is the reality of a lot of these pattern recognition systems and so on. It's a fuzzy way of quote unquote programming. What do you think about this kind of world? Should it be called something totally different than programming? If you're a software engineer, does that mean you're designing systems that are very, can be systematically tested, evaluated, they have a very specific specification and then this other fuzzy software 2.0 world, machine learning world, that's something else totally? Or is there some intermixing that's possible? Well the question is probably only being asked because we don't quite know what that software 2.0 actually is. And I think there is a truism that every task that AI has tackled in the past, at some point we realized how it was done and then it was no longer considered part of artificial intelligence because it was no longer necessary to use that term. It was just, oh now we know how to do this. And a new field of science or engineering has been developed and I don't know if sort of every form of learning or sort of controlling computer systems should always be called programming. So I don't know, maybe I'm focused too much on the terminology. But I expect that there just will be different concepts where people with sort of different education and a different model of what they're trying to do will develop those concepts. I guess if you could comment on another way to put this concept is, I think the kind of functions that neural networks provide is things as opposed to being able to upfront prove that this should work for all cases you throw at it. All you're able, it's the worst case analysis versus average case analysis. All you're able to say is it seems on everything we've tested to work 99.9% of the time, but we can't guarantee it and it fails in unexpected ways. We can't even give you examples of how it fails in unexpected ways, but it's like really good most of the time. Is there no room for that in current ways we think about programming? programming 1.0 is actually sort of getting to that point too, where the sort of the ideal of a bug free program has been abandoned long ago by most software developers. We only care about bugs that manifest themselves often enough to be annoying. And we're willing to take the occasional crash or outage or incorrect result for granted because we can't possibly, we don't have enough programmers to make all the code bug free and it would be an incredibly tedious business. And if you try to throw formal methods at it, it becomes even more tedious. So every once in a while the user clicks on a link and somehow they get an error and the average user doesn't panic. They just click again and see if it works better the second time, which often magically it does, or they go up and they try some other way of performing their tasks. So that's sort of an end to end recovery mechanism and inside systems there is all sorts of retries and timeouts and fallbacks and I imagine that that sort of biological systems are even more full of that because otherwise they wouldn't survive. Do you think programming should be taught and thought of as exactly what you just said? I come from this kind of, you're always denying that fact always. In sort of basic programming education, the sort of the programs you're having students write are so small and simple that if there is a bug you can always find it and fix it. Because the sort of programming as it's being taught in some, even elementary, middle schools, in high school, introduction to programming classes in college typically, it's programming in the small. Very few classes sort of actually teach software engineering, building large systems. Every summer here at Dropbox we have a large number of interns. Every tech company on the West Coast has the same thing. These interns are always amazed because this is the first time in their life that they see what goes on in a really large software development environment. Everything they've learned in college was almost always about a much smaller scale and somehow that difference in scale makes a qualitative difference in how you do things and how you think about it. If you then take a few steps back into decades, 70s and 80s, when you were first thinking about Python or just that world of programming languages, did you ever think that there would be systems as large as underlying Google, Facebook, and Dropbox? Did you, when you were thinking about Python? I was actually always caught by surprise by sort of this, yeah, pretty much every stage of computing. So maybe just because you've spoken in other interviews, but I think the evolution of programming languages are fascinating and it's especially because it leads from my perspective towards greater and greater degrees of intelligence. I learned the first programming language I played with in Russia was with the Turtle logo. Logo, yeah. And if you look, I just have a list of programming languages, all of which I've now played with a little bit. I mean, they're all beautiful in different ways from Fortran, Cobalt, Lisp, Algol 60, Basic, Logo again, C, as a few, the object oriented came along in the 60s, Simula, Pascal, Smalltalk. All of that leads. They're all the classics. The classics. Yeah. The classic hits, right? Steam, that's built on top of Lisp. On the database side, SQL, C++, and all of that leads up to Python, Pascal too, and that's before Python, MATLAB, these kind of different communities, different languages. So can you talk about that world? I know that sort of Python came out of ABC, which I actually never knew that language. I just, having researched this conversation, went back to ABC and it looks remarkably, it has a lot of annoying qualities, but underneath those, like all caps and so on, but underneath that, there's elements of Python that are quite, they're already there. That's where I got all the good stuff. All the good stuff. So, but in that world, you're swimming these programming languages, were you focused on just the good stuff in your specific circle, or did you have a sense of what is everyone chasing? You said that every programming language is built to scratch an itch. Were you aware of all the itches in the community? And if not, or if yes, I mean, what itch were you trying to scratch with Python? Well, I'm glad I wasn't aware of all the itches because I would probably not have been able to do anything. I mean, if you're trying to solve every problem at once, you'll solve nothing. Well, yeah, it's too overwhelming. And so I had a very, very focused problem. I wanted a programming language that sat somewhere in between shell scripting and C. And now, arguably, there is like, one is higher level, one is lower level. And Python is sort of a language of an intermediate level, although it's still pretty much at the high level end. I was thinking about much more about, I want a tool that I can use to be more productive as a programmer in a very specific environment. And I also had given myself a time budget for the development of the tool. And that was sort of about three months for both the design, like thinking through what are all the features of the language syntactically and semantically, and how do I implement the whole pipeline from parsing the source code to executing it. So I think both with the timeline and the goals, it seems like productivity was at the core of it as a goal. So like, for me in the 90s, and the first decade of the 21st century, I was always doing machine learning, AI programming for my research was always in C++. And then the other people who are a little more mechanical engineering, electrical engineering, are MATLABby. They're a little bit more MATLAB focused. Those are the world, and maybe a little bit Java too. But people who are more interested in emphasizing the object oriented nature of things. So within the last 10 years or so, especially with the oncoming of neural networks and these packages that are built on Python to interface with neural networks, I switched to Python and it's just, I've noticed a significant boost that I can't exactly, because I don't think about it, but I can't exactly put into words why I'm just much, much more productive. Just being able to get the job done much, much faster. So how do you think, whatever that qualitative difference is, I don't know if it's quantitative, it could be just a feeling, I don't know if I'm actually more productive, but how do you think about... You probably are. Yeah. Well, that's right. I think there's elements, let me just speak to one aspect that I think that was affecting my productivity is C++ was, I really enjoyed creating performant code and creating a beautiful structure where everything that, you know, this kind of going into this, especially with the newer and newer standards of templated programming of just really creating this beautiful formal structure that I found myself spending most of my time doing that as opposed to getting it, parsing a file and extracting a few keywords or whatever the task was trying to do. So what is it about Python? How do you think of productivity in general as you were designing it now, sort of through the decades, last three decades, what do you think it means to be a productive programmer?",following conversation guido van rossum creator python popular programming language world application involve computer web end development psychology neuroscience computer vision robotic deep learning natural language processing subfield ai conversation mit course artificial general intelligence artificial intelligence podcast enjoy subscribe youtube itunes podcast provider choice simply connect twitter lex friedman spell f r conversation guido van rossum bear netherlands parent world deeply deeply impact world war family soviet union context view human nature human inherently good inherently evil good evil guido van rossum ouch expect deep guess good evil potential lot depend circumstance context peter bell world soviet union europe sort suffering challenge kind set traumatic event emerge beautiful art music literature interview read hear say enjoy dutch literature child tell book influence childhood guido van rossum teenager favorite writer favorite dutch author guy name willem frederik hermans write certainly early novel sort ambiguous thing happen world war think young adult time write lot interesting good book think think peter bell nonfiction way guido van rossum fiction set ambiguous world resistance germans tell truly resistance spy germans character novel sort cross line find exactly happen peter bell novel good guy bad guy nature good evil clear hero guido van rossum hero main character anti hero heroic fail level accomplish lofty goal peter bell look trajectory rest life literature dutch english translation impact outside technical world exist guido van rossum read novel think impact directly peter bell impact work guido van rossum separate world work highly technical sort world art literature directly bearing peter bell think creative element design know design language art guido van rossum disagree say sort feel direct influence traditional art creativity peter bell right course feel mean deeply subconscious guido van rossum know peter bell know let early teen hobby build electronic circuit build mechanical model mind young guido ground desire create system create tinker joy puzzle solving guido van rossum think actually maybe end high school period feel confident design circuit sort interesting somewhat lot time literally take model kit follow instruction put thing mean think year build electronics kit understanding sort electronic understand mean debug sort follow instruction carefully stay naive model like build circuit like transistor work think day understanding coil capacitor actually sort major problem start build complex digital circuit unaware sort analog actually work thing schematic look look fine work realize megahertz level oscillation throw circuit sort wire close switch kind poorly build time think interesting instructive think echo time personal computer bear sense tinker circuit sense encroach revolution personal computing point sit ask predict think able successfully unroll process happen clue remember think summer senior year maybe summer junior year point think go trip math olympiad eastern europe like dutch team nerdy kid sort different experience tell amazing thing call computer hear word exploration electronic sort simple digital circuit sort idea somewhat understand digital calculator work maybe echo computer connection know parent pay magazine subscription punch card call computer involve read card transfer money account interested thing go university study math find computer student allow use suppose talk computer program feel like find yeah thing computer connect real world thing sort type program bunch punched card give punched card operator hour later operator give printout write program abstract remember foray programming sort simple math exercise learn programming language work sense okay year college computer able program generate output start see possibility continuation tinkering circuit start imagine personal computer tool like word processing tool maybe gaming start imagine go world robotic like frankenstein picture create artificial like entity computer think see way interested tinkering maybe sort complete coincidence end sort create programming language tool programmer focused sort activity program happen program write right remember remember maybe second year probably second actually point thing call conway game life probably familiar think think come scientific american column monthly column mathematical diversion blank guy famous time think column conway game life illustration write rule sort suggestion philosophically interesting conway call like page photocopy article remember get speak remember implement version game batch computer pascal program sort read initial situation input read number say generation print generation come page page sort thing remember later similar thing python original version write time find interesting combine trick learn electronics hobbyist time essentially paper design simple circuit build logic gate take bit input sort cell neighbor produce new value cell like combination half add clipping actually adder work translate series boolean operation pascal integer use integer bitwise value basically generate bit generation like instruction nice proud funny mention people know conway game life cellular automata single compute unit kind look neighbor figure look like generation base state neighbor deeply distribute system concept simple rule follow simple rule step look occur beautiful emergent complexity underlie rule simple emergent complexity funny thing implement thing comment proud hack run efficiently comment beautiful implementation comment fact emergent complexity code simple program step print follow generation generation stuff predict happen happen magic mean magic feel program create program run hello world show screen graphical component see magic mechanism create think go forth student incredibly small budget computer time use actually measure get trouble professor overspend department budget different story actually want efficient implementation want explore happen large number generation large size board implementation flawless feed different pattern think maybe follow article pattern like glider pattern repeat number generation translate position right like remember thing like glider gun google conway game life people aww ooh reason understand mean stephen wolfram obsess mathematical tool describe kind complexity emerge kind system way run convinced sort problem lend classic mathematical analysis theory create artificial intelligence artificial kind game life kind create universe let run create scratch design way code python program create fully intelligent system challenging need create universe like game life experiment lot different universe set rule essentially end repeat trivial way yeah stephen wolfram work simple rule say kind surprising quickly find rule create interesting thing able maybe universe laden rule create interesting thing look like human emergent phenomena interesting difficult create think sure let sort ask time world popular press kind captivate america idea artificial intelligence computer able think pretty soon touch science fiction reality way start read science fiction later think teenager read maybe bundle science fiction story background like thought sort computer build intelligent feel try design language different task programmer useful different tool available sort suitable different task write c code write shell code write thing python use language task demand time task actually demand certain language task write program solve problem x scratch like fix bug exist program x add small feature exist large program constrain choice language context like fact write certain language balance long write code long code run phase explore solution spend time write code run time run output want spend time code language like python make iteration fast few detail right program compile run library sort stuff sort quickly bunch exist component prototype application run like build electronic breadboard time sprawl circuit shake stop work function want work schematic design add sort figure oh perfect design radio light sensor okay design pcb solder component small space robust voltage fluctuation mechanical disruption know come design electronic know lot come write code initial step efficient fast stuff get way kind describe like darwin describe evolution specie right observe true python step act create language art month initial step specify bunch goal sort thing observe python goal create rule syntactic structure feature result beginning follow question evolution python beginning sit create lexical analyzer python big sort say want design scratch go borrow feature language like oh interesting basically exactly observe like yeah year old want sort create programming language go successful experience language let mid write parser work implementation abc spend year debate design abc author designer design design fully end implement join team borrow idea concept concrete sort local rule different language like indentation certain syntactic feature abc choose borrow string literal number work c thing funny sounding think surprisingly accurate practical title benevolent dictator life know decade actual title functionally speak decision design decision maybe let python release python example backward compatible python way lot people know deliberation discussion decision like yeah psychology experience regret aspect experience undergo yeah group process point bdfl certainly everybody sort respect position creator current sort owner language design look feedback sort python sense spark people community point oh issue sort bite user python take number python word call time say try sort small change language address word sort past take backwards compatibility seriously python word early version resolve resolve maintain backwards compatibility sort gradual path evolution language certain area stick number word widely recognize problem like roadblock sort thing people trip know thing people trip trip think backwards compatible way resolve issue option resolve issue right yes long time sort resign okay language go perfect way way way sort certain mean plenty thing particular detail well java r visual basic okay easily change bad little bit user education static analyzer warning parse thing think problem go away get bad future ultimately decision right tough decision history python benevolent dictator life maybe small scale decision tear tough decision probably resign right let hold second let interest time cool question let touch important dramatic beautiful certain kind way july year month ago write pep want fight hard pep find people despise decision like remove entirely decision process ordinary core developer available mentor people possibly available basically give permanent vacation bdfl benevolent dictator life shakespearean go appoint successor go create democracy anarchy dictatorship federation dramatic beautiful set statement open ended nature call community create future python kind beautiful aspect dramatic know make decision like heart mind step month later glad like writing actually write pretty quickly literally like month month go circle finally approve big hand design initiate originally sort give bunch nudge direction well language sorry ask async io actually small feature assignment expression lot debate lot people claim know pythonic pythonic know go destroy language like violation python fundamental design philosophy think bullshit favor think know python design philosophy tired stress thing literally sort announce go accept certain wednesday evening finally send email accept implement go bed feeling relieve wake thursday morning think go terrible debate time let stress pep decision resign sort think retirement half decade joke sort mention retirement sort tell community point future go retire fl title literally think okay day want good time wife go little beach town nearby think maybe minute write thing call shakespearean funny thing realize monumental decision minute later read link message twitter people discuss twitter guido resign bdfl post internal forum think read core developer think day news sort aspect element powerful element uncertainty lie ahead briefly talk example play guitar hobby fun play people super positive super friendly like awesome great enter outside observer enter programming community camp topic camp plus camp pretty harsh criticize oppose camp onlooker totally wrong think yeah holy war sort favorite activity programming community psychology okay healthy community productive force ultimately evolution language everybody pat tell truth good thing think middle ground sort nasty okay middle ground healthy ongoing criticism feedback productive mean level mean propose fix small issue code base chance reviewer sort respond say actually well way come decide future python core developer community think compete proposal constitution future fear future hope future confident future large think debate healthy productive actually write resignation email know python good spot python core developer community group people sort write review code go python people time large number different area expertise represent different level experience python core dev community different level experience completely outside software development general large system small system embed system feel okay resign know community care grab bag future feature development let ask comment maybe quickly concurrent programming parallel computing async io thing people express hope complain discuss reddit async io parallelization general packaging totally clueless pip install stuff apparently pipenv poetry dependency packaging system manage dependency emerge lot confusion right thing use functional programming go functional programming kind idea course gil connect parallelization suppose global interpreter lock problem comment whichever want comment let gil parallelization async io topic hopeful python develop sort high concurrency high parallelism language sort way language design way user use language way language implement pretty unlikely future think need way people use great concern think async io special case sort allow overlap io io sort good practice support high throughput io connection second worried think async io evolve couple compete package smart people sort push async io well parallel computing think python language way work expect write algorithm python compiler automatically parallelize use package like numpy bunch powerful package sort use cpus available tell package datum abstract operation apply world package implement usually tensorflow package come parallelize gpu example care term packaging comment future packaging python packaging favorite topic tough problem os platform want packaging packaging solution specific language linux compete packaging solution linux unix general work language language like node javascript ruby python packaging solution work ecosystem language use tough problem approach use system packaging system install python use python packaging system install party python package people year ago python packaging terrible situation nowadays pip future separate ecosystem numerical scientific python base anaconda live think need packaging extremely happy know issue bring interest time let sort skip million question watch half hour oral history computer history museum nice thing give linear progression interview give feeling life know life live interesting thing sort pretty good spend little existence earth outside family look journey proud moment stand accomplishment idea creation python stand thing look damn pretty good python definitely good thing sort creation python way sort raise python like baby conceive child raise child set child free world set child sort able care proud announcer monty python flying circus completely different favorite monty python moment moment hitchhiker guide literature movie crack think play dead parrot sketch oh brilliant favorite push daisy okay greta thank talk today lex great conversation feel understanding actually go inside computer know bit memory difficult program sort believe build intelligent sort satisfy definition intelligence think influential thing read early twenty gödel escherbach consciousness big eye opener sense sense brain time brain computer total separation way yeah pragmatically practically know limit memory limit sequential computing weakly paralyzed computing know hard create easy similarity brain computer oh yeah mean totally believe brain computer sense mean rule use play pretty different rule sort implement current hardware believe like separate thing infuse intelligence consciousness soul atheist probably year old think bit math universe parent atheist know atheist believe sort intelligence consciousness possibly emerge fix set rule camp totally sort give million year evolution take time dna particular machine sort encode information unlimited information chemical form figure way replicate think maybe million year ago think close half billion year ago sort originated change sort structure dna change like binary code hardware mean basic programming language change maybe programming obviously sort happen set rule good sort develop endless variability sort idea self replicate molecule compete resource type eventually sort take happen fossil know exactly happen believe clear happen comment consciousness think talk program bit talk know intelligence connect program fundamentally consciousness thing think developer programming language human pretty sort separate topic sort line work work programming involve go direction develop intelligence consciousness sort privately avid reader popular science writing thought actually believe consciousness thing feeling forget read influence feel look cat dog mouse form intelligence look fish form intelligence evolution take long time feel sort evolution intelligence lead sort human form intelligence follow evolution sense especially visual sense mean enormous processing need interpret scene human well computer feeling sort reason like mammal particular develop level consciousness eventually sort go intelligence self awareness consciousness sort robot highly develop sense lot rich sensory information come interesting thought basic mechanism dna basic building block programming add ability high resolution sensor sensor stack thing basic programming try survive develop interesting thing start human appear like intelligence consciousness far robot think self drive car sort great opportunity develop like drive pay attention rule road look clue oh shopping district oh old lady cross street oh carry pile mail mailbox bet go cross street reach mailbox slow think turn observation understanding consciousness go system world go oh tree go fall sort expect go unconscious go self drive car network bazillion computer google amazon datum center networked sense actually highlight work thomas vehicles highlight big gap currently truly need able solve problem formulation consciousness intelligence basically system order interact human oppose kind abstract notion consciousness consciousness need able empathize able fear understand fear death aspect important interact pedestrian need able basic computation base human desire thought sort yeah look dog dog clearly know mean dog owner friend dog dog clearly know human go model human go learn dog know go want sad leave cry afraid mistreat young assign sort consciousness dog think think consciousness intelligence spectrum interesting return programming language way think build kind thing build intelligence build consciousness build artificial being think exciting idea come century leibniz hobbes descartes feeling convert thought reasoning thing find special brain convert logic formalize formal reasoning formalize knowledge calculate brain calculate idea possible actually program aware concept pattern match sense aware sort thought discover incredible bit mathematic like newton calculus sort idealism sort extension logic math sort go line think like yeah logic like bunch rule bunch input realize recognize face bunch rule shit ton datum plus circuit sort interpret visual clue context massively parallel pattern match store rule mean tomorrow dropbox office recognize wear different shirt yeah tomorrow coffee shop belmont idea beach kind mistake time know like oh person colleague wife movie recognize pattern matching rule unable encode piece information look room wear black shirt certain height human probably ten thousand fact pick moment moment scene grant aggregate understand scene think encode end day table calculate know mean mean yes sense actual magic layer abstraction fact enter eye ear understanding scene think ai cover distance like human body realize build atom uselessly reductionist view right body build organ organ build cell cell build protein protein build amino acid amino acid build atom quantum mechanic pragmatic view mean obviously engineer agree kind view consider sam harris view intelligence information processing like say sensory information stuff come action intelligent make sound easy know sam harris oh philosopher like philosopher think right essentially descartes wait minute like say magic basically say appear like magic know little magic know atom know organ fact know little atom organ way recreatable mean excited fact figure atom right take fact sensory organ turn reason action sort lot abstraction figure deal mean know tangent simple program parse compiler parse program sense input routine compiler parser sense organ build mighty complicated internal representation program see linear sequence byte represent text program anymore abstract syntax tree know viewer listener familiar compiler technology few few day right true probably people want shortcut sort abstraction data structure compiler use produce output relevant like translation program machine code execute hardware datum structure get throw away fish fly see sort get visual impulse sure build datum structure fly minimal fly mean case fly brain imagine layer abstraction dark sense motion fly sort respond arm clearly visual processing intelligent intelligent abstraction motion similar thing complicated brain mean drive car incredibly good abstraction motion yeah sense abstraction motion probably primary source information know think know build abstraction build complicated datum structure base build persistent datum structure sort processing information sort get store memory pretty permanently available recall mean thing sort conscious remember like phone number age write imagine remember seven number digit reproduce sort repeat time fairly conscious form memorization hand recognize face idea brain bunch specialized hardware know recognize face know sort code dna train age zero brain know lot thing like useful interaction human conscious anymore right actual day day life operate high level abstraction conscious little detail underlie compiler like turtle turtle turtle way compiler way essentially magic try think descartes start train say magic mean descarte notion soul body fundamentally separate separate yeah think write god political reason know actually historian notion reasoning human thought formalize think continue century russell gadot incompleteness theorem debate limit thing formalize turing machine come exciting idea mean underlie lot computing lot computer encode lot stuff talk term recognize face theoretically algorithm run computer context like ask programming philosophical way mean program computer say write python program compile program compile byte code form layer program layer abstraction high programming context get high high level abstraction think point high level abstraction call programming resemble programming moment source code mean source code sort low level machine like molecule electron sort protein brain program system administration know machine run machine different level abstraction sense far understand way decade people progress thing like facial recognition self driving car endless endless amount training datum lay person feel totally lay person field look like researcher publish result necessarily know exactly algorithm work upset sort read sort fluff piece facebook newspaper social network algorithm like totally different interpretation word algorithm way train learn year old algorithm set rule completely understand mathematically analyze prove thing like prove aristotelian sieve produce prime number prime number yeah know know andrej karpathy afraid head ai tesla stanford cheeky way call concept software let disentangle second kind refer traditional algorithm concept algorithm clear read understand prove function kind software software exactly describe neural network type machine learn feed bunch datum neural network learn function specify input output want look inside analyze train function map input output give lot datum programming get lot datum programming program programming programming different activity like build organ cell call chemistry let step think sort generally course know like parent teach kid thing call programming sense programming provide datum example use case imagine write function loop clearly readable text say lot example function lot example take function figure rest concept question like fuzzy way reality lot pattern recognition system fuzzy way quote unquote programming think kind world call totally different programming software engineer mean design system systematically test evaluate specific specification fuzzy software world machine learn world totally intermix possible question probably ask know software actually think truism task ai tackle past point realize long consider artificial intelligence long necessary use term oh know new field science engineering develop know sort form learning sort control computer system call programming know maybe focus terminology expect different concept people sort different education different model try develop concept guess comment way concept think kind function neural network provide thing oppose able upfront prove work case throw able bad case analysis versus average case analysis able test work time guarantee fail unexpected way example fail unexpected way like good time room current way think programming program actually sort get point sort ideal bug free program abandon long ago software developer care bug manifest annoying willing occasional crash outage incorrect result grant possibly programmer code bug free incredibly tedious business try throw formal method tedious user click link error average user panic click work well second time magically try way perform task sort end end recovery mechanism inside system sort retrie timeout fallback imagine sort biological system survive think programming teach think exactly say come kind deny fact sort basic programming education sort program have student write small simple bug find fix sort programming teach elementary middle school high school introduction programming class college typically programming small class sort actually teach software engineering build large system summer dropbox large number intern tech company west coast thing intern amazed time life go large software development environment learn college small scale difference scale make qualitative difference thing think step decade think python world programming language think system large underlying google facebook dropbox think python actually catch surprise sort yeah pretty stage computing maybe speak interview think evolution programming language fascinating especially lead perspective great great degree intelligence learn programming language play russia turtle logo logo yeah look list programming language play little bit mean beautiful different way fortran cobalt lisp algol basic logo c object orient come simula pascal smalltalk lead classic classic yeah classic hit right steam build lisp database sql lead python pascal python matlab kind different community different language talk world know sort python come abc actually know language having research conversation go abc look remarkably lot annoying quality underneath like cap underneath element python get good stuff good stuff world swim programming language focused good stuff specific circle sense chase say programming language build scratch itch aware itch community yes mean itch try scratch python glad aware itch probably able mean try solve problem solve yeah overwhelming focused problem want programming language sit shell scripting arguably like high level low level python sort language intermediate level pretty high level end think want tool use productive programmer specific environment give time budget development tool sort month design like think feature language syntactically semantically implement pipeline parse source code execute think timeline goal like productivity core goal like decade century machine learning ai programming research people little mechanical engineering electrical engineering matlabby little bit matlab focus world maybe little bit java people interested emphasize object orient nature thing year especially oncoming neural network package build python interface neural network switch python notice significant boost exactly think exactly word productive able job fast think qualitative difference know quantitative feeling know actually productive think probably yeah right think element let speak aspect think affect productivity enjoy create performant code create beautiful structure know kind go especially new new standard template programming create beautiful formal structure find spend time oppose get parse file extract keyword task try python think productivity general design sort decade decade think mean productive programmer,"['Guido van Rossum', 'Lex Friedman', 'Peter Bell', 'Willem Frederik Hermans', 'Stephen Wolfram', 'Gödel Escherbach', 'Thomas Vehicles', 'Sam Harris', 'Andrej Karpathy']","['Python Software Foundation', 'Dropbox', 'Google']","['Python Programming Language', 'Cloud Computing Platforms', 'Big Data Analytics']","['Programming Languages', 'Software Development Practices', 'Open Source Development', 'Technological Innovation', 'Online Communities and Knowledge Sharing']"
7,Jeff Atwood,Stack Overflow and Coding Horror,"The following is a conversation with Jeff Atwood. He is the cofounder of Stack Overflow and Stack Exchange, websites that are visited by millions of people every single day. Much like with Wikipedia, it is difficult to understate the impact on global knowledge and productivity that these networks of sites have created. Jeff is also the author of the famed blog Coding Horror and the founder of Discourse, an open source software project that seeks to improve the quality of our online community discussions. This conversation is part of the MIT course on artificial general intelligence and the artificial intelligence podcast. If you enjoy it, subscribe on YouTube, iTunes, or your podcast provider of choice, or simply connect with me on Twitter at Lex Friedman, spelled F R I D. And now, here's my conversation with Jeff Atwood. Having co created and managed for a few years the world's largest community of programmers in Stack Overflow 10 years ago, what do you think motivates most programmers? Is it fame, fortune, glory, process of programming itself, or is it the sense of belonging to a community? It's puzzles, really. I think it's this idea of working on puzzles independently of other people and just solving a problem, sort of like on your own almost. Although, nobody really works alone in programming anymore. But I will say there's an aspect of hiding yourself away and just beating on a problem until you solve it, like brute force basically to me is what a lot of programming is. The computer's so fast that you can do things that would take forever for a human, but you can just do them so many times and so often that you get the answer. You're saying just the pure act of tinkering with the code is the thing that drives most problems. The struggle balance within the joy of overcoming, the brute force process of pain and suffering that eventually leads to something that actually works. Well, data's fun, too. There's this thing called the shuffling problem. The naive shuffle that most programmers write has a huge flaw, and there's a lot of articles online about this because it can be really bad if you're a casino and you have an unsophisticated programmer writing your shuffle algorithm. There's surprising ways to get this wrong, but the neat thing is the way to figure that out is just to run your shuffle a bunch of times and see how many orientations of cards you get. You should get an equal distribution of all the cards. And with the naive method of shuffling, if you just look at the data, if you just brute force it and say, OK, I don't know what's going to happen, you just write a program that does it a billion times and then see what the buckets look like of the data. And the Monty Hall problem is another example of that, where you have three doors and somebody gives you information about another door. So the correct answer is you should always switch in the Monty Hall problem, which is not intuitive, and it freaks people out all the time. But you can solve it with data. If you write a program that does the Monty Hall game and then never switches, then always switches, just compare, you would immediately see that you don't have to be smart. You don't have to figure out the answer algorithmically. You can just brute force it out with data and say, well, I know the answer is this because I ran the program a billion times, and these are the data buckets that I got from it. So empirically find it. But what's the joy of that? So for you, for you personally, outside of family, what motivates you in this process? Well, to be honest, I don't really write a lot of code anymore. What I do at Discourse is managery stuff, which I always despised. As a programmer, you think of managers as people who don't really do anything themselves. But the weird thing about code is you realize that language is code. The ability to direct other people lets you get more stuff done than you could by yourself anyway. You said language is code? Language is code. Meaning communication with other humans? Yes, it is. You can think of it as a systematic. So what is it like to be, what makes, before we get into programming, what makes a good manager? What makes a good leader? Well, I think a leader, it's all about leading by example, first of all, sort of doing and being the things that you want to be. Now, this can be kind of exhausting, particularly when you have kids, because you realize that your kids are watching you all the time, even in ways that you've stopped seeing yourself. The hardest person to see on the planet is really yourself. It's a lot easier to see other people and make judgments about them. But yourself, you're super biased. You don't actually see yourself the way other people see you. Often, you're very, very hard on yourself in a way that other people really aren't going to be. So that's one of the insights is you've got to be really diligent about thinking, am I behaving in a way that represents how I want other people to behave, like leading through example? There's a lot of examples of leaders that really mess this up, like they make decisions that are like, wow, it's a bad example for other people. So I think leading by example is one. The other one I believe is working really hard. And I don't mean working exhaustively, but showing a real passion for the problem, not necessarily your solution to the problem, but the problem itself is just one that you really believe in. Like with discourse, for example, the problem that we're looking at, which is my current project, is how do you get people in groups to communicate in a way that doesn't break down into the howling of wolves? How do you deal with trolling? Not like technical problems. How do I get people to post paragraphs? How do I get people to use bold? How do I get people to use complete sentences, although those are problems as well? But how do I get people to get along with each other and then solve whatever problem it is they set out to solve, or reach some consensus on discussion, or just not hurt each other even? Maybe it's a discussion that doesn't really matter, but are people yelling at each other? And why? Like that's not the purpose of this kind of communication. So I would say leadership is about setting an example, doing the things that represent what you want to be, and making sure that you're actually doing those things. And there's a trick to that too, because the things you don't do also say a lot about what you are. Yeah, so let's pause on that one. So those two things are fascinating. So how do you have as a leader that self awareness? So you just said it's really hard to be self aware. So for you personally, or maybe for other leaders you've seen or look up to, how do you know both that the things you're doing are the wrong things to be doing, the way you speak to others, the way you behave, and the things you're not doing? How do you get that signal? I think there's two aspects to that. One is like processing feedback that you're getting, so. How do you get feedback? Well, right, so are you getting feedback, right? So one way we do it, for example, with discourse, we have three cofounders, and we periodically talk about decisions before we make them. So it's not like one person can make a mistake, or like, wow, there can be misunderstandings, things like that. So it's part of like group consensus of leadership is like it's good to have, I think systems where there's one leader, and that leader has the rule of absolute law are just really dangerous in my experience. For communities, for example, like if you have a community that's run by one person, that one person makes all the decisions, that person's gonna have a bad day. Something could happen to that person, something, there's a lot of variables. So like first, when you think about leadership, have multiple people doing leadership and have them talk amongst each other. So giving each other feedback about the decisions that they're making. And then when you do get feedback, I think there's that little voice in your head, right? Or your gut or wherever you wanna put it in your body. I think that voice is really important. Like I think most people who have any kind of moral compass or like want to do, most people want to do the right thing. I do believe that. I mean, there might be a handful of sociopaths out there that don't, but most people, they want other people to think of them as a good person. And why wouldn't you, right? Like, do you want people to despise you? I mean, that's just weird, right? So you have that little voice that sort of the angel and devil on your shoulder sort of talking to you about like what you're doing, how you're doing, how does it make you feel to make these decisions, right? And I think having some attunement to that voice is important. But you said that voice also for, I think this is a programmer situation too, where sometimes the devil on the shoulder is a little too loud. So you're a little too self critical for a lot of developers, and especially when you have introverted personality. How do you struggle with a self criticism or the criticism of others? So one of the things of leadership is to do something that's potentially unpopular or where people doubt you and you still go through with the decision. So what's that balance like? I think you have to walk people through your decision making, right? Like you have to, this is where blogging is really important and communication is so important. Again, code language is just another kind of code. It's like, here is the program by which I arrived at the conclusion that I'm gonna reach, right? It's one thing to say like, this is a decision, it's final, deal with it, right? That's not usually satisfying to people. But if you say, look, we've been thinking about this problem for a while. Here's some stuff that's happened. Here's what we think is right. Here's our goals. Here's what we wanna achieve. And we've looked at these options and we think this available options is the best option. People will be like, oh, okay, right? Maybe I don't totally agree with you, but I can kind of see where you're coming from and I see it's not just arbitrary decision delivered from a cloud of flames in the sky, right? It's like a human trying to reach some kind of consensus about goals. And their goals might be different than yours. That's completely legit, right? But if you're making that clear, it's like, oh, well, the reason we don't agree is because we have totally different goals, right? Like, how could we agree? It's not that you're a bad person. It's that we have radically different goals in mind when we started looking at this problem. And the other one you said is passion. So, or hard work, sorry. Well, those are tied together in my mind. Let's say hard work and passion. Like for me, like I just really love the problem discourse is setting out to solve because in a way it's like, there's a vision of the world where it all devolves into Facebook basically owning everything and every aspect of human communication, right? And this has always been kind of a scary world for me. First, cause I don't, I think Facebook is really good at execution. I got to compliment them. They're very competent in terms of what they're doing, but Facebook has not much of a moral compass in terms of Facebook cares about Facebook, really. They don't really care about you and your problems. What they care about is how big they can make Facebook, right? Is that you talking about the company or just the mechanism of how Facebook works? Kind of both really, right? Like, and the idea with discourse, the reason I'm so passionate about it is cause I believe every community should have the right to own themselves, right? Like they should have their own software that they can run that belongs to them. That's their space where they can set the rules. And if they don't like it, they can move to different hosting or, you know, whatever they need to happen can happen. But like this idea of a company town where all human communication is implicitly owned by WhatsApp, Instagram, and Facebook. And it's really disturbing too, cause Facebook is really smart. Like I said, they're great at execution. Buying in WhatsApp and buying Instagram were incredibly smart decisions. And they also do this thing, I don't know if you know, but they have this VPN software that they give away for free on smartphones and it indirectly feeds all the data about the traffic back to Facebook. So they can see what's actually getting popular through the VPNs, right? They have low level access to the network data because users have let them have that. So. So let's take a small pause here. First of all, discourse. Can you talk about, can you lay out the land of all the different ways you can have communities? So there's Stack Overflow that you've built. There's discourse. So Stack Overflow is kind of like a Wiki, Wikipedia you talk about. And it's a very specific scalpel, very focused. So what is the purpose of discourse and maybe contrast that with Facebook? First of all, say, what is discourse? Yeah. Start from the beginning. Well, let me start from the very beginning. So Stack Overflow is a very structured Wiki style Q and A for programmers, right? And that was the problem we first worked on. And when we started, we thought it was discussions because we looked at like programming forums and other things, but we quickly realized we were doing Q and A, which is a very narrow subset of human communication, right? Sorry, so when you started Stack Overflow, you thought you didn't even know the Q and A. Not really. You didn't know it would be Q and A. Well, we didn't know. We had an idea of like, okay, these are things that we see working online. We had a goal, right? Our goal was there was this site, Experts Exchange, with a very unfortunate name. Thank you for killing that site. Yeah, I know, right? Like a lot of people don't remember it anymore, which is great. Like that's the measure of success when people don't remember the thing that you were trying to replace, then you've totally won. So it was a place to get answers to programming questions, but it wasn't clear if it was like focused Q and A, if it was a discussion. There were plenty of programming forums. So we weren't really sure. We were like, okay, we'll take aspects of dig and Reddit, like voting were very important. Reordering answers based on votes. Wiki style stuff of like being able to edit posts, not just your posts, but other people's posts to make them better and keep them more up to date. Ownership of blogging of like, okay, this is me. I'm saying this in my voice, this is the stuff that I know. And your reputation accrues to you and it's peer recognition. So you asked earlier, like what motivates programmers? I think peer recognition motivates them a lot. That was one of the key insights of Stack Overflow was like recognition from your peers is why things get done. Not necessarily money, not necessarily your boss, but like your peers saying, wow, this person really knows their stuff, has a lot of value. So the reputation system came from that. So we were sort of Frankensteining a bunch of stuff together in Stack Overflow, like stuff we had seen working and we knew worked and that became Stack Overflow. Over time, we realized it wasn't really discussion. It was very focused questions and answers. There wasn't a lot of room on the page for let me talk about this tangential thing. It was more like, okay, is it answering the question? Is it clarifying the question? Or could it be an alternative answer to the same question? Because there's usually more than one way to do it in programming, there's like say five to 10 ways. And one of the patterns we got into early on with Stack Overflow was there were questions where there would be like hundreds of answers. And we're like, wow, how can there be a programming question with 500, 200, 500 answers? And we looked at those and we realized those were not really questions in the traditional sense. They were discussions. It was stuff that we allowed early on that we eventually decided wasn't allowed such as what's your favorite programming food? What's the funniest programming cartoon you've seen? And we had to sort of backfill a bunch of rules about like, why isn't this allowed? Such as, is this a real problem you're facing? Like nobody goes to work and says, wow, I can't work cause I don't know what the funniest programming cartoon is. So sorry, can't compile this code now, right? It's not a real problem you're facing in your job. So that was run rule. And the second, like, what can you really learn from that? It's like what I call accidental learning or Reddit style learning. Where you're just like, oh, I'll just browse some things and oh, wow, you know, did you know tree frogs only live three years? I mean, I just made that up. I don't know if that's true. But I didn't really set out to learn that. I don't need to know that, right? It's accidental learning. It was more intentional learning where you're like, okay, I have a problem. And I want to learn about stuff around this problem having, right? And it could be theory, it could be compiler theory, it could be other stuff, but I'm having a compiler problem. Hence, I need to know the compiler theory, that aspect of it that gets me to my answer, right? So kind of a directed learning. So we had to backfill all these rules as we sort of figured out what the heck it was we were doing. And the system came very strict over time. And a lot of people still complain about that. And I wrote my latest blog entry, what does Stack Overflow want to be when it grows up? Celebrating the 10 year anniversary, yeah. Yeah, so 10 years. And the system has trended towards strictness. There's a variety of reasons for this. One is people don't like to see other people get reputation for stuff as they view as frivolous, which I can actually understand. Because if you saw a programmer got like 500 upvotes for funniest programming cartoon or funniest comment they had seen in code, it's like, well, why do they have that reputation? Is it because they wrote the joke? Probably not. I mean, if they did, maybe, or the cartoon, right? They're getting a bunch of reputation based on someone else's work that's not even programming. It's just a joke, right? It's related to programming. So you begin to resent that. You're like, well, that's not fair. And it isn't. At some level, they're correct. I mean, I empathize. Because it's not correct to get reputation for that. Versus here's a really gnarly regular expression problem. And here's a really clever, insightful, detailed answer laying out, oh, here's why you're seeing the behavior that you're seeing. Here, let me teach you some things about how to avoid that in the future. That's great. That's gold, right? You want people to get reputation for that, not so much for, wow, look at this funny thing I saw, right? Great. So there's this very specific Q&A format. And then take me through the journey towards discourse and Facebook and Twitter. So you started at the beginning that Stack Overflow evolved to have a purpose. So what is discourse, this passion you have for creating community for discussion? When was that born and how? Well, part of it is based on the realization that Stack Overflow is only good for very specific subjects where it's based on data, facts, and science, where answers can be kind of verified to be true. Another form of that is there's the book of knowledge, like the tome of knowledge that defines whatever it is. You can refer to that book and it'll give you the answer. There has to be, it only works on subjects where there's like semi clear answers to things that can be verified in some form. Now again, there's always more than one way to do it. There's complete flexibility and system around that. But where it falls down is stuff like poker and LEGO. Like we had, if you go to stackexchange.com, we have an engine that tries to launch different Q&A topics, right? And people can propose Q&A topics, sample questions, and if it gets enough support within the network, we launched that Q&A site. So some of the ones we launched were poker and LEGO and they did horribly, right? Because I mean, they might still be there lingering on in some form, but it was an experiment. This is like a test, right? And some subjects work super well on the stack engine and some don't. But the reason LEGO and poker don't work is because they're so social, really. It's not about what's the rule here in poker. It's like, well, what kind of cigars do we like to smoke while playing poker? Or what's a cool set of cards to use when I'm playing poker? Or what's some strategies? Say I have this hand come up with some strategies I could use. It's more of a discussion around what's happening with LEGO. Same thing, here's this cool LEGO set I found. Look how awesome this is. And I'm like, yeah, that's freaking awesome, right? It's not a question, right? There's all these social components and discussions that don't fit at all. We literally have to disallow those in Stack Overflow because it's not about being social. It's about problems that you're facing in your work that you need concrete answers for. You have a real demonstrated problem that's blocking you in something. Nobody's blocked by, what should I do when I have a straight flush? It's not a blocking problem in the world. It's just an opportunity to hang out and discuss. So discourse was a way to address that and say, look, discussion forum software was very, very bad. And when I came out of Stack Overflow in early 2012, it was still very, very bad. I expected it improved in the four years since I last looked, but it had not improved at all. And I was like, well, that's kind of terrible because I love these communities of people talking about things that they love. They're just communities of interest, right? And there's no good software for them. Startups would come to me and say, hey, Jeff, I want to have this startup. Here's my idea. And the first thing I would say to them is, well, first, why are you asking me? I don't really know your field necessarily. Why aren't you asking the community, the people that are interested in this problem, the people that are using your product, why aren't you talking to them? And then they'd say, oh, great idea. How do I do that? And then that's when I started playing sad trombone because I realized all the software involving talking to your users, customers, audience, patrons, whatever it is, it was all really bad. It was stuff that I would be embarrassed to recommend to other people. And yet, that's where I felt they could get the biggest and strongest, most effective input for what they should be doing with their product, right? It's from their users, from their community, right? That's what we did on Stack Overflow. So what we're talking about with forums, the, what is it, the dark matter of the internet, it's still, I don't know if it's still, but for the longest time, it has some of the most passionate and fascinating discussions. And what's the usual structure? There's usually, it's linear, so it's sequential. So you're posting one after the other and there's pagination, so it's every, there's 10 posts and then you go to the next page. And that format still is used by, like I'm, we're doing a lot of research with Tesla vehicles and there's a Tesla Motors Club forum, which is extremely. We really wanted to run that actually. They pinged us about it, I don't think we got it, but I really would have liked to gotten that one. But they've started before even 2012, I believe. It's like, you don't want a heartbeat that's like so fast. It's like you're just freaking out. But it is a measure of health. You should have a healthy heartbeat. It's up to people listening to decide what that means. But it has to be healthy. It has to be reasonable. Because otherwise, you're just going to be frustrated because that's how you build software. You make mistakes. You roll it out. You live with it. You see what it feels like and say, oh, God, that was a terrible idea. Oh, my gosh, this could be even better if we did Y, right? You turn the crank. And then the more you do that, the faster you get ahead of your competitors ultimately. It's rate of change, right? Delta V, right? How fast are you moving? Well, within a year, you're going to be miles away by the time they catch up with you, right? That's the way it works. And plus, as a software developer and user, I love software that's constantly changing. Because I don't understand people who get super pissed off when like, oh, they changed the software on me. How dare they? I'm like, yes, change the software. Change it all the time, man. That's what makes this stuff great is that it can be changed so rapidly and become something that is greater than it is now. Now, granted, there are some changes that suck. I admit. I've seen it many times. But in general, that's what makes software cool, right? It's that it is so malleable. Fighting that is weird to me. Because it's like, well, you're fighting the essence of the thing that you're building. That doesn't make sense. You want to really embrace that. Not to be a hummingbird, but embrace it to a healthy cycle of your heartbeat, right? So you talk about that people really don't change. It's true. That's why probably a lot of the stuff you write about in your blog probably will remain true. Well, there's a flip side of the coin. People don't change. Like, investing and understanding people is like learning Unix in 1970. Because nothing has changed, right? All those things you've learned about people will still be valid 34 years from now. Whereas if you learn the latest JavaScript framework, that's going to be good for like two years, right? Exactly. But if you look at the future of programming, so there's a people component, but there's also the technology itself. What do you see as the future of programming? Will it change significantly, or as far as you can tell, people are ultimately programming, and so it's not something that you foresee changing in any fundamental way? Well, you've got to go look back on sort of the basics of programming. And one of things that always shocked me is like source control. Like, I didn't learn anything about source control. Granted, I graduated from college in 1992. But I remember hearing from people as late as like 1998, 1999, like even maybe today, they're not learning source control. And to me, it's like, well, how can you not learn source control? That is so fundamental to working with other programmers, working in a way that you don't lose your work. Just basic software, the literal bedrock of software development is source control. Now, you compare it today, like GitHub, right? Like Microsoft bought GitHub, which I think was an incredibly smart acquisition move on their part. Now they have anybody who wants reasonable source control to go sign up on GitHub. It's all set up for you, right? There's tons of walkthroughs, tons of tutorials. So from the concept of like, has programming advanced from, say, 1999, it's like, well, hell, we have GitHub. I mean, my god, yes, right? Like, it's massively advanced over what it was. Now, as to whether programming is significantly different, I'm going to say no. But I think the baseline of what we view as fundamentals will continue to go up and actually get better, like source control. That's one of the fundamentals that has gotten hundreds of orders of magnitude better than it was 10, 20 years ago. So those are the fundamentals. Let me introduce two things that maybe you can comment on. So one is mobile phones. So that could fundamentally transform what programming is, or maybe not. Maybe you can comment on that. And the other one is artificial intelligence, which promises to, in some ways, to do some of the programming for you is one way to think about it. So it's really what a programmer is, is using the intelligence that's inside your skull to do something useful. The hope with artificial intelligence is that it does some of the useful parts for you where you don't have to think about it. So do you see smartphones, the fact that everybody has one, and they're getting more and more powerful as potentially changing programming? And do you see AI as potentially changing programming? OK, so that's good. So smartphones have definitely changed. I mean, since, I guess, 2010 is when they really started getting super popular. I mean, in the last eight years, the world has literally changed, right? Everybody carries a computer around, and that's normal. I mean, that is such a huge change in society. I think we're still dealing with a lot of the positive and negative ramifications of that, right? Everybody's connected all the time. Everybody's on the computer all the time. That was my dream world as a geek, right? But it's like, be careful what you ask for, right? Like, wow, now everybody has a computer. It's not quite the utopia that we thought it would be, right? Computers can be used for a lot of stuff that's not necessarily great. So to me, that's the central focus of the smartphone, is just that it puts a computer in front of everyone. Granted, a small, touch screen, smallish, touch screen computer. But as for programming, I don't know. I don't think that I've kind of, over time, come to subscribe to the Unix view of the world when it comes to programming. You want to teach these basic command line things, and that is just what programming is going to be for, I think, a long, long time. I don't think there's any magical visual programming that's going to happen. I don't know. I've, over time, have become a believer in that Unix philosophy of just, you know, they kind of had to write with Unix. That's going to be the way it is for a long, long time. And we'll continue to, like I said, raise the baseline. The tools will get better. It'll get simpler. But it's still fundamentally going to be command line tools, fancy IDEs. That's kind of it for the foreseeable future. I'm not seeing any visual programming stuff on the horizon. Because you kind of think, like, what do you do on a smartphone that will be directly analogous to programming? Like, I'm trying to think, right? And there's really not much. So not necessarily analogous to programming, but the kind of things that, the kind of programs you would need to write might need to be very different. Yeah. And the kind of languages. I mean, but I probably also subscribe to the same, just because everything in this world might be written in JavaScript. Oh, yeah. That's already happening. I mean, discourse is a bet. Discourse itself, JavaScript, is another bet on that side of the table. And I still try and believe in that. So I would say smartphones have mostly a cultural shift more than a programming shift. Now, your other question was about artificial intelligence and sort of devices predicting what you're going to do. And I do think there's some strength to that. I think artificial intelligence is kind of overselling it in terms of what it's doing. It's more like, people are predictable, right? People do the same things. Let me give you an example. One check we put in a discourse that's been a lot of big commercial websites is, say you log in from New York City now. And then an hour later, you log in from San Francisco. It's like, well, hmm, that's interesting. How did you get from New York to San Francisco in one hour? So at that point, you're like, OK, this is a suspicious login at that point. So we would alert you. It's like, OK. But that's not AI, right? That's just a heuristic of like, how did you, in one hour, get 2,000 miles, right? That doesn't. I mean, you're grand. Maybe you're on a VPN. There's other ways to happen. That's just a basic prediction based on the idea that people pretty much don't move around that much. They may travel occasionally. But nobody, unless you're a traveling salesman that's literally traveling the world every day, there's so much repetition and predictability in terms of things you're going to do. And I think good software anticipates your needs. For example, Google, I think it's called Google Now or whatever that Google thing is that predicts your commute and predicts, based on your phone location, where are you every day? Well, that's probably where you work, that kind of stuff. I do think computers can get a lot better at that. I hesitate to call it full blown AI. It's just computers getting better at like, first of all, they have a ton of data because everybody has a smartphone. Now, all of a sudden, we have all this data that we didn't have before about location, about communication, and feeding that into some basic heuristics and maybe some fancy algorithms that turn it into predictions of anticipating your needs, like a friend would, right? Like, oh, hey, I see your home. Would you like some dinner, right? Like, let's go get some food, because that's usually what we do at this time of day, right? In the context of actually the act of programming, do you see IDEs improving and making the life of programming as better? I do think that is possible, because there's a lot of repetition in programming, right? Oh, you know, Clippy would be the bad example of, oh, I see. It looks like you're writing a for loop. But there are patterns in code, right? And actually, libraries are kind of like that, right? Rather than go code up your own HTTP request library, it's like, well, you'd use one of the existing ones that we have. That's already a troubleshot, right? It's not AI, per se. It's just building better LEGO bricks, bigger LEGO bricks, that have more functionality in them, so people don't have to worry about the low level stuff as much anymore. Like, WordPress, for example, to me, is like a tool for somebody who isn't a programmer to do something. I mean, you can turn WordPress into anything. It's kind of crazy, actually, through plugins, right? And that's not programming, per se. It's just LEGO bricks stacking WordPress elements, right? And a little bit of configuration glue. So I would say, maybe in a broader sense, what I'm seeing, like, there'll be more gluing and less actual programming. And that's a good thing, right? Because most of the stuff you need is kind of out there already. You said 1970s, Unix. Do you see PHP and these kind of old remnants of the early birth of programming remaining with us for a long time? Like you said, Unix in itself. Do you see, ultimately, this stuff just being there out of momentum? I kind of do. I mean, I was a big believer in Windows early on. And I was a big, you know, I was like, Unix, what a waste of time. But over time, I've completely flipped on that, where I was like, okay, the Unix guys were right. And pretty much Microsoft and Windows were kind of wrong, at least on the server side. Now, on the desktop, right, you need a GUI, you need all that stuff. And you have the two philosophies, like Apple built on Unix, effectively, Darwin. And on the desktop, it's a slightly different story. But on the server side, where you're gonna be programming. Now, it's a question of where the programming's gonna be. There's gonna be a lot more like client side programming, because technically, discourse is client side programming. The way you get discourse, we deliver a big ball of JavaScript, which is then executed locally. So we're really using a lot more local computing power. We'll still retrieve the data, obviously, we have to display the posts on the screen and so forth. But in terms of like sorting and a lot of the basic stuff, we're using the host processor. But to the extent that a lot of programming is still gonna be server side, I would say, yeah, the Unix philosophy definitely won. And there'll be different veneers over Unix, but it's still, if you peel away one or two layers, it's gonna be Unixy for a long, I think Unix won. I mean, so definitively. It's interesting to hear you say that, because you've done so much excellent work on the Microsoft side in terms of backend development. Cool. So what's the future hold for Jeff Atwood? I mean, the discourse, continuing the discourse in trying to improve conversation on the web? Well, discourse is what I've viewed as a, and originally I called it a five year project, then really quickly revised that to a 10 year project. So we started in early 2013, that's when we launched the first version. So we're still five years in. This is the part where it starts getting good. Like we have a good product now. Discourse, there's any project you build in software, it takes three years to build what you want it to build anyway. Like V1 is gonna be terrible, which it was. But you ship it anyway, because that's how you get better at stuff. It's about turning the crank. It's not about V1 being perfect, because that's ridiculous. It's about V1, then let's get really good at V1.1, 1.2, 1.3, like how fast can we iterate? And I think we're iterating like crazy on discourse, to the point that like, it's a really good product now. We have serious momentum. And my original vision was, I wanna be the WordPress of discussion. Meaning someone came to you and said, I wanna start a blog. Although the very question is kind of archaic now. It's like, who actually blogs anymore? But I wanted the answer to that to be, it would be WordPress normally, because that's the obvious choice for blogging most of the time. But if someone said, hey, I need a group of people to get together and do something, the answer should be discourse, right? That should be the default answer for people. Because it's open source, it's free, doesn't cost you anything. You control it, you can run it. Your minimum server cost for discourse is five bucks a month at this point. They actually got the VPS prices down. It used to be $10 a month for one gigabyte of RAM, which we have a kind of heavy stack. Like there's a lot of stuff in discourse. You need Postgres, you need Redis, you need Ruby, and Rails, you need a sidekick for scheduling. It's not a trivial amount of stuff because we were architected for like, look, we're building for the next 10 years. I don't care about shared PHP hosting. That's not my model. My idea is like, hey, eventually, this is gonna be very cheap for everybody and I wanna build it right. Using again, higher, bigger building block levels, right? That have more requirements. And there's a WordPress model of WordPress.org, WordPress.com. Is there a central hosting for discourse or no? There is. We're not strictly segmenting into the open source versus the commercial side. We have a hosting business. That's how discourse makes money is we host discourse instances and we have really close relationship with our customers of the symbiosis of them giving us feedback on the product. We definitely wait feedback from customers a lot heavier than feedback from somebody who just wanders by and gives feedback. But that's where we make all our money. But we don't have a strict division. We encourage people to use discourse. Like the whole point is that it's free, right? Anybody can set it up. I don't wanna be the only person that hosts discourse. That's absolutely not the goal. But it is a primary way for us to build a business and it's actually kind of a great business. I mean, the business is going really, really well in terms of hosting. So I used to work at Google Research. It's a company that's basically funded on advertisements. So it's Facebook. Let me ask if you can comment on it. I think advertisement is best. So you'd be extremely critical on what ads are but at its best, it's actually serving you. In a sense, it's giving you, it's connecting you to what you would want to explore. So it's like related posts or related content. It's the same, that's the best of advertisement. So discourse is connecting people based on their interests. It seems like a place where advertisement at its best could actually serve the users. Is that something that you're considering thinking about as a way to bring, to financially support the platform? That's interesting because I actually have a contrarian view of advertising, which I kind of agree with you. I recently installed AdBlocker reluctantly because I don't like to do that. But the performance of the ads, man, they're so heavy now and it's just crazy. So it's almost like a performance argument more than like, I actually am pro ads and I have a contrarian viewpoint. I agree with you. If you do ads right, it's serving you stuff you would be interested in anyway. I don't mind that, that actually is kind of a good thing. So plus I think it's rational to wanna support the people that are doing this work through seeing their ads. But that said, I run AdBlock now, which I didn't wanna do, but I was convinced by all these articles, like 30, 40 megabytes of stuff just to serve you ads. Yeah, it feels like ads now are like the experts exchange of whenever you start a stock overflow. It's a little bit, it's overwhelming. Oh, there's so many companies in ad tech that it's embarrassing. Like you can do that, have you seen those logo charts of like just the whole page? It's like you can't even see them, they're so small. There's so many companies in the space. But since you brought it up, I do wanna point out that very, very few discourse sites actually run using an ad supported model. It's not effective. Like it's too diluted, it's too weird, it doesn't pay well, and like users hate it. So it's a combination of like users hate it, it doesn't actually work that well in practice. Like in theory, yes, I agree with you. If you had clean, fast ads that were exactly the stuff you would be interested in, awesome. We're so far from that though, right? Like, and Google does an okay job. They do retargeting and stuff like that, but in the real world, discourse sites rarely can make ads work. It just doesn't work for so many reasons. But you know what does work is subscriptions, Patreon, affiliate codes for like Amazon, of like just, oh, here's a cool yo yo, click, and then you click and go to Amazon, they get a small percentage of that, which is fair, I think. I mean, because you saw the yo yo on that site and you clicked through and you bought it, right? That's fair for them to get 5% of that or 2% of that, whatever it is. Those things definitely work. In fact, a site that I used to participate on a lot, I helped the owner. One of the things, I got them to switch to discourse. I basically paid them to switch to discourse because I was like, look, you guys got to switch. I can't come here anymore on this terrible software. But I was like, look, and on top of that, like you're serving people ads that they hate. Like you should just go full on Patreon because he had a little bit of Patreon. Go full on Patreon, do the Amazon affiliates thing for any Amazon links that get posted and just do that and just triple down on that stuff. And that's worked really well for them and this creator in particular. So that stuff works, but traditional ads, I mean, definitely not working, at least on discourse. So last question. You've created the code keyboard. I've programmed most of my adult life on a Kinesis keyboard. I have one upstairs now. Can you describe what a mechanical keyboard is and why is it something that makes you happy? Well, you know, this is another fetish item, really. Like, it's not required. You can do programming on any kind of keyboard, even like an onscreen keyboard. Oh, god, that's terrifying. But you could. I mean, if you look back at the early days of computing, there were chiclet keyboards, which are awful. But what's a chiclet keyboard? Oh, god. OK, well, it's just like thin rubber membranes. Oh, the rubber ones, oh, no. Super bad, right? So it's a fetish item. All that really says is, look, I care really about keyboards because the keyboard is the primary method of communication with the computer. So it's just like having a nice mic for this podcast. You want a nice keyboard, right? Because it has a very tactile feel. I can tell exactly when I press the key. I get that little click. So, oh, and it feels good. And it's also kind of a fetish item. It's like, wow, I care enough about programming that I care about the tool, the primary tool, that I use to communicate with the computer, make sure it's as good as it feels good to use for me. And I can be very productive with it. So to be honest, it's a little bit of a fetish item, but a good one. It indicates that you're serious. It indicates you're interested. It indicates that you care about the fundamentals. Because you know what makes you a good programmer? Being able to type really fast, right? This is true, right? So a core skill is just being able to type fast enough to get your ideas out of your head into the code base. So just practicing your typing can make you a better programmer. It is also something that makes you, well, makes you enjoy typing, correct? The actual act, something about the process. Like I play piano. It's tactile. There's a tactile feel that ultimately feeds the passion, makes you happy. Right. No, totally. That's it. I mean, and it's funny because artisanal keyboards have exploded. Like Massdrop has gone ballistic with this stuff. There's probably like 500 keyboard projects on Massdrop alone. And there's some other guy I follow on Twitter. I used to write for the site The Tech Report way back in the day. And he's like, every week he's just posting what I call keyboard porn of just cool keyboards. Like, oh my god, those look really cool, right? It's like, how many keyboards does this guy have, right? It's kind of like me with yo yos. How many yo yos do you have? How many do you need? Well, technically one, but I like a lot. I don't know why. So same thing with keyboards. So yeah, they're awesome. Like, I highly recommend anybody that doesn't have a mechanical to research it, look into it, and see what you like. And it's ultimately a fetish item. But I think these sort of items, these religious artifacts that we have, are part of what make us human. Like, that part's important, right? It's kind of what makes life worth living. Yeah. It's not necessary in the strictest sense, but ain't nothing necessary if you think about it, right? Like, so yeah, why not? So sure. Jeff, thank you so much for talking today. Yeah, you're welcome. Thanks for having me. I mean, they've been running for a long time. It's still an extremely rich source of information. So what's broken about that system and how are you trying to fix it? I think there's a lot of power in connecting people that love the same stuff around that specific topic. Meaning Facebook's idea of connection is just any human that's related to another human, right? Like through friendship or any other reason. Facebook's idea of the world is sort of the status update, right? Like a friend of yours did something, ate at a restaurant, right? Whereas discussion forums were traditionally around the interest graph. Like I love electric cars, specifically I love Tesla, right? Like I love the way they approach the problem. I love the style of the founder. I just love the design ethic. And there's a lot to like about Tesla. I don't know if you saw the oatmeal, he did a whole love comic to Tesla. And it was actually kind of cool because I learned some stuff. He was talking about how great Tesla cars were specifically, like how they were built differently. And he went into a lot of great detail that was really interesting. And to me, that oatmeal post, if you read it, is the genesis of pretty much all interest communities. I just really love this stuff. So like for me, for example, there's yo yos, right? Like I'm into the yo yo communities. And these interest communities are just really fascinating to me. And I feel more connected to the yo yo communities than I do to friends that I don't see that often, right? Like to me, the powerful thing is the interest graph. And Facebook kind of dabbles in the interest graph. I mean, they have groups, you can sign up for groups and stuff, but it's really about the relationship graph. Like this is my coworker, this is my relative, this is my friend, but not so much about the interest. So I think that's the linchpin of which forums and communities are built on that I personally love. Like I said, leadership is about passion, right? And being passionate about stuff is a really valid way to look at the world. And I think it's a way a lot of stuff in the world gets done. Like I once had someone describe me as, he's like, Jeff, you're a guy who, you just get super passionate about a few things at a time, and you just go super deep in those things. And I was like, oh, that's kind of right. That's kind of what I do. I get into something and just be super into that for a couple of years or whatever, and just learn all I can about it, and go super deep in it. And that's how I enjoy experiencing the world, right? Like not being shallow on a bunch of things, but being really deep on a few things that I'm interested in. So forums kind of unlock that, right? And you don't want a world where everything belongs to Facebook, at least I don't. I want a world where communities can kind of own themselves, set their own norms, set their own rules, control the experience. Because community is also about ownership, right? Like if you're meeting at the Barnes and Noble every Thursday and Barnes and Noble says, get out of here, you guys don't buy enough books. Well, you know, you're kind of hosed, right? Barnes and Noble owns you, right? Like you can't. But if you have your own meeting space, you know, your own clubhouse, you can set your own rules, decide what you want to talk about there, and just really generate a lot better information than you could like hanging out at Barnes and Noble every Thursday at 3 p.m., right? So that's kind of the vision of Discourse, is a place where it's fully open source. You can take the software, you can install it anywhere, and, you know, you and a group of people can go deep on whatever it is that you're into. And this works for startups, right? Startups are a group of people who go super deep on a specific problem, right? And they want to talk to the community. It's like, well, install Discourse, right? That's what we do at Discourse. That's what I did at Stack Overflow. I spent a lot of time on Meta Stack Overflow, which is our internal, well, public community feedback site, and just experiencing what the users were experiencing, right, because they're the ones doing all the work in the system. And they had a lot of interesting feedback. And there's that 90, 10 rule of, like, 90% of the feedback you get is not really actionable for a variety of reasons. It might be bad feedback, it might be crazy feedback, it might be feedback you just can't act on right now. But there's 10% of it that's like gold. It's like literally gold and diamonds, where it's like feedback of really good improvements to your core product that are not super hard to get to and actually make a lot of sense. And my favorite is about 5% of those stuff I didn't even see coming. It's like, oh my God, I never even thought of that. But that's a brilliant idea, right? And I can point to so many features of Stack Overflow that we derive from Meta Stack Overflow feedback and Meta discourse, right? Same exact principle of discourse, you know? We're getting ideas from the community. I was like, oh my God, I never thought of that, but that's fantastic, right? Like, I love that relationship with the community. From having built these communities, what have you learned about? What's the process of getting a critical mass of members in a community? Is it luck, skill, timing, persistence? What is, is it the tools, like discourse, that empower that community? What's the key aspect of starting for one guy or gal and then building it to two and then 10 and a hundred and a thousand and so on? I think when you're starting with an N of one, I mean, I think it's persistence and also you have to be interesting. Like somebody I really admire once said something that I always liked about blogging. He's like, here's how you blog. You have to have something interesting to say and have an interesting way of saying it, right? And then do that for like 10 years. So that's the genesis, is like you have to have sort of something interesting to say that's not exactly what everybody else is saying and an interesting way of saying it, which is another way of saying, kind of entertaining way of saying it. And then as far as growing it, it's like ritual. You know, like you have to, like say you're starting a blog, you have to say, look, I'm gonna blog every week, three times a week, and you have to stick to that schedule, right? Because until you do that for like several years, you're never gonna get anywhere. Like it just takes years to get to where you need to get to. And part of that is having the discipline to stick with the schedule. And it helps, again, if it's something you're passionate about, this won't feel like work. You're like, I love this. I could talk about this all day, every day, right? You just have to do it in a way that's interesting to other people. And then as you're growing the community, that pattern of participation within the community of like generating these artifacts and inviting other people to help you like collaborate on these artifacts, like even in the case of blogging, like I felt in the early days of my blog, which I started in 2004, which is really the genesis of Stack Overflow. If you look at all my blog, it leads up to Stack Overflow, which was, I have all this energy in my blog, but I don't, like 40,000 people were subscribing to me. And I was like, I wanna do something. And then I met Joel and said, hey, Joel, I wanna do something, take this ball of energy from my blog and do something. And all the people reading my blog saw that. It's like, oh, cool. You're involving us. You're saying, look, you're part of this community. Let's build this thing together. Like they pick the name. Like we voted on the name for Stack Overflow on my blog. Like we came up, and naming is super hard. First of all, the hardest problem in computer science is coming up with a good name for stuff, right? But you can go back to my blog. There's the poll where we voted and Stack Overflow became the name of the site. And all the early beta users of Stack Overflow were audience of my blog plus Joel's blog, right? So we started from, like, if you look at the genesis, okay, I was just a programmer who said, hey, I love programming, but I have no outlet to talk about it. So I'm just gonna blog about it, because I don't have enough people to work to talk to about it. Because at the time I worked a place where, you know, programming wasn't the core output of the company, it was a pharmaceutical company. And I just love this stuff, you know, to an absurd degree. So I was like, I'll just blog about it. And then I'll find an audience and eventually found an audience, eventually found Joel, and eventually built Stack Overflow from that one core of activity, right? But it was that repetition of feeding back in feedback from my blog comments, feedback from Joel, feedback from the early Stack Overflow community. When people see that you're doing that, they will follow along with you, right? They'll say, cool, you're here in good faith. You're actually, you know, not listening to everything because that's impossible, that's impossible. But you're actually, you know, waiting our feedback and what you're doing. And why wouldn't I? Because who does all the work on Stack Overflow? Me, Joel? No, it's the other programmers that are doing all the work. So you gotta have some respect for that. And then, you know, discipline around, look, you know, we're trying to do a very specific thing here on Stack Overflow. We're not trying to solve all the world's problems. We're trying to solve this very specific Q and A problem in a very specific way. Not cause we're jerks about it, but because these strict set of rules help us get really good results, right? And programmers, that's an easy sell for the most part because programmers are used to dealing with ridiculous systems of rules like constantly. That's basically their job. So they're very, oh yeah, super strict system of rules that lets me get what I want. That's programming, right? That's what Stack Overflow is, so. So you're making it sound easy, but in 2004, let's go back there. In 2004, you started the blog, Coding Horror. Was it called that at the very beginning? It was. One of the smart things I did, it's from a book by Steve McConnell, Code Complete, which is one of my favorite programming books, still probably my number one programming book for anyone to read. So one of the smart things I did back then, I don't always do smart things when I start stuff. I contacted Steve and said, hey, I really like this. It was a sidebar illustration indicating danger in code, right? Coding Horror was like, watch out. And I love that illustration because it spoke to me. Because I saw that illustration go, oh my God, that's me. Like I'm always my own worst enemy. Like that's the key insight in programming is every time you write something, think how am I gonna screw myself? Because you will, constantly, right? So that icon was like, oh yeah, I need to constantly hold that mirror up and look, and say, look, you're very fallible. You're gonna screw this up. Like how can you build this in such a way that you're not gonna screw it up later? Like how can you get that discipline around making sure at every step I'm thinking through all the things that I could do wrong or that other people could do wrong? Because that is actually how you get to be a better programmer a lot of times, right? So that sidebar illustration, I loved it so much. And I wrote Steve before I started my blog and said, hey, can I have permission to use this because I just really like this illustration? And Steve was kind enough to give me permission to do that and just continues to give me permission, so yeah. Really, that's awesome. But in 2004, you started this blog. You know, you look at Stephen King, his book on writing, or Stephen Pressfield, War of Art book. I mean, it seems like writers suffer. I mean, it's a hard process of writing, right? There's gonna be suffering. I mean, I won't kid you. Well, the work is suffering, right? Like doing the work, like even when you're every week, you're like, okay, that blog post wasn't very good or people didn't like it or people said disparaging things about it. You have to like have the attitude like, you know, no matter what happens, I wanna do this for me, right? It's not about you, it's about me. I mean, in the end, it is about everyone because this is how good work gets out into the world. But you have to be pretty strict about saying like, you know, I'm selfish in the sense that I have to do this for me. You know, you mentioned Stephen King, like his book on writing. But like one of the things I do, for example, when writing is like, I read it out loud. One of the best pieces of advice for writing anything is read it out loud, like multiple times and make it sound like you're talking because that is the goal of good writing. It should sound like you said it with slightly better phrasing because you have more time to think about what you're saying but like, it should sound natural when you say it. And I think that's probably the single best writing advice I can give anyone. Just read it over and over out loud, make sure it sounds like something you would normally say and it sounds good. And what's your process of writing? See, there's usually a pretty good idea behind the blog post. So ideas, right. So I think you gotta have the concept that there's so many interesting things in the world. Like, I mean, my God, the world is amazing, right? Like you can never write about everything that's going on because it's so incredible. But if you can't come up with like, let's say one interesting thing per day to talk about, then you're not trying hard enough because the world is full of just super interesting stuff. And one great way to like mine stuff is go back to old books cause they bring up old stuff that's still super relevant. And I did that a lot cause I was like reading classic programming books and a lot of the early blog posts were like, oh, I was reading this programming book and they brought this really cool concept and I wanna talk about it some more. And you get the, I mean, you're not claiming credit for the idea but it gives you something interesting to talk about that's kind of evergreen, right? Like you don't have to go, what should I talk about? So we'll just go dig up some old classic programming books and find something that, oh, wow, that's interesting. Or how does that apply today? Or what about X and Y or compare these two concepts. So pull a couple of sentences from that book and then sort of play off of it, almost agree or disagree. So in 2007, you wrote that you were offered a significant amount of money to sell the blog. You chose not to. What were all the elements you were thinking about? Cause I'd like to take you back. It seems like there's a lot of nonlinear decisions you made through life. So what was that decision like? Right, so one of the things I love is the Choose Your Own Adventure books, which I loved as a kid and I feel like they're early programmer books cause they're all about if then statements, right? If this, then this. And they're also very, very unforgiving. Like there's all these sites that map the classic Choose Your Own Adventure books and how many outcomes are bad, a lot of bad outcomes. So part of the game is like, oh, I got a bad outcome. Go back one step, go back one further step. It's like, how did I get here, right? Like it's a sequence of decisions. And this is true of life, right? Like every decision is a sequence, right? Individually, any individual decision is not necessarily right or wrong, but they lead you down a path, right? So I do think there's some truth to that. So this particular decision, the blog had gotten fairly popular. There's a lot of RSS readers that I had discovered. And this guy contacted me out of the blue from this like bug tracking company. He's like, oh, I really wanna buy your blog for like, I think it was around, it was $100,000, it might have been like 80,000, but it was a lot, right? Like, and that's, you know, at the time, like I would have a year's worth of salary all at once. So I didn't really think about like, well, you know, and I remember talking to people at the time, I was like, wow, that's a lot of money. But then I'm like, I really like my blog, right? Like, do I wanna sell my blog? Cause it wouldn't really belong to me anymore at that point. And one of the guidelines that I like to, I don't like to give advice to people a lot, but one of the pieces of advice I do give, cause I do think it's really true and it's generally helpful is whenever you're looking at a set of decisions, like, oh gosh, should I do A, B or C, you gotta pick the thing that's a little scarier in that list because not, you know, not like jump off a cliff scary, but the thing that makes you nervous. Cause if you pick the safe choice, it's usually, you're not really pushing. You're not pushing yourself. You're not choosing the thing that's gonna help you grow. So for me, the scarier choice was to say no. I was like, well, no, let's just see where this is going. Right? Because then I own it. I mean, it belongs to me. It's my thing. And I can just take it and tell some other logical conclusion, right? Because imagine how different the world would have been had I said yes and sold the blog. It's like, there probably wouldn't be Stack Overflow. You know, a lot of other stuff would have changed. So for that particular decision, I think it was that same rule. Like what scares me a little bit more. Do the thing that scares you. Yeah. So speaking of which, startups. I think there's a specific, some more general questions that a lot of people would be interested in. You've started Stack Overflow. You started this course. So what's the, it was one, two, three guys, whatever it is in the beginning. What was that process like? Do you start talking about it? Do you start programming? Do you start, like, where's the birth and the catalyst that actually. Well, I can talk about it in the context of both Stack Overflow and Discourse. So I think the key thing initially is there is a problem. Something, there's some state of the world that's unsatisfactory to the point that, like, you're upset about it, right? Like, in that case, it was experts exchange. I mean, Joel's original idea, because I approached Joel as like, look, Joel, I have all this energy behind my blog. I want to do something. I want to build something. But I don't know what it is, because I'm honestly not a good idea person. I'm really not. I'm like the execution guy. I'm really good at execution, but I'm not good at, like, blue skying ideas. Not my forte. Which is another reason why I like the community feedback, because they blue sky all day long for you, right? So when I can just go in and cherry pick a blue sky idea from community, even if I have to spend three hours reading to get one good idea, it's worth it, man. But anyway, so the idea from Joel was, hey, experts exchange, it's got great data, but the experience is hideous, right? It's trying to trick you. It feels like used car salesman. It's just bad. So I was like, oh, that's awesome. It feeds into community. It feeds into, like, you know, we can make creative comments. So I think the core is to have a really good idea that you feel very strongly about in the beginning, that, like, there's a wrong in the world, an injustice that we will write through the process of building this thing. For Discourse, it was like, look, there's no good software for communities to just hang out and, like, do stuff, right? Like, whether it's problem solving, startup, whatever. Forums are such a great building block of online community, and they're hideous. They were so bad, right? It was embarrassing. Like, I literally was embarrassed to be associated with this software, right? I was like, we have to have software that you can be proud of. It's like, this is competitive with Reddit. This is competitive with Twitter. This is competitive with Facebook, right? I would be proud to have the software on my site. So that was the genesis of Discourse, was feeling very strongly about there needs to be a good solution for communities. So that's step one. Genesis of an idea you feel super strongly about, right? And then people galvanize around the idea. Like, Joel was already super excited about the idea. I was excited about the idea. So with the forum software, I was posting on Twitter. I had researched, as part of my research, I start researching the problem, right? And I found a game called Forum Wars, which was a parody of forum. It's still very, very funny, of forum behavior, circa, I would say, 2003. It's aged some, right? Like, the behavior's a little different in there of Twitter. But it was awesome. It was very funny. And it was like a game. It was like an RPG. And it had a forum attached to it. So it was like a game about forums with a forum attached. I was like, this is awesome, right? This is so cool. And the founder of that company, or that project, it wasn't really a company, contacted me, this guy Robin Ward from Toronto. He said, hey, I saw you've been talking about forums. And I really love that problem space. He was like, I'd still love to build really good forum software, because I don't think anything out there's any good. And I was like, awesome. At that point, I was like, we're starting a company. Because I couldn't have whooshed for a better person to walk through the door and say, I'm excited about this, too. Same thing with Joel, right? I mean, Joel is a legend in the industry, right? So when he walked through and said, I'm excited about this problem, I was like, me too, man. We can do this, right? So that, to me, is the most important step. It's like, having an idea you're super excited about, and another person, a cofounder, right? Because again, you get that dual leadership, right? Am I making a bad decision? Sometimes it's nice to have checks of like, is this a good idea? I don't know, right? So those are the crucial seeds. But then starting to build stuff, whether it's you programming or somebody else's. There is prototyping. So there's tons of research. There's tons of research, like, what's out there that failed? Because a lot of people look at the successes. Oh, look at how successful X is. Everybody looks at the successes. Those are boring. Show me the failures, because that is what's interesting. That's where people were experimenting. That's where people were pushing. And they failed, but they probably failed for reasons that weren't directly about the quality of their idea, right? So look at all the failures. Don't just look what everybody looks at, which is like, oh, gosh, look at all these successful people. Look at the failures. Look at the things that didn't work. Research the entire field. And so that's the research that I was doing that led me to Robin, right? Was that. And then when we, for example, when we did Stack Overflow, we're like, okay, well, I really like elements of voting and dig and read it. I like the Wikipedia, everything's up to date. Nothing is like an old tombstone that has horrible out of date information. We know that works. Wikipedia is an amazing resource. Blogging, the idea of ownership is so powerful, right? Like, oh, I, Joe wrote this, and look how good Joe's answer is, right? All these concepts were rolling together. Researching all the things that were out there that were working and why they were working and trying to fold them into, again, that Frankenstein's monster of what Stack Overflow is. And by the way, that wasn't a free decision because there's still a ton of tension in the Stack Overflow system. There's reasons people complain about Stack Overflow because it's so strict, right? Why is it so strict? Why are you guys always closing my questions? It's because there's so much tension that we built into the system around trying to get good, good results out of the system. And it's not a free. That stuff doesn't come for free, right? It's not like we, we all have perfect answers and nobody will have to get their feelings heard or nobody will have to get downvoted. It doesn't work that way, right? So this is an interesting point and a small tangent. You write about anxiety. So I've posted a lot of questions and written answers on Stack Overflow. On the question side, you usually go to something very specific to something I'm working on. And this is something you talk about that really the goal of Stack Overflow isn't about, is to write a question that's not about you, it's about the question that will help the community in the future. Right, but that's a tough sell, right? Because people are like, well, I don't really care about the community. What I care about is my problem. And that's fair, right? It's sort of that, again, that tension, that balancing act of we wanna help you, but we also wanna help everybody that comes behind you. The long line of people are gonna come up and say, oh, I kinda have that problem too, right? And if nobody's ever gonna come up and say, I have this problem too, then that question shouldn't exist on Stack Overflow because the question is too specific. And even that's tension, right? How do you judge that? How do you know that nobody's ever gonna have this particular question again? So there's a lot of tension in the system. Do you think that anxiety of asking the question, the anxiety of answering, that tension is inherent to programmers, is inherent to this kind of process? Or can it be improved? Can it be happy land where that tension is not quite so harsh? I don't think Stack Overflow can totally change the way it works. One thing they are working on finally is the ask page had not changed since 2011. I'm still kind of bitter about this because I feel like you have a Q&A system and what are the core pages in a Q&A system? Well, first of all, the question, all the answers and also the ask page, particularly when you're a new user or someone trying to ask a question, that's the point at which you need the most help. And we just didn't adapt with the times. But the good news is they're working on this, from what I understand, and it's gonna be a more wizard based format. And you could envision a world where as part of this wizard based program, when you're asking questions, okay, come up with a good title, what are good words to put in the title? One word that's not good to put in the title is problem, for example. I have a problem. Oh, you have a problem. Okay, a problem, that's great. You need specifics. So it's trying to help you make a good question title, for example, that step will be broken out, all that stuff. But one of those steps in that wizard of asking could say, hey, I'm a little nervous. I've never done this before. Can you put me in a queue for special mentoring? You could opt in to a special mentor. I think that would be fantastic. I don't have any objection to that at all in terms of being an opt in system. Because there are people that are like, I just wanna help them. I wanna help a person no matter what. I wanna go above and beyond. I wanna spend hours with this person. It depends what their goals are. It's a great idea. Who am I to judge? So that's fine. It's not precluded from happening. But there's a certain big city ethos that we started with. Like, look, we're in New York City. You don't come to New York City and expect them to be, oh, welcome to the city, Joe. How's it going? Come on in. Let me show you around. That's not how New York City works. Again, New York City has a reputation for being rude, which I actually don't think it is, having been there fairly recently. It's not rude. It's just like going about their business. Like, look, I have things to do. I'm busy. I'm a busy professional, as are you. And since you're a busy professional, certainly when you ask a question, you're gonna ask the best possible question. Because you're a busy professional and you would not accept anything less than a very well written question with a lot of detail about why you're doing it, what you're doing, what you researched, what you found, because you're a professional like me. And this rubs people sometimes the wrong way. And I don't think it's wrong to say, look, I don't want that experience. I want just a more chill place for beginners. And I still think Stack Overflow is not, was never designed for beginners, right? There's this misconception that, even Joel says sometimes, oh yeah, Stack Overflow for beginners. And I think if you're a prodigy, it can be. Right. But for the most part, not. But that's not really representative, right? Like, I think as a beginner, you want a totally different set of tools. You want like live screen sharing, live chat. You want access to resources. You want a playground, like a playground you can experiment in and like test and all this stuff that we just don't give people because that was never really the audience that we were designing Stack Overflow for. That doesn't mean it's wrong. And I think it would be awesome if there was a site like that on the internet, or if Stack Overflow said, hey, you know, we're gonna start doing this. That's fine too. You know, I'm not there. I'm not making those decisions. But I do think the pressure, the tension that you described is there for people to be, look, I'm a little nervous because I know I gotta do my best work, right? The other one is something you talk about, which is also really interesting to me, is duplicate questions or it's a really difficult problem that you highlight. It's super hard. Like you could take one little topic and you could probably write 10, 20, 30 ways of asking about that topic and there will be all different. I don't know if there should be one page that answers all of it. Is there a way that Stack Overflow can help disambiguate, like separate these duplicate questions or connect them together? Or is it a totally hopeless, difficult, impossible task? I think it's a very, very hard computer science problem. And partly because people are very good at using completely different words. It always amazed me on Stack Overflow. You'd have two questions that were functionally identical and one question had like zero words in common with the other question. Like, oh my God, from a computer science perspective, how do you even begin to solve that? And it happens all the time. People are super good at this, right? Accidentally at asking the same thing in like 10, 20 different ways. And the other complexity is we want some of those duplicates to exist because if there's five versions with different words, have those five versions point to the one centralized answer, right? It's like, okay, this is a duplicate, no worries. Here's the answer that you wanted over here on the prime example that we want to have, rather than having 10 copies of the question and the answer. Because if you have 10 copies of the question and answer, this also devalues the reputation system, which programmers hate, as I previously mentioned. You're getting reputation for an answer that somebody else already gave. It's like, well, it's an answer, but somebody else already gave that answer. So why are you getting reputation for the same answer as the other guy who gave it four years ago? People get offended by that, right? So the reputation system itself adds tension to the system in that the people who have a lot of reputation become very incentivized to enforce the reputation system. And for the most part, that's good. I know it sounds weird, but for most parts, like look, strict systems, I think to use Stack Overflow, you have to have the idea that, OK, strict systems ultimately work better. And I do think in programming, you're familiar with loose typing versus strict typing, right? The idea that you can declare a variable, not declare a variable, rather, just start using a variable. And OK, I see it's implicitly an integer. Bam, awesome. Duck equals 5. Well, duck is now an integer of 5, right? And you're like, cool, awesome, simpler, right? Why would I want to worry about typing? And for a long time, in the Ruby community, they're like, yeah, this is awesome. You just do a bunch of unit testing, which is testing your program's validity after the fact to catch any bugs that strict typing of variables would have caught. And now you have this thing called TypeScript for Microsoft from the guy who built C Sharp Anders, who's one of the greatest minds in software development, right, like in terms of language design. And says, no, no, no, we want to bolt on a strict type system to JavaScript because it makes things better. And now everybody's like, oh my god, we deployed TypeScript and found 50 latent bugs that we didn't know about, right? Like, this is super common. So I think there is a truth in programming that strictness, it's not the goal. We're not saying be super strict because strictness is correct. No, it's no, no. Strictness produces better results. That's what I'm saying, right? So strict typing of variables, I would say you almost universally have consensus now is basically correct. Should be that way in every language, right? Duck equals five should generate an error because no, you didn't declare. You didn't tell me that duck was an integer, right? That's a bug, right? Or maybe you mistyped. You typed deck instead of duck, right? You never know. This happens all the time, right? So with that in mind, I will say that the strictness of the system is correct. Now, that doesn't mean cruel. That doesn't mean mean. That doesn't mean angry. It just means strict, OK? So I think where there's misunderstanding is people get cranky, right? Like, another question you asked is like, why are programmers kind of mean sometimes? Well, who do programmers work with all day long? So I have a theory that if you're at a job and you work with assholes all day long, what do you eventually become? An asshole. An asshole. And what is the computer except the world's biggest asshole? Because the computer has no time for your bullshit. The computer, the minute you make a mistake, everything is crashing down, right? One semicolon has crashed space missions, right? So that's normal. So you begin to internalize that. You begin to think, oh, my coworker, the computer, is super strict and kind of a jerk about everything. So that's kind of how I'm going to be. Because I work with this computer, and I have to exceed to its terms on everything. So therefore, you start to absorb that. You start to think, oh, well, being really strict arbitrarily is really good. An error of error code 56249 is a completely good error message because that's what the computer gave me, right? So you kind of forget to be a person at some level. And you know how they say great detectives internalize criminals and kind of are criminals themselves, like this trope of the master detective is good because he can think like the criminal. Well, I do think that's true of programmers. Really good programmers think like the computer because that's their job. But if you internalize it too much, you become the computer. You kind of become a jerk to everybody because that's what you've internalized. You're almost not a jerk, but you have no patience for a lack of strictness, as you said. It's not out of a sense of meanness. It's accidental. But I do believe it's an occupational hazard of being a programmer is you start to behave like the computer. You're very unforgiving. You're very terse. You're very, oh, wrong, incorrect, move on. It's like, well, can you help me? What could I do to fix? No, wrong, next question. Like, that's normal for the computer. Just fail, next. I don't know if you remember in Saturday Night Live, in the 90s, they had this character who was an IT guy. The move guy. Move. Move. Was that Jimmy Fallon? No. No. Who played him? OK, yeah, I remember. Move. Right. He had no patience for it. Might have been Mad TV, actually. Wasn't it Mad TV? Might have been. But anyway, that's always been the perception. You start to behave like the computer. It's like, oh, you're wrong, out of the way, you know? You've written so many blog posts about programming, about programs, programming, programmers. What do you think makes a good, let's start with, what makes a good solo programmer? Well, I don't think you should be a solo programmer. I think to be a good solo programmer, it's kind of like what I talked about, well, not on Mike, but one of the things John Carmack, one of the best points he makes in the book Masters of Doom, which is a fantastic book, and anybody listening to this who hasn't read it, please read it. It's such a great book, is that at the time, they were working on stuff like Wolfenstein and Doom. They didn't have the resources that we have today. They didn't have Stack Overflow. They didn't have Wikipedia. They didn't have discourse forums. They didn't have places to go to get people to help them. They had to work on their own. And that's why it took a genius like Carmack to do this stuff, because you had to be a genius to invent from first principles. A lot of the stuff he was like, the hacks he was coming up with were genius, genius level stuff. But you don't need to be a genius anymore, and that means not working by yourself. You have to be good at researching stuff online. You have to be good at asking questions, really good questions that are really well researched, which implies, oh, I went out and researched for three hours before I wrote these questions. That's what you should be doing, because that's what's going to make you good. To me, this is the big difference between programming in the 80s versus programming today, is you kind of had to be by yourself back then. Where would you go for answers? I remember in the early days when I was learning Visual Basic for Windows, I would call the Microsoft Helpline on the phone when I had programming. Because I was like, I don't know what to do. So I would go and call, and they had these huge phone banks. And I'm like, can you imagine how alien that is now? Who would do that? That's crazy. So there was just nowhere else to go when you got stuck. I had the books that came with it. I read those, studied those religiously. I just saw a post from Steve Sanofsky that said the C++ version 7 came with 10,000 pages of written material. Because where else were you going to figure that stuff out? Go to the library? I mean, you didn't have Wikipedia. You didn't have Reddit. You didn't have anywhere to go to answer these questions. So you've talked about, through the years, basically not having an ego and not thinking that you're the best programmer in the world. So always kind of just looking to improve, to become a better programmer than you were yesterday. So how have you changed as a programmer and as a thinker, designer around programming over the past, what is it, 15 years, really, of being a public figure? I would say the big insight that I had is, eventually, as a programmer, you have to stop writing code to be effective, which is kind of disturbing. Because you really love it. But you realize being effective at programming, at programming in the general sense, doesn't mean writing code. And a lot of times, you can be much more successful by not writing code and writing code in terms of just solving the problems you have, essentially hiring people that are really good and setting them free and giving them basic direction on strategy and stuff. Because a lot of the problems you encounter aren't necessarily solved through really gnarly code. They're solved by conceptual solutions, which can then be turned into code. But are you even solving the right problem? So I would say, for me, the main insight I have is, to succeed as a programmer, you eventually kind of stop writing code. That's going to sound discouraging, probably, to people hearing. But I don't mean it that way. What I mean is that you're coding at a higher level language. Eventually, like, OK, so we're coding in assembly language. That's the beginning, right? You're hardcoded to the architecture. Then you have stuff like C, where it's like, wow, we can abstract across the architecture. We can write code. I can then compile that code for ARM or whatever x86 or whatever else is out there. And then even higher level than that, you're looking at Python, Ruby, interpreted languages. And then, to me, as a programmer, I'm like, OK, I want to go even higher. I want to go higher than that. How do I abstract higher than the language? It's like, well, you abstract in spoken language and written language, right? You're sort of inspiring people to get things done, giving them guidance, like, what if we did this? What if we did this? You're writing in the highest level language that there is, which is, for me, English, whatever your spoken language is. So it's all about being effective, right? And I think Patrick McKenzie, patio11 on Hacker News and works at Stripe, has a great post about this, of how calling yourself a programmer is a career limiting move at some level once you get far enough from your career. And I really believe that. And again, I apologize. This is sound discouraging. I don't mean it to be, but he's so right. Because all the stuff that goes on around the code, like the people, that's another thing, if you look at my early blog entries, is about, wow, programming is about people more than it's about code, which doesn't really make sense. But it's about, can these people even get along together? Can they understand each other? Can you even explain to me what it is you're working on? Are you solving the right problem? PeopleWare, another classic programming book, which, again, up there with Code Complete, please read PeopleWare. It's that software is people. People are the software, first and foremost. So a lot of the skills that I was working on early in the blog were about figuring out the people parts of programming, which were the harder parts. The hard part of programming, once you get a certain skill level in programming, you can pretty much solve any reasonable problem that's put in front of you. You're not writing algorithms from scratch. That just doesn't happen. So any sort of reasonable problem put in front of you, you're going to be able to solve. But what you can't solve is, our manager is a total jerk. You cannot solve that with code. That is not a code solvable problem. And yet, that will cripple you way more than, oh, we had to use this stupid framework I don't like, or Sam keeps writing bad code that I hate, or Dave is off there in the wilderness writing God knows what. These are not your problems. Your problem is your manager or a co worker is so toxic to everybody else in your team that nobody can get anything done, because everybody's so stressed out and freaked out. These are the problems that you have to attack. Absolutely. And so as you go to these higher level abstractions, as you've developed as a programmer to higher and higher level abstractions and go into natural language, you're also the guy who preached building it, diving in and doing it, and learn by doing. Yes. Do you worry that as you get to higher and higher level abstractions, you lose track of the lower level of just building? Do you worry about that, even not maybe now, but 10 years from now, 20 years from now? Well, no. I mean, there is always that paranoia around, oh, gosh, I don't feel it's valuable since I'm not writing code. But for me, when we started the discourse project, it was Ruby, which I didn't really know Ruby. I mean, as you pointed out, and this is another valuable observation in Stack Overflow, you can be super proficient in, for example, C Sharp, which I was working in. That's what we built Stack Overflow in and still is written in. And then switch to Ruby, and you're a newbie again. But you have the framework. I know what a for loop is. I know what recursion is. I know what a stack trace is. I have all the fundamental concepts to be a programmer. I just don't know Ruby. So I'm still on a higher level. I'm not like a beginner beginner, like you're saying. I'm just like, I need to apply my programming concepts I already know to Ruby. Well, so there's a question that's really interesting. So looking at Ruby, how do you go about learning enough that your intuition can be applied, carried over? That's what I was trying to get to. It's like what I realized, particularly when I started with just me and Robin, I realized if I bother Robin, I am now costing us productivity. Every time I go to Robin, rather than building our first alpha version of discourse, he's now answering my stupid questions about Ruby. Is that a good use of his time? Is that a good use of my time? And the answer to both of those was resoundingly no. We were getting to an alpha, and it was pretty much just, OK, we'll hire more programmers. We eventually hired Neil, and then eventually Sam, who came in as a cofounder. Actually, it was Sam first, then Neil later. But the answer to the problem is just hire other competent programmers. Now I shall pull myself up by my bootstraps and learn Ruby. But at some point, writing code becomes a liability to you in terms of getting things done. There's so many other things that go on in the project, like building the prototype. You mentioned, well, how do you, if you're not writing code, how does everybody keep focus on what are we building? Well, first, basic mockups and research. What do we even want to build? There's a little bit of that that goes on. But then very quickly, you get to the prototype stage. Like, build a prototype. Let's iterate on the prototype really, really rapidly. And that's what we do with discourse. And that's what we demoed to get our seed funding for discourse was the alpha version of discourse that we had running and ready to go. And it was very, it was bad. I mean, it was, I'll just tell you it was bad. We have screenshots of it. I'm just embarrassed to look at it now. But it was the prototype. We were figuring out what's working, what's not working. Because there's such a broad gap between the way you think things will work in your mind or even on paper and the way they work once you sit and live in the software, like actually spend time living and breathing in software, so different. So my philosophy is get to a prototype. And then what you're really optimizing for is speed of iteration, like how you can turn the crank. How quickly can we iterate? That's the absolutely critical metric of any software project. And I had a tweet recently that people liked. And I totally, this is so fundamental to what I do, is like if you want to measure the core competency of any software tech company, it's the speed at which somebody can say, hey, we really need this word in the product. Change this word, right? Because it will be more clear to the user. Like, instead of respond, it's reply or something. But there's some, from the conception of that idea to how quickly that single word can be changed in your software and rolled out to users, that is your life cycle. That's your health, your heartbeat. If your heartbeat is like super slow, you're basically dead. No, seriously. Like, if it takes two weeks or even a month to get that single word changed, everybody's like, oh my god, this is a great idea. That word is so much clearer. I'm talking about like a super, like everybody's on board for this change. It's not like, let's just change a word because we're bored. It's like, this is an awesome change. And then it takes months to roll out. It's like, well, you're dead. You can't iterate. You can't, how are you going to do anything, right? So anyway, about the heartbeat, it's like, get the prototype and then iterate on it. That's what I view as the central tenet of modern software development. That's fascinating that you put it that way. So I work and I build autonomous vehicles. And when you look at what, maybe compare Tesla to most other automakers, the heart beat for Tesla is literally days now in terms of they can over the air deploy software updates to all their vehicles, which is markedly different than every other automaker, which takes years to update a piece of software. And that's reflected in everything that's the final product. That's reflected in really how slowly they adapt to the times. And to be clear, I'm not saying being a hummingbird is the goal either.",following conversation jeff atwood cofounder stack overflow stack exchange website visit million people single day like wikipedia difficult understate impact global knowledge productivity network site create jeff author famed blog coding horror founder discourse open source software project seek improve quality online community discussion conversation mit course artificial general intelligence artificial intelligence podcast enjoy subscribe youtube itunes podcast provider choice simply connect twitter lex friedman spell f r conversation jeff atwood having co create manage year world large community programmer stack overflow year ago think motivate programmer fame fortune glory process program sense belong community puzzle think idea work puzzle independently people solve problem sort like work programming anymore aspect hide away beat problem solve like brute force basically lot programming computer fast thing forever human time answer say pure act tinker code thing drive problem struggle balance joy overcome brute force process pain suffering eventually lead actually work data fun thing call shuffling problem naive shuffle programmer write huge flaw lot article online bad casino unsophisticated programmer write shuffle algorithm surprising way wrong neat thing way figure run shuffle bunch time orientation card equal distribution card naive method shuffle look datum brute force ok know go happen write program billion time bucket look like datum monty hall problem example door somebody give information door correct answer switch monty hall problem intuitive freak people time solve datum write program monty hall game switch switch compare immediately smart figure answer algorithmically brute force datum know answer run program billion time data bucket get empirically find joy personally outside family motivate process honest write lot code anymore discourse managery stuff despise programmer think manager people weird thing code realize language code ability direct people let stuff say language code language code mean communication human yes think systematic like make programming make good manager make good leader think leader lead example sort thing want kind exhausting particularly kid realize kid watch time way stop see hard person planet lot easy people judgment super biased actually way people hard way people go insight get diligent thinking behave way represent want people behave like lead example lot example leader mess like decision like wow bad example people think lead example believe work hard mean work exhaustively show real passion problem necessarily solution problem problem believe like discourse example problem look current project people group communicate way break howling wolf deal trolling like technical problem people post paragraph people use bold people use complete sentence problem people solve problem set solve reach consensus discussion hurt maybe discussion matter people yell like purpose kind communication leadership set example thing represent want make sure actually thing trick thing lot yeah let pause thing fascinating leader self awareness say hard self aware personally maybe leader see look know thing wrong thing way speak way behave thing signal think aspect like process feedback get feedback right get feedback right way example discourse cofounder periodically talk decision like person mistake like wow misunderstanding thing like like group consensus leadership like good think system leader leader rule absolute law dangerous experience community example like community run person person make decision person go to bad day happen person lot variable like think leadership multiple people leadership talk give feedback decision make feedback think little voice head right gut wanna body think voice important like think people kind moral compass like want people want right thing believe mean handful sociopath people want people think good person right like want people despise mean weird right little voice sort angel devil shoulder sort talk like feel decision right think have attunement voice important say voice think programmer situation devil shoulder little loud little self critical lot developer especially introvert personality struggle self criticism criticism thing leadership potentially unpopular people doubt decision balance like think walk people decision making right like blogging important communication important code language kind code like program arrive conclusion go to reach right thing like decision final deal right usually satisfy people look think problem stuff happen think right goal wanna achieve look option think available option good option people like oh okay right maybe totally agree kind come arbitrary decision deliver cloud flame sky right like human try reach kind consensus goal goal different completely legit right make clear like oh reason agree totally different goal right like agree bad person radically different goal mind start look problem say passion hard work sorry tie mind let hard work passion like like love problem discourse set solve way like vision world devolve facebook basically own aspect human communication right kind scary world cause think facebook good execution get compliment competent term facebook moral compass term facebook care facebook care problem care big facebook right talk company mechanism facebook work kind right like idea discourse reason passionate cause believe community right right like software run belong space set rule like different hosting know need happen happen like idea company town human communication implicitly own whatsapp instagram facebook disturb cause facebook smart like say great execution buy whatsapp buy instagram incredibly smart decision thing know know vpn software away free smartphone indirectly feed datum traffic facebook actually get popular vpn right low level access network datum user let let small pause discourse talk lay land different way community stack overflow build discourse stack overflow kind like wiki wikipedia talk specific scalpel focused purpose discourse maybe contrast facebook discourse yeah start beginning let start beginning stack overflow structured wiki style q programmer right problem work start think discussion look like programming forum thing quickly realize q narrow subset human communication right sorry start stack overflow think know q know q know idea like okay thing work online goal right goal site experts exchange unfortunate thank kill site yeah know right like lot people remember anymore great like measure success people remember thing try replace totally win place answer program question clear like focus q discussion plenty programming forum sure like okay aspect dig reddit like voting important reorder answer base vote wiki style stuff like able edit post post people post well date ownership blogging like okay say voice stuff know reputation accrue peer recognition ask early like motivate programmer think peer recognition motivate lot key insight stack overflow like recognition peer thing necessarily money necessarily boss like peer say wow person know stuff lot value reputation system come sort frankensteine bunch stuff stack overflow like stuff see work know work stack overflow time realize discussion focused question answer lot room page let talk tangential thing like okay answer question clarify question alternative answer question usually way programming like way pattern get early stack overflow question like hundred answer like wow programming question answer look realize question traditional sense discussion stuff allow early eventually decide allow favorite programming food funniest programming cartoon see sort backfill bunch rule like allow real problem face like go work say wow work cause know funny programming cartoon sorry compile code right real problem face job run rule second like learn like accidental learning reddit style learning like oh browse thing oh wow know know tree frog live year mean know true set learn need know right accidental learning intentional learning like okay problem want learn stuff problem have right theory compiler theory stuff have compiler problem need know compiler theory aspect get answer right kind directed learning backfill rule sort figure heck system come strict time lot people complain write late blog entry stack overflow want grow celebrate year anniversary yeah yeah year system trend strictness variety reason people like people reputation stuff view frivolous actually understand see programmer get like upvote funniest programming cartoon funniest comment see code like reputation write joke probably mean maybe cartoon right get bunch reputation base work program joke right relate programming begin resent like fair level correct mean empathize correct reputation versus gnarly regular expression problem clever insightful detailed answer lay oh see behavior see let teach thing avoid future great gold right want people reputation wow look funny thing see right great specific format journey discourse facebook twitter start beginning stack overflow evolve purpose discourse passion create community discussion bear base realization stack overflow good specific subject base datum fact science answer kind verify true form book knowledge like tome knowledge define refer book answer work subject like semi clear answer thing verify form way complete flexibility system fall stuff like poker lego like engine try launch different topic right people propose topic sample question get support network launch site one launch poker lego horribly right mean linger form experiment like test right subject work super stack engine reason lego poker work social rule poker like kind cigar like smoke play poker cool set card use play poker strategy hand come strategy use discussion happen lego thing cool lego set find look awesome like yeah freak awesome right question right social component discussion fit literally disallow stack overflow social problem face work need concrete answer real demonstrate problem block block straight flush blocking problem world opportunity hang discuss discourse way address look discussion forum software bad come stack overflow early bad expect improve year look improve like kind terrible love community people talk thing love community interest right good software startup come hey jeff want startup idea thing ask know field necessarily ask community people interested problem people product talk oh great idea start play sad trombone realize software involve talk user customer audience patron bad stuff embarrassed recommend people feel big strong effective input product right user community right stack overflow talk forum dark matter internet know long time passionate fascinating discussion usual structure usually linear sequential post pagination post page format like lot research tesla vehicle tesla motors club forum extremely want run actually ping think get like gotten start believe like want heartbeat like fast like freak measure health healthy heartbeat people listen decide mean healthy reasonable go frustrate build software mistake roll live feel like oh god terrible idea oh gosh well y right turn crank fast ahead competitor ultimately rate change right delta v right fast move year go mile away time catch right way work plus software developer user love software constantly change understand people super piss like oh change software dare like yes change software change time man make stuff great change rapidly great grant change suck admit see time general make software cool right malleable fight weird like fight essence thing build sense want embrace hummingbird embrace healthy cycle heartbeat right talk people change true probably lot stuff write blog probably remain true flip coin people change like invest understand people like learn unix change right thing learn people valid year learn late javascript framework go good like year right exactly look future programming people component technology future programming change significantly far tell people ultimately program foresee change fundamental way get look sort basic programming thing shock like source control like learn source control grant graduate college remember hear people late like like maybe today learn source control like learn source control fundamental work programmer work way lose work basic software literal bedrock software development source control compare today like github right like microsoft buy github think incredibly smart acquisition anybody want reasonable source control sign github set right ton walkthrough ton tutorial concept like program advanced like hell github mean god yes right like massively advanced programming significantly different go think baseline view fundamental continue actually well like source control fundamental get hundred order magnitude well year ago fundamental let introduce thing maybe comment mobile phone fundamentally transform programming maybe maybe comment artificial intelligence promise way programming way think programmer intelligence inside skull useful hope artificial intelligence useful part think smartphone fact everybody get powerful potentially change programming ai potentially change programming ok good smartphone definitely change mean guess start get super popular mean year world literally change right everybody carry computer normal mean huge change society think deal lot positive negative ramification right everybody connect time everybody computer time dream world geek right like careful ask right like wow everybody computer utopia think right computer lot stuff necessarily great central focus smartphone put computer grant small touch screen smallish touch screen computer programming know think kind time come subscribe unix view world come programming want teach basic command line thing programming go think long long time think magical visual programming go happen know time believer unix philosophy know kind write unix go way long long time continue like say raise baseline tool well simple fundamentally go command line tool fancy ide kind foreseeable future see visual programming stuff horizon kind think like smartphone directly analogous programming like try think right necessarily analogous programming kind thing kind program need write need different yeah kind language mean probably subscribe world write javascript oh yeah happen mean discourse bet discourse javascript bet table try believe smartphone cultural shift programming shift question artificial intelligence sort device predict go think strength think artificial intelligence kind overselle term like people predictable right people thing let example check discourse lot big commercial website log new york city hour later log san francisco like hmm interesting new york san francisco hour point like ok suspicious login point alert like ok ai right heuristic like hour mile right mean grand maybe vpn way happen basic prediction base idea people pretty travel occasionally travel salesman literally travel world day repetition predictability term thing go think good software anticipate need example google think call google google thing predict commute predict base phone location day probably work kind stuff think computer lot well hesitate blown ai computer get well like ton datum everybody smartphone sudden datum location communication feed basic heuristic maybe fancy algorithm turn prediction anticipate need like friend right like oh hey home like dinner right like let food usually time day right context actually act programming ide improve make life programming well think possible lot repetition programming right oh know clippy bad example oh look like write loop pattern code right actually library kind like right code http request library like use exist one troubleshot right ai se build well lego brick big lego brick functionality people worry low level stuff anymore like wordpress example like tool somebody programmer mean turn wordpress kind crazy actually plugin right programming se lego brick stack wordpress element right little bit configuration glue maybe broad sense see like gluing actual programming good thing right stuff need kind say unix php kind old remnant early birth programming remain long time like say unix ultimately stuff momentum kind mean big believer windows early big know like unix waste time time completely flip like okay unix guy right pretty microsoft windows kind wrong server desktop right need gui need stuff philosophy like apple build unix effectively darwin desktop slightly different story server go to program question programming go to go to lot like client programming technically discourse client programming way discourse deliver big ball javascript execute locally lot local computing power retrieve datum obviously display post screen forth term like sort lot basic stuff host processor extent lot programming go to server yeah unix philosophy definitely win different veneer unix peel away layer go to unixy long think unix win mean definitively interesting hear excellent work microsoft term backend development cool future hold jeff atwood mean discourse continue discourse try improve conversation web discourse view originally call year project quickly revise year project start early launch version year start get good like good product discourse project build software take year build want build like go to terrible ship well stuff turn crank perfect ridiculous let good like fast iterate think iterate like crazy discourse point like good product momentum original vision wanna wordpress discussion mean come say wanna start blog question kind archaic like actually blog anymore want answer wordpress normally obvious choice blogge time say hey need group people answer discourse right default answer people open source free cost control run minimum server cost discourse buck month point actually get vps price month gigabyte ram kind heavy stack like lot stuff discourse need postgre need redis need ruby rail need sidekick scheduling trivial stuff architecte like look build year care share php hosting model idea like hey eventually go to cheap everybody wanna build right high big building block level right requirement wordpress model central hosting discourse strictly segment open source versus commercial host business discourse make money host discourse instance close relationship customer symbiosis give feedback product definitely wait feedback customer lot heavy feedback somebody wander give feedback money strict division encourage people use discourse like point free right anybody set wanna person host discourse absolutely goal primary way build business actually kind great business mean business go term hosting work google research company basically fund advertisement facebook let ask comment think advertisement good extremely critical ad good actually serve sense give connect want explore like relate post relate content good advertisement discourse connect people base interest like place advertisement good actually serve user consider think way bring financially support platform interesting actually contrarian view advertising kind agree recently instal adblocker reluctantly like performance ad man heavy crazy like performance argument like actually pro ad contrarian viewpoint agree ad right serve stuff interested mind actually kind good thing plus think rational wanna support people work see ad say run adblock wanna convince article like megabyte stuff serve ad yeah feel like ad like expert exchange start stock overflow little bit overwhelming oh company ad tech embarrassing like see logo chart like page like small company space bring wanna point discourse site actually run ad support model effective like dilute weird pay like user hate combination like user hate actually work practice like theory yes agree clean fast ad exactly stuff interested awesome far right like google okay job retargete stuff like real world discourse site rarely ad work work reason know work subscription patreon affiliate code like amazon like oh cool yo yo click click amazon small percentage fair think mean see yo yo site click buy right fair thing definitely work fact site participate lot help owner thing get switch discourse basically pay switch discourse like look guy get switch come anymore terrible software like look like serve people ad hate like patreon little bit patreon patreon amazon affiliate thing amazon link post triple stuff work creator particular stuff work traditional ad mean definitely work discourse question create code keyboard program adult life kinesis keyboard upstairs describe mechanical keyboard make happy know fetish item like require programming kind keyboard like onscreen keyboard oh god terrifying mean look early day computing chiclet keyboard awful chiclet keyboard oh god ok like thin rubber membrane oh rubber one oh super bad right fetish item say look care keyboard keyboard primary method communication computer like have nice mic podcast want nice keyboard right tactile feel tell exactly press key little click oh feel good kind fetish item like wow care programming care tool primary tool use communicate computer sure good feel good use productive honest little bit fetish item good indicate indicate interested indicate care fundamental know make good programmer able type fast right true right core skill able type fast idea head code base practice typing well programmer make make enjoy type correct actual act process like play piano tactile tactile feel ultimately feed passion make happy right totally mean funny artisanal keyboard explode like massdrop go ballistic stuff probably like keyboard project massdrop guy follow twitter write site tech report way day like week post keyboard porn cool keyboard like oh god look cool right like keyboard guy right kind like yo yos yo yos need technically like lot know thing keyboard yeah awesome like highly recommend anybody mechanical research look like ultimately fetish item think sort item religious artifact human like important right kind make life worth live yeah necessary strictest sense ai necessary think right like yeah sure jeff thank talk today yeah welcome thank have mean run long time extremely rich source information break system try fix think lot power connect people love stuff specific topic mean facebook idea connection human relate human right like friendship reason facebook idea world sort status update right like friend eat restaurant right discussion forum traditionally interest graph like love electric car specifically love tesla right like love way approach problem love style founder love design ethic lot like tesla know see oatmeal love comic tesla actually kind cool learn stuff talk great tesla car specifically like build differently go lot great detail interesting oatmeal post read genesis pretty interest community love stuff like example yo yos right like yo yo communities interest community fascinating feel connected yo yo community friend right like powerful thing interest graph facebook kind dabble interest graph mean group sign group stuff relationship graph like coworker relative friend interest think linchpin forum community build personally love like say leadership passion right passionate stuff valid way look world think way lot stuff world get like describe like jeff guy super passionate thing time super deep thing like oh kind right kind super couple year learn super deep enjoy experience world right like shallow bunch thing deep thing interested forum kind unlock right want world belong facebook want world community kind set norm set rule control experience community ownership right like meet barnes noble thursday barnes noble say guy buy book know kind hose right barne noble own right like meeting space know clubhouse set rule decide want talk generate lot well information like hang barnes noble thursday right kind vision discourse place fully open source software install know group people deep work startup right startup group people super deep specific problem right want talk community like install discourse right discourse stack overflow spend lot time meta stack overflow internal public community feedback site experience user experience right one work system lot interesting feedback rule like feedback actionable variety reason bad feedback crazy feedback feedback act right like gold like literally gold diamond like feedback good improvement core product super hard actually lot sense favorite stuff come like oh god think brilliant idea right point feature stack overflow derive meta stack overflow feedback meta discourse right exact principle discourse know get idea community like oh god think fantastic right like love relationship community having build community learn process get critical mass member community luck skill timing persistence tool like discourse empower community key aspect start guy gal build thousand think start n mean think persistence interesting like somebody admire say like blogge like blog interesting interesting way say right like year genesis like sort interesting exactly everybody say interesting way say way say kind entertaining way say far grow like ritual know like like start blog look go to blog week time week stick schedule right like year go to like take year need have discipline stick schedule help passionate will feel like work like love talk day day right way interesting people grow community pattern participation community like generate artifact invite people help like collaborate artifact like case blogging like feel early day blog start genesis stack overflow look blog lead stack overflow energy blog like people subscribe like wanna meet joel say hey joel wanna ball energy blog people read blog see like oh cool involve say look community let build thing like pick like vote stack overflow blog like come naming super hard hard problem computer science come good stuff right blog poll vote stack overflow site early beta user stack overflow audience blog plus joel blog right start like look genesis okay programmer say hey love programming outlet talk go to blog people work talk time work place know programming core output company pharmaceutical company love stuff know absurd degree like blog find audience eventually find audience eventually find joel eventually build stack overflow core activity right repetition feed feedback blog comment feedback joel feedback early stack overflow community people follow right cool good faith actually know listen impossible impossible actually know wait feedback work stack overflow joel programmer work get to respect know discipline look know try specific thing stack overflow try solve world problem try solve specific q problem specific way cause jerk strict set rule help good result right programmer easy sell programmer deal ridiculous system rule like constantly basically job oh yeah super strict system rule let want programming right stack overflow make sound easy let start blog coding horror call beginning smart thing book steve mcconnell code complete favorite programming book probably number programming book read smart thing smart thing start stuff contact steve say hey like sidebar illustration indicate danger code right code horror like watch love illustration speak see illustration oh god like bad enemy like key insight programming time write think go to screw constantly right icon like oh yeah need constantly hold mirror look look fallible go to screw like build way go to screw later like discipline make sure step think thing wrong people wrong actually well programmer lot time right sidebar illustration love write steve start blog say hey permission use like illustration steve kind permission continue permission yeah awesome start blog know look stephen king book writing stephen pressfield war art book mean like writer suffer mean hard process writing right go to suffer mean will kid work suffer right like work like week like okay blog post good people like people say disparage thing like attitude like know matter happen wanna right mean end good work get world pretty strict say like know selfish sense know mention stephen king like book writing like thing example write like read loud good piece advice write read loud like multiple time sound like talk goal good writing sound like say slightly well phrasing time think say like sound natural think probably single good writing advice read loud sure sound like normally sound good process writing usually pretty good idea blog post idea right think get to concept interesting thing world like mean god world amazing right like write go incredible come like let interesting thing day talk try hard world super interesting stuff great way like stuff old book cause bring old stuff super relevant lot cause like read classic programming book lot early blog post like oh read programming book bring cool concept wanna talk mean claim credit idea give interesting talk kind evergreen right like talk dig old classic programming book find oh wow interesting apply today x y compare concept pull couple sentence book sort play agree disagree write offer significant money sell blog choose element think cause like like lot nonlinear decision life decision like right thing love choose adventure book love kid feel like early programmer book cause statement right unforgiving like site map classic choose adventure book outcome bad lot bad outcome game like oh get bad outcome step step like right like sequence decision true life right like decision sequence right individually individual decision necessarily right wrong lead path right think truth particular decision blog get fairly popular lot rss reader discover guy contact blue like bug track company like oh wanna buy blog like think like lot right like know time like year worth salary think like know remember talk people time like wow lot money like like blog right like wanna sell blog cause belong anymore point guideline like like advice people lot piece advice cause think true generally helpful look set decision like oh gosh b c get to pick thing little scary list know like jump cliff scary thing make nervous cause pick safe choice usually push push choose thing go to help grow scary choice like let go right mean belong thing tell logical conclusion right imagine different world say yes sell blog like probably stack overflow know lot stuff change particular decision think rule like scare little bit thing scare yeah speak startup think specific general question lot people interested start stack overflow start course guy beginning process like start talk start programming start like birth catalyst actually talk context stack overflow discourse think key thing initially problem state world unsatisfactory point like upset right like case expert exchange mean joel original idea approach joel like look joel energy blog want want build know honestly good idea person like execution guy good execution good like blue sky idea forte reason like community feedback blue sky day long right cherry pick blue sky idea community spend hour reading good idea worth man idea joel hey expert exchange get great datum experience hideous right try trick feel like car salesman bad like oh awesome feed community feed like know creative comment think core good idea feel strongly beginning like wrong world injustice write process build thing discourse like look good software community hang like stuff right like problem solve startup forum great building block online community hideous bad right embarrassing like literally embarrassed associate software right like software proud like competitive reddit competitive twitter competitive facebook right proud software site genesis discourse feel strongly need good solution community step genesis idea feel super strongly right people galvanize idea like joel super excited idea excited idea forum software post twitter research research start research problem right find game call forum wars parody forum funny forum behavior circa age right like behavior little different twitter awesome funny like game like rpg forum attach like game forum forum attach like awesome right cool founder company project company contact guy robin ward toronto say hey see talk forum love problem space like love build good forum software think good like awesome point like start company whoosh well person walk door excited thing joel right mean joel legend industry right walk say excited problem like man right important step like have idea super excited person cofounder right dual leadership right make bad decision nice check like good idea know right crucial seed start build stuff programming somebody prototype ton research ton research like fail lot people look success oh look successful x everybody look success boring failure interesting people experiment people push fail probably fail reason directly quality idea right look failure look everybody look like oh gosh look successful people look failure look thing work research entire field research lead robin right example stack overflow like okay like element voting dig read like wikipedia date like old tombstone horrible date information know work wikipedia amazing resource blogging idea ownership powerful right like oh joe write look good joe answer right concept roll research thing work work try fold frankenstein monster stack overflow way free decision ton tension stack overflow system reason people complain stack overflow strict right strict guy close question tension build system try good good result system free stuff come free right like perfect answer feeling hear downvote work way right interesting point small tangent write anxiety post lot question write answer stack overflow question usually specific work talk goal stack overflow write question question help community future right tough sell right people like care community care problem fair right sort tension balance act wanna help wanna help everybody come long line people go to come oh kinda problem right go to come problem question exist stack overflow question specific tension right judge know go to particular question lot tension system think anxiety ask question anxiety answering tension inherent programmer inherent kind process improve happy land tension harsh think stack overflow totally change way work thing work finally ask page change kind bitter feel like system core page system question answer ask page particularly new user try ask question point need help adapt time good news work understand go to wizard base format envision world wizard base program ask question okay come good title good word title word good title problem example problem oh problem okay problem great need specific try help good question title example step break stuff step wizard asking hey little nervous queue special mentoring opt special mentor think fantastic objection term opt system people like wanna help wanna help person matter wanna wanna spend hour person depend goal great idea judge fine preclude happen certain big city ethos start like look new york city come new york city expect oh welcome city joe go come let new york city work new york city reputation rude actually think having fairly recently rude like go business like look thing busy busy professional busy professional certainly ask question go to ask good possible question busy professional accept write question lot detail research find professional like rub people wrong way think wrong look want experience want chill place beginner think stack overflow design beginner right misconception joel say oh yeah stack overflow beginner think prodigy right representative right like think beginner want totally different set tool want like live screen sharing live chat want access resource want playground like playground experiment like test stuff people audience design stack overflow mean wrong think awesome site like internet stack overflow say hey know go to start fine know make decision think pressure tension describe people look little nervous know get to good work right talk interesting duplicate question difficult problem highlight super hard like little topic probably write way ask topic different know page answer way stack overflow help disambiguate like separate duplicate question connect totally hopeless difficult impossible task think hard computer science problem partly people good completely different word amaze stack overflow question functionally identical question like zero word common question like oh god computer science perspective begin solve happen time people super good right accidentally ask thing like different way complexity want duplicate exist version different word version point centralized answer right like okay duplicate worry answer want prime example want have copy question answer copy question answer devalue reputation system programmer hate previously mention get reputation answer somebody give like answer somebody give answer get reputation answer guy give year ago people offend right reputation system add tension system people lot reputation incentivize enforce reputation system good know sound weird part like look strict system think use stack overflow idea ok strict system ultimately work well think programming familiar loose typing versus strict typing right idea declare variable declare variable start variable ok implicitly integer bam awesome duck equal duck integer right like cool awesome simple right want worry type long time ruby community like yeah awesome bunch unit testing test program validity fact catch bug strict typing variable catch thing call typescript microsoft guy build c sharp anders great mind software development right like term language design say want bolt strict type system javascript make thing well everybody like oh god deploy typescript find latent bug know right like super common think truth program strictness goal say super strict strictness correct strictness produce well result say right strict typing variable universally consensus basically correct way language right duck equal generate error declare tell duck integer right bug right maybe mistype type deck instead duck right know happen time right mind strictness system correct mean cruel mean mean mean angry mean strict ok think misunderstanding people cranky right like question ask like programmer kind mean programmer work day long theory job work asshole day long eventually asshole asshole computer world big asshole computer time bullshit computer minute mistake crash right semicolon crash space mission right normal begin internalize begin think oh coworker computer super strict kind jerk kind go work computer exceed term start absorb start think oh strict arbitrarily good error error code completely good error message computer give right kind forget person level know great detective internalize criminal kind criminal like trope master detective good think like criminal think true programmer good programmer think like computer job internalize computer kind jerk everybody internalize jerk patience lack strictness say sense meanness accidental believe occupational hazard programmer start behave like computer unforgiving terse oh wrong incorrect like help fix wrong question like normal computer fail know remember saturday night live character guy guy jimmy fallon play ok yeah remember right patience mad tv actually mad tv perception start behave like computer like oh wrong way know write blog post programming program programming programmer think make good let start make good solo programmer think solo programmer think good solo programmer kind like talk mike thing john carmack good point make book masters doom fantastic book anybody listen read read great book time work stuff like wolfenstein doom resource today stack overflow wikipedia discourse forum place people help work take genius like carmack stuff genius invent principle lot stuff like hack come genius genius level stuff need genius anymore mean work good research stuff online good ask question good question research imply oh go research hour write question go good big difference programming versus programming today kind answer remember early day learn visual basic windows microsoft helpline phone programming like know huge phone bank like imagine alien crazy get stick book come read study religiously see post steve sanofsky say version come page write material go figure stuff library mean wikipedia reddit answer question talk year basically have ego think good programmer world kind look improve well programmer yesterday change programmer thinker designer programming past year public figure big insight eventually programmer stop write code effective kind disturbing love realize effective programming programming general sense mean write code lot time successful write code write code term solve problem essentially hire people good set free give basic direction strategy stuff lot problem encounter necessarily solve gnarly code solve conceptual solution turn code solve right problem main insight succeed programmer eventually kind stop write code go sound discouraging probably people hear mean way mean code high level language eventually like ok code assembly language beginning right hardcode architecture stuff like c like wow abstract architecture write code compile code arm high level look python ruby interpret language programmer like ok want high want high abstract high language like abstract spoken language write language right sort inspire people thing give guidance like write high level language english spoken language effective right think patrick mckenzie hacker news work stripe great post call programmer career limit level far career believe apologize sound discouraging mean right stuff go code like people thing look early blog entry wow programming people code sense people understand explain work solve right problem peopleware classic programming book code complete read peopleware software people people software foremost lot skill work early blog figure people part programming hard part hard programming certain skill level programming pretty solve reasonable problem write algorithm scratch happen sort reasonable problem go able solve solve manager total jerk solve code code solvable problem cripple way oh use stupid framework like sam keep write bad code hate dave wilderness write god know problem problem manager co worker toxic everybody team everybody stress freak problem attack absolutely high level abstraction develop programmer high high level abstraction natural language guy preach build dive learn yes worry high high level abstraction lose track low level build worry maybe year year mean paranoia oh gosh feel valuable write code start discourse project ruby know ruby mean point valuable observation stack overflow super proficient example c sharp work build stack overflow write switch ruby newbie framework know loop know recursion know stack trace fundamental concept programmer know ruby high level like beginner beginner like say like need apply programming concept know ruby question interesting look ruby learn intuition apply carry try like realize particularly start robin realize bother robin cost productivity time robin build alpha version discourse answer stupid question ruby good use time good use time answer resoundingly get alpha pretty ok hire programmer eventually hire neil eventually sam come cofounder actually sam neil later answer problem hire competent programmer shall pull bootstrap learn ruby point write code liability term get thing thing project like build prototype mention write code everybody focus build basic mockup research want build little bit go quickly prototype stage like build prototype let iterate prototype rapidly discourse demo seed funding discourse alpha version discourse run ready bad mean tell bad screenshot embarrassed look prototype figure work work broad gap way think thing work mind paper way work sit live software like actually spend time live breathe software different philosophy prototype optimize speed iteration like turn crank quickly iterate absolutely critical metric software project tweet recently people like totally fundamental like want measure core competency software tech company speed somebody hey need word product change word right clear user like instead respond reply conception idea quickly single word change software roll user life cycle health heartbeat heartbeat like super slow basically dead seriously like take week month single word change everybody like oh god great idea word clear talk like super like everybody board change like let change word bored like awesome change take month roll like dead iterate go right heartbeat like prototype iterate view central tenet modern software development fascinating way work build autonomous vehicle look maybe compare tesla automaker heart beat tesla literally day term air deploy software update vehicle markedly different automaker take year update piece software reflect final product reflect slowly adapt time clear say hummingbird goal,"['Jeff Atwood', 'Coding Horror', 'Lex Friedman', 'Delta V', 'Meta Stack Overflow', 'Meta Stack', 'Stack Overflow', 'Steve McConnell', 'Code Complete', 'Stephen King', 'Stephen Pressfield', 'Robin Ward', 'Jimmy Fallon', 'John Carmack', 'Steve Sanofsky', 'Patrick McKenzie']","['Stack Overflow', 'Microsoft', 'Google']","['Cloud Computing Platforms', 'Big Data Analytics', 'Internet of Things']","['Online Communities and Knowledge Sharing', 'Software Development Practices', 'Programming Languages', 'Open Source Development', 'Technological Innovation']"
8,Eric Schmidt,Google,"The following is a conversation with Eric Schmidt. He was the CEO of Google for 10 years and a chairman for six more, guiding the company through an incredible period of growth and a series of world changing innovations. He is one of the most impactful leaders in the era of the internet and the powerful voice for the promise of technology in our society. It was truly an honor to speak with him as part of the MIT course on artificial general intelligence and the artificial intelligence podcast. And now here's my conversation with Eric Schmidt. What was the first moment when you fell in love with technology? I grew up in the 1960s as a boy where every boy wanted to be an astronaut and part of the space program. So like everyone else of my age, we would go out to the cow pasture behind my house, which was literally a cow pasture and we would shoot model rockets off. And that I think is the beginning. And of course, generationally today, it would be video games and all the amazing things that you can do online with computers. There's a transformative, inspiring aspect of science and math that maybe rockets would bring would instill in individuals. You've mentioned yesterday that eighth grade math is where the journey through mathematical universe diverges from many people. It's this fork in the roadway. There's a professor of math at Berkeley, Edward Frankel. He, I'm not sure if you're familiar with him. I am. He has written this amazing book I recommend to everybody called Love and Math. Two of my favorite words. He says that if painting was taught like math, then the students would be asked to paint a fence, which is his analogy of essentially how math is taught. And so you never get a chance to discover the beauty of the art of painting or the beauty of the art of math. So how, when, and where did you discover that beauty? I think what happens with people like myself is that your math enabled pretty early and all of a sudden you discover that you can use that to discover new insights. The great scientists will all tell a story, the men and women who are fantastic today, that somewhere when they were in high school or in college, they discovered that they could discover something themselves. And that sense of building something, of having an impact that you own, drives knowledge acquisition and learning. In my case, it was programming. And the notion that I could build things that had not existed that I had built, that it had my name on it. And this was before open source, but you could think of it as open source contributions. So today, if I were a 16 or 17 year old boy, I'm sure that I would aspire as a computer scientist to make a contribution like the open source heroes of the world today. That would be what would be driving me. And I'd be trying and learning and making mistakes and so forth in the ways that it works. The repository that GitHub represents and that open source libraries represent is an enormous bank of knowledge of all of the people who are doing that. And one of the lessons that I learned at Google was that the world is a very big place and there's an awful lot of smart people. And an awful lot of them are underutilized. So here's an opportunity, for example, building parts of programs, building new ideas to contribute to the greater of society. So in that moment in the 70s, the inspiring moment where there was nothing and then you created something through programming, that magical moment. So in 1975, I think you've created a program called Lex, which I especially like because my name is Lex. So thank you, thank you for creating a brand that established a reputation that's long lasting, reliable and has a big impact on the world and still used today. So thank you for that. But more seriously, in that time, in the 70s, as an engineer, personal computers were being born. Do you think you'd be able to predict the 80s, 90s and the aughts of where computers would go? I'm sure I could not and would not have gotten it right. I was the beneficiary of the great work of many, many people who saw it clearer than I did. With Lex, I worked with a fellow named Michael Lesk, who was my supervisor. And he essentially helped me architect and deliver a system that's still in use today. After that, I worked at Xerox Palo Alto Research Center, where the Alto was invented. And the Alto is the predecessor of the modern personal computer or Macintosh and so forth. And the Altos were very rare. And I had to drive an hour from Berkeley to go use them. But I made a point of skipping classes and doing whatever it took to have access to this extraordinary achievement. I knew that they were consequential. What I did not understand was scaling. I did not understand what would happen when you had 100 million as opposed to 100. And so the, since then, and I have learned the benefit of scale, I always look for things which are going to scale to platforms, right? So mobile phones, Android, all those things. There are, the world is in numerous, there are many, many people in the world, people really have needs. They really will use these platforms and you can build big businesses on top of them. So it's interesting. So when you see a piece of technology, now you think, what will this technology look like when it's in the hands of a billion people? That's right. So an example would be that the market is so competitive now that if you can't figure out a way for something to have a million users or a billion users, it probably is not going to be successful because something else will become the general platform and your idea will become a lost idea or a specialized service with relatively few users. So it's a path to generality. It's a path to general platform use. It's a path to broad applicability. Now there are plenty of good businesses that are tiny. So luxury goods, for example. But if you want to have an impact at scale, you have to look for things which are of common value, common pricing, common distribution and solve common problems. They're problems that everyone has. And by the way, people have lots of problems. Information, medicine, health, education and so forth. Work on those problems. Like you said, you're a big fan of the middle class. Because there's so many of them. There's so many of them. By definition. So any product, any thing that has a huge impact and improves their lives is a great business decision and it's just good for society. And there's nothing wrong with starting off in the high end as long as you have a plan to get to the middle class. There's nothing wrong with starting with a specialized market in order to learn and to build and to fund things. So you start with a luxury market to build a general purpose market. But if you define yourself as only a narrow market, someone else can come along with a general purpose market that can push you to the corner, can restrict the scale of operation, can force you to be a lesser impact than you might be. So it's very important to think in terms of broad businesses and broad impact. Even if you start in a little corner somewhere. So as you look to the 70s but also in the decades to come and you saw computers, did you see them as tools or was there a little element of another entity? I remember a quote saying AI began with our dream to create the gods. Is there a feeling when you wrote that program that you were creating another entity, giving life to something? I wish I could say otherwise, but I simply found the technology platforms so exciting. That's what I was focused on. I think the majority of the people that I've worked with, and there are a few exceptions, Steve Jobs being an example, really saw this as a great technological play. I think relatively few of the technical people understood the scale of its impact. So I used NCP, which is a predecessor to TCPIP. It just made sense to connect things. We didn't think of it in terms of the internet and then companies and then Facebook and then Twitter and then politics and so forth. We never did that build. We didn't have that vision. And I think most people, it's a rare person who can see compounding at scale. Most people can see, if you ask people to predict the future, they'll give you an answer of six to nine months or 12 months, because that's about as far as people can imagine. But there's an old saying, which actually was attributed to a professor at MIT a long time ago, that we overestimate what can be done in one year and we underestimate what can be done in a decade. And there's a great deal of evidence that these core platforms at hardware and software take a decade, right? So think about self driving cars. Self driving cars were thought about in the 90s. There were projects around them. The first DARPA Grand Challenge was roughly 2004. So that's roughly 15 years ago. And today we have self driving cars operating in a city in Arizona, right? It's 15 years and we still have a ways to go before they're more generally available. So you've spoken about the importance, you just talked about predicting into the future. You've spoken about the importance of thinking five years ahead and having a plan for those five years. The way to say it is that almost everybody has a one year plan. Almost no one has a proper five year plan. And the key thing to having a five year plan is to having a model for what's going to happen under the underlying platforms. So here's an example. Moore's Law as we know it, the thing that powered improvements in CPUs has largely halted in its traditional shrinking mechanism because the costs have just gotten so high. It's getting harder and harder. But there's plenty of algorithmic improvements and specialized hardware improvements. So you need to understand the nature of those improvements and where they'll go in order to understand how it will change the platform. In the area of network connectivity, what are the gains that are gonna be possible in wireless? It looks like there's an enormous expansion of wireless connectivity at many different bands. And that we will primarily, historically I've always thought that we were primarily gonna be using fiber, but now it looks like we're gonna be using fiber plus very powerful high bandwidth sort of short distance connectivity to bridge the last mile. That's an amazing achievement. If you know that, then you're gonna build your systems differently. By the way, those networks have different latency properties, right? Because they're more symmetric, the algorithms feel faster for that reason. And so when you think about whether it's a fiber or just technologies in general, so there's this barber wooden poem or quote that I really like. It's from the champions of the impossible rather than the slaves of the possible that evolution draws its creative force. So in predicting the next five years, I'd like to talk about the impossible and the possible. Well, and again, one of the great things about humanity is that we produce dreamers, right? We literally have people who have a vision and a dream. They are, if you will, disagreeable in the sense that they disagree with the, they disagree with what the sort of zeitgeist is. They say there is another way. They have a belief, they have a vision. If you look at science, science is always marked by such people who went against some conventional wisdom, collected the knowledge at the time and assembled it in a way that produced a powerful platform. And you've been amazingly honest about, in an inspiring way, about things you've been wrong about predicting and you've obviously been right about a lot of things, but in this kind of tension, how do you balance, as a company, in predicting the next five years, the impossible, planning for the impossible, so listening to those crazy dreamers, letting them do, letting them run away and make the impossible real, make it happen, and slow, you know, that's how programmers often think, and slowing things down and saying, well, this is the rational, this is the possible, the pragmatic, the dreamer versus the pragmatist, so it's helpful to have a model which encourages a predictable revenue stream as well as the ability to do new things. So in Google's case, we're big enough and well enough managed and so forth that we have a pretty good sense of what our revenue will be for the next year or two, at least for a while. And so we have enough cash generation that we can make bets, and indeed, Google has become alphabet, so the corporation is organized around these bets, and these bets are in areas of fundamental importance to the world, whether it's artificial intelligence, medical technology, self driving cars, connectivity through balloons, on and on and on. And there's more coming and more coming. So one way you could express this is that the current business is successful enough that we have the luxury of making bets. And another one that you could say is that we have the wisdom of being able to see that a corporate structure needs to be created to enhance the likelihood of the success of those bets. So we essentially turned ourselves into a conglomerate of bets and then this underlying corporation, Google, which is itself innovative. So in order to pull this off, you have to have a bunch of belief systems, and one of them is that you have to have bottoms up and tops down. The bottoms up we call 20% time, and the idea is that people can spend 20% of the time whatever they want, and the top down is that our founders in particular have a keen eye on technology and they're reviewing things constantly. So an example would be they'll hear about an idea or I'll hear about something and it sounds interesting, let's go visit them. And then let's begin to assemble the pieces to see if that's possible. And if you do this long enough, you get pretty good at predicting what's likely to work. So that's a beautiful balance that struck. Is this something that applies at all scale? It seems to be that Sergey, again, 15 years ago, came up with a concept called 10% of the budget should be on things that are unrelated. It was called 70, 20, 10. 70% of our time on core business, 20% on adjacent business, and 10% on other. And he proved mathematically, of course he's a brilliant mathematician, that you needed that 10% to make the sum of the growth work. And it turns out he was right. So getting into the world of artificial intelligence, you've talked quite extensively and effectively to the impact in the near term, the positive impact of artificial intelligence, whether it's especially machine learning in medical applications and education, and just making information more accessible, right? In the AI community, there is a kind of debate. There's this shroud of uncertainty as we face this new world with artificial intelligence in it. And there's some people, like Elon Musk, you've disagreed, at least on the degree of emphasis he places on the existential threat of AI. So I've spoken with Stuart Russell, Max Tegmark, who share Elon Musk's view, and Yoshua Bengio, Steven Pinker, who do not. And so there's a lot of very smart people who are thinking about this stuff, disagreeing, which is really healthy, of course. So what do you think is the healthiest way for the AI community to, and really for the general public, to think about AI and the concern of the technology being mismanaged in some kind of way? So the source of education for the general public has been robot killer movies. Right. And Terminator, et cetera. And the one thing I can assure you we're not building are those kinds of solutions. Furthermore, if they were to show up, someone would notice and unplug them, right? So as exciting as those movies are, and they're great movies, were the killer robots to start, we would find a way to stop them, right? So I'm not concerned about that. And much of this has to do with the timeframe of conversation. So you can imagine a situation 100 years from now when the human brain is fully understood and the next generation and next generation of brilliant MIT scientists have figured all this out, we're gonna have a large number of ethics questions, right? Around science and thinking and robots and computers and so forth and so on. So it depends on the question of the timeframe. In the next five to 10 years, we're not facing those questions. What we're facing in the next five to 10 years is how do we spread this disruptive technology as broadly as possible to gain the maximum benefit of it? The primary benefits should be in healthcare and in education. Healthcare because it's obvious. We're all the same even though we somehow believe we're not. As a medical matter, the fact that we have big data about our health will save lives, allow us to deal with skin cancer and other cancers, ophthalmological problems. There's people working on psychological diseases and so forth using these techniques. I can go on and on. The promise of AI in medicine is extraordinary. There are many, many companies and startups and funds and solutions and we will all live much better for that. The same argument in education. Can you imagine that for each generation of child and even adult, you have a tutor educator that's AI based, that's not a human but is properly trained, that helps you get smarter, helps you address your language difficulties or your math difficulties or what have you. Why don't we focus on those two? The gains societally of making humans smarter and healthier are enormous and those translate for decades and decades and we'll all benefit from them. There are people who are working on AI safety, which is the issue that you're describing and there are conversations in the community that should there be such problems, what should the rules be like? Google, for example, has announced its policies with respect to AI safety, which I certainly support and I think most everybody would support and they make sense, right? So it helps guide the research but the killer robots are not arriving this year and they're not even being built. And on that line of thinking, you said the time scale. In this topic or other topics, have you found it useful on the business side or the intellectual side to think beyond five, 10 years, to think 50 years out? Has it ever been useful or productive? In our industry, there are essentially no examples of 50 year predictions that have been correct. Let's review AI, right? AI, which was largely invented here at MIT and a couple of other universities in the 1956, 1957, 1958, the original claims were a decade or two. And when I was a PhD student, I studied AI a bit and it entered during my looking at it, a period which is known as AI winter, which went on for about 30 years, which is a whole generation of science, scientists and a whole group of people who didn't make a lot of progress because the algorithms had not improved and the computers had not approved. It took some brilliant mathematicians starting with a fellow named Jeff Hinton at Toronto and Montreal who basically invented this deep learning model which empowers us today. The seminal work there was 20 years ago and in the last 10 years, it's become popularized. So think about the timeframes for that level of discovery. It's very hard to predict. Many people think that we'll be flying around in the equivalent of flying cars, who knows? My own view, if I wanna go out on a limb, is to say that we know a couple of things about 50 years from now. We know that there'll be more people alive. We know that we'll have to have platforms that are more sustainable because the earth is limited in the ways we all know and that the kind of platforms that are gonna get built will be consistent with the principles that I've described. They will be much more empowering of individuals. They'll be much more sensitive to the ecology because they have to be, they just have to be. I also think that humans are gonna be a great deal smarter and I think they're gonna be a lot smarter because of the tools that I've discussed with you and of course, people will live longer. Life extension is continuing apace. A baby born today has a reasonable chance of living to 100, which is pretty exciting. It's well past the 21st century, so we better take care of them. And you mentioned an interesting statistic on some very large percentage, 60, 70% of people may live in cities. Today, more than half the world lives in cities and one of the great stories of humanity in the last 20 years has been the rural to urban migration. This has occurred in the United States, it's occurred in Europe, it's occurring in Asia and it's occurring in Africa. When people move to cities, the cities get more crowded, but believe it or not, their health gets better, their productivity gets better, their IQ and educational capabilities improve. So it's good news that people are moving to cities, but we have to make them livable and safe. So you, first of all, you are, but you've also worked with some of the greatest leaders in the history of tech. What insights do you draw from the difference in leadership styles of yourself, Steve Jobs, Elon Musk, Larry Page, now the new CEO, Sandra Pichai and others? From the, I would say, calm sages to the mad geniuses. One of the things that I learned as a young executive is that there's no single formula for leadership. They try to teach one, but that's not how it really works. There are people who just understand what they need to do and they need to do it quickly. Those people are often entrepreneurs. They just know and they move fast. There are other people who are systems thinkers and planners, that's more who I am, somewhat more conservative, more thorough in execution, a little bit more risk of risk. A little bit more risk averse. There's also people who are sort of slightly insane, in the sense that they are emphatic and charismatic and they feel it and they drive it and so forth. There's no single formula to success. There is one thing that unifies all of the people that you named, which is very high intelligence. At the end of the day, the thing that characterizes all of them is that they saw the world quicker, faster, they processed information faster. They didn't necessarily make the right decisions all the time, but they were on top of it. And the other thing that's interesting about all those people is they all started young. So think about Steve Jobs starting Apple roughly at 18 or 19. Think about Bill Gates starting at roughly 20, 21. Think about by the time they were 30, Mark Zuckerberg, a good example, at 19, 20. By the time they were 30, they had 10 years. At 30 years old, they had 10 years of experience of dealing with people and products and shipments and the press and business and so forth. It's incredible how much experience they had compared to the rest of us who were busy getting our PhDs. Yes, exactly. So we should celebrate these people because they've just had more life experience, right? And that helps inform the judgment. At the end of the day, when you're at the top of these organizations, all the easy questions have been dealt with, right? How should we design the buildings? Where should we put the colors on our product? What should the box look like, right? The problems, that's why it's so interesting to be in these rooms, the problems that they face, right, in terms of the way they operate, the way they deal with their employees, their customers, their innovation, are profoundly challenging. Each of the companies is demonstrably different culturally. They are not, in fact, cut of the same. They behave differently based on input. Their internal cultures are different. Their compensation schemes are different. Their values are different. So there's proof that diversity works. So, so when faced with a tough decision, in need of advice, it's been said that the best thing one can do is to find the best person in the world who can give that advice and find a way to be in a room with them, one on one and ask. So here we are, and let me ask in a long winded way, I wrote this down. In 1998, there were many good search engines, Lycos, Excite, AltaVista, Infoseek, Ask Jeeves maybe, Yahoo even. So Google stepped in and disrupted everything. They disrupted the nature of search, the nature of our access to information, the way we discover new knowledge. So now it's 2018, actually 20 years later. There are many good personal AI assistants, including, of course, the best from Google. So you've spoken in medical and education, the impact of such an AI assistant could bring. So we arrive at this question. So it's a personal one for me, but I hope my situation represents that of many other, as we said, dreamers and the crazy engineers. So my whole life, I've dreamed of creating such an AI assistant. Every step I've taken has been towards that goal. Now I'm a research scientist in human centered AI here at MIT. So the next step for me as I sit here, so facing my passion is to do what Larry and Sergey did in 98, this simple startup. And so here's my simple question. Given the low odds of success, the timing and luck required, the countless other factors that can't be controlled or predicted, which is all the things that Larry and Sergey faced, is there some calculation, some strategy to follow in this step? Or do you simply follow the passion just because there's no other choice? I think the people who are in universities are always trying to study the extraordinarily chaotic nature of innovation and entrepreneurship. My answer is that they didn't have that conversation. They just did it. They sensed a moment when in the case of Google, there was all of this data that needed to be organized and they had a better algorithm. They had invented a better way. So today with human centered AI, which is your area of research, there must be new approaches. It's such a big field. There must be new approaches, different from what we and others are doing. There must be startups to fund. There must be research projects to try. There must be graduate students to work on new approaches. Here at MIT, there are people who are looking at learning from the standpoint of looking at child learning. How do children learn starting at age one and two? And the work is fantastic. Those approaches are different from the approach that most people are taking. Perhaps that's a bet that you should make or perhaps there's another one. But at the end of the day, the successful entrepreneurs are not as crazy as they sound. They see an opportunity based on what's happened. Let's use Uber as an example. As Travis sells the story, he and his co founder were sitting in Paris and they had this idea because they couldn't get a cab. And they said, we have smartphones and the rest is history. So what's the equivalent of that Travis Eiffel Tower, where is a cab moment that you could, as an entrepreneur, take advantage of? Whether it's in human centered AI or something else. That's the next great startup. And the psychology of that moment. So when Sergey and Larry talk about, and listen to a few interviews, it's very nonchalant. Well, here's the very fascinating web data and here's an algorithm we have for, we just kind of want to play around with that data. And it seems like that's a really nice way to organize this data. I should say what happened to remember is that they were graduate students at Stanford and they thought this was interesting. So they built a search engine and they kept it in their room. And they had to get power from the room next door because they were using too much power in the room. So they ran an extension cord over, right? And then they went and they found a house and they had Google world headquarters of five people, right, to start the company. And they raised $100,000 from Andy Bechtolsheim, who was the Sun founder to do this and Dave Cheriton and a few others. The point is their beginnings were very simple but they were based on a powerful insight. That is a replicable model for any startup. It has to be a powerful insight. The beginnings are simple. And there has to be an innovation. In Larry and Sergey's case, it was PageRank, which was a brilliant idea, one of the most cited papers in the world today. What's the next one? So you're one of, if I may say, richest people in the world. And yet it seems that money is simply a side effect of your passions and not an inherent goal. But you're a fascinating person to ask. So much of our society at the individual level and at the company level and as nations is driven by the desire for wealth. What do you think about this drive? And what have you learned about, if I may romanticize the notion, the meaning of life, having achieved success on so many dimensions? There have been many studies of human happiness and above some threshold, which is typically relatively low for this conversation, there's no difference in happiness about money. The happiness is correlated with meaning and purpose, a sense of family, a sense of impact. So if you organize your life, assuming you have enough to get around and have a nice home and so forth, you'll be far happier if you figure out what you care about and work on that. It's often being in service to others. There's a great deal of evidence that people are happiest when they're serving others and not themselves. This goes directly against the sort of press induced excitement about powerful and wealthy leaders of one kind. And indeed these are consequential people. But if you are in a situation where you've been very fortunate as I have, you also have to take that as a responsibility and you have to basically work both to educate others and give them that opportunity, but also use that wealth to advance human society. In my case, I'm particularly interested in using the tools of artificial intelligence and machine learning to make society better. I've mentioned education, I've mentioned inequality and middle class and things like this, all of which are a passion of mine. It doesn't matter what you do, it matters that you believe in it, that it's important to you, and that your life will be far more satisfying if you spend your life doing that. I think there's no better place to end than a discussion of the meaning of life. Eric, thank you so much.",following conversation eric schmidt ceo google year chairman guide company incredible period growth series world change innovation impactful leader era internet powerful voice promise technology society truly honor speak mit course artificial general intelligence artificial intelligence podcast conversation eric schmidt moment fall love technology grow boy boy want astronaut space program like age cow pasture house literally cow pasture shoot model rocket think beginning course generationally today video game amazing thing online computer transformative inspire aspect science math maybe rocket bring instill individual mention yesterday eighth grade math journey mathematical universe diverge people fork roadway professor math berkeley edward frankel sure familiar write amazing book recommend everybody call love math favorite word say painting teach like math student ask paint fence analogy essentially math teach chance discover beauty art painting beauty art math discover beauty think happen people like math enable pretty early sudden discover use discover new insight great scientist tell story man woman fantastic today high school college discover discover sense build have impact drive knowledge acquisition learning case program notion build thing exist build open source think open source contribution today year old boy sure aspire computer scientist contribution like open source hero world today drive try learn make mistake forth way work repository github represent open source library represent enormous bank knowledge people lesson learn google world big place awful lot smart people awful lot underutilize opportunity example build part program build new idea contribute great society moment inspiring moment create programming magical moment think create program call lex especially like lex thank thank create brand establish reputation long lasting reliable big impact world today thank seriously time engineer personal computer bear think able predict aught computer sure get right beneficiary great work people see clear lex work fellow name michael lesk supervisor essentially help architect deliver system use today work xerox palo alto research center alto invent alto predecessor modern personal computer macintosh forth altos rare drive hour berkeley use point skip class take access extraordinary achievement know consequential understand scale understand happen million oppose learn benefit scale look thing go scale platform right mobile phone android thing world numerous people world people need use platform build big business interesting piece technology think technology look like hand billion people right example market competitive figure way million user billion user probably go successful general platform idea lose idea specialized service relatively user path generality path general platform use path broad applicability plenty good business tiny luxury good example want impact scale look thing common value common pricing common distribution solve common problem problem way people lot problem information medicine health education forth work problem like say big fan middle class definition product thing huge impact improve life great business decision good society wrong start high end long plan middle class wrong start specialized market order learn build fund thing start luxury market build general purpose market define narrow market come general purpose market push corner restrict scale operation force less impact important think term broad business broad impact start little corner look decade come see computer tool little element entity remember quote say ai begin dream create god feeling write program create entity give life wish simply find technology platform exciting focus think majority people work exception steve jobs example see great technological play think relatively technical people understand scale impact ncp predecessor tcpip sense connect thing think term internet company facebook twitter politic forth build vision think people rare person compound scale people ask people predict future answer month month far people imagine old saying actually attribute professor mit long time ago overestimate year underestimate decade great deal evidence core platform hardware software decade right think self drive car self drive car think project darpa grand challenge roughly roughly year ago today self drive car operate city arizona right year way generally available speak importance talk predict future speak importance think year ahead have plan year way everybody year plan proper year plan key thing have year plan have model go happen underlie platform example moore law know thing powered improvement cpu largely halt traditional shrinking mechanism cost get high get hard hard plenty algorithmic improvement specialized hardware improvement need understand nature improvement order understand change platform area network connectivity gain go to possible wireless look like enormous expansion wireless connectivity different band primarily historically think primarily go to fiber look like go to fiber plus powerful high bandwidth sort short distance connectivity bridge mile amazing achievement know go to build system differently way network different latency property right symmetric algorithm feel fast reason think fiber technology general barber wooden poem quote like champion impossible slave possible evolution draw creative force predict year like talk impossible possible great thing humanity produce dreamer right literally people vision dream disagreeable sense disagree disagree sort zeitgeist way belief vision look science science mark people go conventional wisdom collect knowledge time assemble way produce powerful platform amazingly honest inspiring way thing wrong predict obviously right lot thing kind tension balance company predict year impossible plan impossible listen crazy dreamer let let run away impossible real happen slow know programmer think slow thing say rational possible pragmatic dreamer versus pragmatist helpful model encourage predictable revenue stream ability new thing google case big manage forth pretty good sense revenue year cash generation bet google alphabet corporation organize bet bet area fundamental importance world artificial intelligence medical technology self drive car connectivity balloon coming come way express current business successful luxury make bet wisdom able corporate structure need create enhance likelihood success bet essentially turn conglomerate bet underlying corporation google innovative order pull bunch belief system bottom top bottom time idea people spend time want founder particular keen eye technology review thing constantly example hear idea hear sound interesting let visit let begin assemble piece possible long pretty good predict likely work beautiful balance strike apply scale sergey year ago come concept call budget thing unrelated call time core business adjacent business prove mathematically course brilliant mathematician need sum growth work turn right get world artificial intelligence talk extensively effectively impact near term positive impact artificial intelligence especially machine learning medical application education make information accessible right ai community kind debate shroud uncertainty face new world artificial intelligence people like elon musk disagree degree emphasis place existential threat ai speak stuart russell max tegmark share elon musk view yoshua bengio steven pinker lot smart people think stuff disagree healthy course think healthy way ai community general public think ai concern technology mismanage kind way source education general public robot killer movie right terminator et cetera thing assure build kind solution furthermore notice unplug right exciting movie great movie killer robot start find way stop right concerned timeframe conversation imagine situation year human brain fully understand generation generation brilliant mit scientist figure go to large number ethic question right science thinking robot computer forth depend question timeframe year face question face year spread disruptive technology broadly possible gain maximum benefit primary benefit healthcare education healthcare obvious believe medical matter fact big datum health save life allow deal skin cancer cancer ophthalmological problem people work psychological disease forth technique promise ai medicine extraordinary company startup fund solution live well argument education imagine generation child adult tutor educator ai base human properly train help smart help address language difficulty math difficulty focus gain societally make human smart healthy enormous translate decade decade benefit people work ai safety issue describe conversation community problem rule like google example announce policy respect ai safety certainly support think everybody support sense right help guide research killer robot arrive year build line thinking say time scale topic topic find useful business intellectual think year think year useful productive industry essentially example year prediction correct let review ai right ai largely invent mit couple university original claim decade phd student study ai bit enter look period know ai winter go year generation science scientist group people lot progress algorithm improve computer approve take brilliant mathematician start fellow name jeff hinton toronto montreal basically invent deep learning model empower today seminal work year ago year popularize think timeframe level discovery hard predict people think fly equivalent fly car know view wanna limb know couple thing year know people alive know platform sustainable earth limit way know kind platform go to build consistent principle describe empowering individual sensitive ecology think human go to great deal smarter think go to lot smart tool discuss course people live long life extension continue apace baby bear today reasonable chance live pretty exciting past century well care mention interesting statistic large percentage people live city today half world live city great story humanity year rural urban migration occur united states occur europe occur asia occur africa people city city crowd believe health get well productivity get well iq educational capability improve good news people move city livable safe work great leader history tech insight draw difference leadership style steve jobs elon musk larry page new ceo sandra pichai calm sage mad genius thing learn young executive single formula leadership try teach work people understand need need quickly people entrepreneur know fast people system thinker planner somewhat conservative thorough execution little bit risk risk little bit risk averse people sort slightly insane sense emphatic charismatic feel drive forth single formula success thing unify people name high intelligence end day thing characterize see world quick fast process information fast necessarily right decision time thing interesting people start young think steve jobs start apple roughly think bill gates start roughly think time mark zuckerberg good example time year year old year experience deal people product shipment press business forth incredible experience compare rest busy get phds yes exactly celebrate people life experience right help inform judgment end day organization easy question deal right design building color product box look like right problem interesting room problem face right term way operate way deal employee customer innovation profoundly challenging company demonstrably different culturally fact cut behave differently base input internal culture different compensation scheme different value different proof diversity work face tough decision need advice say good thing find good person world advice find way room ask let ask long wind way write good search engine lycos excite altavista infoseek ask jeeves maybe yahoo google step disrupt disrupt nature search nature access information way discover new knowledge actually year later good personal ai assistant include course good google speak medical education impact ai assistant bring arrive question personal hope situation represent say dreamer crazy engineer life dream create ai assistant step take goal research scientist human centered ai mit step sit face passion larry sergey simple startup simple question give low odd success timing luck require countless factor control predict thing larry sergey face calculation strategy follow step simply follow passion choice think people university try study extraordinarily chaotic nature innovation entrepreneurship answer conversation sense moment case google datum need organize well algorithm invent well way today human center ai area research new approach big field new approach different startup fund research project try graduate student work new approach mit people look learn standpoint look child learning child learn start age work fantastic approach different approach people take bet end day successful entrepreneur crazy sound opportunity base happen let use uber example travis sell story co founder sit paris idea cab say smartphone rest history equivalent travis eiffel tower cab moment entrepreneur advantage human center ai great startup psychology moment sergey larry talk listen interview nonchalant fascinating web datum algorithm kind want play data like nice way organize datum happen remember graduate student stanford think interesting build search engine keep room power room door power room run extension cord right go find house google world headquarters people right start company raise andy bechtolsheim sun founder dave cheriton point beginning simple base powerful insight replicable model startup powerful insight beginning simple innovation larry sergey case pagerank brilliant idea cite paper world today rich people world money simply effect passion inherent goal fascinating person ask society individual level company level nation drive desire wealth think drive learn romanticize notion meaning life having achieve success dimension study human happiness threshold typically relatively low conversation difference happiness money happiness correlate meaning purpose sense family sense impact organize life assume nice home forth far happy figure care work service great deal evidence people happy serve go directly sort press induce excitement powerful wealthy leader kind consequential people situation fortunate responsibility basically work educate opportunity use wealth advance human society case particularly interested tool artificial intelligence machine learning society well mention education mention inequality middle class thing like passion matter matter believe important life far satisfying spend life think well place end discussion meaning life eric thank,"['Eric Schmidt', 'Edward Frankel', 'Michael Lesk', 'Steve Jobs', 'Elon Musk', 'Stuart Russell', 'Max Tegmark', 'Yoshua Bengio', 'Steven Pinker', 'Jeff Hinton', 'Larry Page', 'Sandra Pichai', 'Bill Gates', 'Mark Zuckerberg', 'Andy Bechtolsheim', 'Dave Cheriton']","['Google', 'MIT', 'Stanford University']","['Deep Neural Networks', 'Natural Language Processing Models', 'Cloud Computing Platforms', 'Internet of Things']","['AI in Business and Industry', 'Technological Innovation', 'Future of Technology', 'Machine Learning Fundamentals', 'Human-AI Interaction']"
9,Stuart Russell,Long-Term Future of AI,"The following is a conversation with Stuart Russell. He's a professor of computer science at UC Berkeley and a coauthor of a book that introduced me and millions of other people to the amazing world of AI called Artificial Intelligence, A Modern Approach. So it was an honor for me to have this conversation as part of MIT course in artificial general intelligence and the artificial intelligence podcast. If you enjoy it, please subscribe on YouTube, iTunes or your podcast provider of choice, or simply connect with me on Twitter at Lex Friedman spelled F R I D. And now here's my conversation with Stuart Russell. So you've mentioned in 1975 in high school, you've created one of your first AI programs that play chess. Were you ever able to build a program that beat you at chess or another board game? So my program never beat me at chess. I actually wrote the program at Imperial College. So I used to take the bus every Wednesday with a box of cards this big and shove them into the card reader. And they gave us eight seconds of CPU time. It took about five seconds to read the cards in and compile the code. So we had three seconds of CPU time, which was enough to make one move, you know, with a not very deep search. And then we would print that move out and then we'd have to go to the back of the queue and wait to feed the cards in again. How deep was the search? Are we talking about one move, two moves, three moves? No, I think we got an eight move, a depth eight with alpha beta. And we had some tricks of our own about move ordering and some pruning of the tree. But you were still able to beat that program? Yeah, yeah. I was a reasonable chess player in my youth. I did an Othello program and a backgammon program. So when I got to Berkeley, I worked a lot on what we call meta reasoning, which really means reasoning about reasoning. And in the case of a game playing program, you need to reason about what parts of the search tree you're actually going to explore because the search tree is enormous, bigger than the number of atoms in the universe. And the way programs succeed and the way humans succeed is by only looking at a small fraction of the search tree. And if you look at the right fraction, you play really well. If you look at the wrong fraction, if you waste your time thinking about things that are never going to happen, moves that no one's ever going to make, then you're going to lose because you won't be able to figure out the right decision. So that question of how machines can manage their own computation, how they decide what to think about, is the meta reasoning question. And we developed some methods for doing that. And very simply, the machine should think about whatever thoughts are going to improve its decision quality. We were able to show that both for Othello, which is a standard two player game, and for Backgammon, which includes dice rolls, so it's a two player game with uncertainty. For both of those cases, we could come up with algorithms that were actually much more efficient than the standard alpha beta search, which chess programs at the time were using. And that those programs could beat me. And I think you can see the same basic ideas in Alpha Go and Alpha Zero today. The way they explore the tree is using a form of meta reasoning to select what to think about based on how useful it is to think about it. Is there any insights you can describe with our Greek symbols of how do we select which paths to go down? There's really two kinds of learning going on. So as you say, Alpha Go learns to evaluate board positions. So it can look at a go board. And it actually has probably a superhuman ability to instantly tell how promising that situation is. To me, the amazing thing about Alpha Go is not that it can be the world champion with its hands tied behind his back, but the fact that if you stop it from searching altogether, so you say, okay, you're not allowed to do any thinking ahead. You can just consider each of your legal moves and then look at the resulting situation and evaluate it. So what we call a depth one search. So just the immediate outcome of your moves and decide if that's good or bad. That version of Alpha Go can still play at a professional level. And human professionals are sitting there for five, 10 minutes deciding what to do and Alpha Go in less than a second can instantly intuit what is the right move to make based on its ability to evaluate positions. And that is remarkable because we don't have that level of intuition about Go. We actually have to think about the situation. So anyway, that capability that Alpha Go has is one big part of why it beats humans. The other big part is that it's able to look ahead 40, 50, 60 moves into the future. And if it was considering all possibilities, 40 or 50 or 60 moves into the future, that would be 10 to the 200 possibilities. So way more than atoms in the universe and so on. So it's very, very selective about what it looks at. So let me try to give you an intuition about how you decide what to think about. It's a combination of two things. One is how promising it is. So if you're already convinced that a move is terrible, there's no point spending a lot more time convincing yourself that it's terrible because it's probably not going to change your mind. So the real reason you think is because there's some possibility of changing your mind about what to do. And it's that changing your mind that would result then in a better final action in the real world. So that's the purpose of thinking is to improve the final action in the real world. So if you think about a move that is guaranteed to be terrible, you can convince yourself it's terrible, you're still not going to change your mind. But on the other hand, suppose you had a choice between two moves. One of them you've already figured out is guaranteed to be a draw, let's say. And then the other one looks a little bit worse. It looks fairly likely that if you make that move, you're going to lose. But there's still some uncertainty about the value of that move. There's still some possibility that it will turn out to be a win. Then it's worth thinking about that. So even though it's less promising on average than the other move, which is a good move, it's worth thinking about on average than the other move, which is guaranteed to be a draw. There's still some purpose in thinking about it because there's a chance that you will change your mind and discover that in fact it's a better move. So it's a combination of how good the move appears to be and how much uncertainty there is about its value. The more uncertainty, the more it's worth thinking about because there's a higher upside if you want to think of it that way. And of course in the beginning, especially in the AlphaGo Zero formulation, everything is shrouded in uncertainty. So you're really swimming in a sea of uncertainty. So it benefits you to, I mean, actually following the same process as you described, but because you're so uncertain about everything, you basically have to try a lot of different directions. Yeah. So the early parts of the search tree are fairly bushy that it will look at a lot of different possibilities, but fairly quickly, the degree of certainty about some of the moves, I mean, if a move is really terrible, you'll pretty quickly find out, right? You lose half your pieces or half your territory and then you'll say, okay, this is not worth thinking about anymore. And then so further down the tree becomes very long and narrow and you're following various lines of play, 10, 20, 30, 40, 50 moves into the future. And that again is something that human beings have a very hard time doing mainly because they just lack the short term memory. You just can't remember a sequence of moves that's 50 moves long. And you can't imagine the board correctly for that many moves into the future. Of course, the top players, I'm much more familiar with chess, but the top players probably have, they have echoes of the same kind of intuition instinct that in a moment's time AlphaGo applies when they see a board. I mean, they've seen those patterns, human beings have seen those patterns before at the top, at the grandmaster level. It seems that there is some similarities or maybe it's our imagination creates a vision of those similarities, but it feels like this kind of pattern recognition that the AlphaGo approaches are using is similar to what human beings at the top level are using. I think there's, there's some truth to that, but not entirely. Yeah. I mean, I think the, the extent to which a human grandmaster can reliably instantly recognize the right move and instantly recognize the value of the position. I think that's a little bit overrated. But if you sacrifice a queen, for example, I mean, there's these, there's these beautiful games of chess with Bobby Fischer, somebody where it's seeming to make a bad move. And I'm not sure there's a perfect degree of calculation involved where they've calculated all the possible things that happen, but there's an instinct there, right? That somehow adds up to Yeah. So I think what happens is you, you, you get a sense that there's some possibility in the position, even if you make a weird looking move, that it opens up some, some lines of, of calculation that otherwise would be definitely bad. And, and it's that intuition that there's something here in this position that might, might yield a win. And then you follow that, right? And, and in some sense, when a, when a chess player is following a line and in his or her mind, they're, they're mentally simulating what the other person is going to do, what the opponent is going to do. And they can do that as long as the moves are kind of forced, right? As long as there's, you know, there's a, a fort we call a forcing variation where the opponent doesn't really have much choice how to respond. And then you follow that, how to respond. And then you see if you can force them into a situation where you win. You know, we see plenty of mistakes even, even in grandmaster games where they just miss some simple three, four, five move combination that, you know, wasn't particularly apparent in, in the position, but was still there. That's the thing that makes us human. Yeah. So when you mentioned that in Othello, those games were after some matter reasoning improvements and research was able to beat you. How did that make you feel? Part of the meta reasoning capability that it had was based on learning and, and you could sit down the next day and you could just feel that it had got a lot smarter, you know, and all of a sudden you really felt like you're sort of pressed against the wall because it was, it was much more aggressive and, and was totally unforgiving of any minor mistake that you might make. And, and actually it seemed understood the game better than I did. And Gary Kasparov has this quote where during his match against Deep Blue, he said, he suddenly felt that there was a new kind of intelligence across the board. Do you think that's a scary or an exciting possibility for, for Kasparov and for yourself in, in the context of chess, purely sort of in this, like that feeling, whatever that is? I think it's definitely an exciting feeling. You know, this is what made me work on AI in the first place was as soon as I really understood what a computer was, I wanted to make it smart. You know, I started out with the first program I wrote was for the Sinclair programmable calculator. And I think you could write a 21 step algorithm. That was the biggest program you could write, something like that. And do little arithmetic calculations. So I think I implemented Newton's method for a square roots and a few other things like that. But then, you know, I thought, okay, if I just had more space, I could make this thing intelligent. And so I started thinking about AI and, and I think the, the, the thing that's scary is not, is not the chess program because, you know, chess programs, they're not in the taking over the world business. But if you extrapolate, you know, there are things about chess that don't resemble the real world, right? We know, we know the rules of chess. The chess board is completely visible to the program where of course the real world is not most, most of the real world is, is not visible from wherever you're sitting, so to speak. And to overcome those kinds of problems, you need qualitatively different algorithms. Another thing about the real world is that, you know, we, we regularly plan ahead on the timescales involving billions or trillions of steps. Now we don't plan those in detail, but you know, when you choose to do a PhD at Berkeley, that's a five year commitment and that amounts to about a trillion motor control steps that you will eventually be committed to. Including going up the stairs, opening doors, drinking water. Yeah. I mean, every, every finger movement while you're typing, every character of every paper and the thesis and everything. So you're not committing in advance to the specific motor control steps, but you're still reasoning on a timescale that will eventually reduce to trillions of motor control actions. And so for all of these reasons, you know, AlphaGo and Deep Blue and so on don't represent any kind of threat to humanity, but they are a step towards it, right? And progress in AI occurs by essentially removing one by one these assumptions that make problems easy. Like the assumption of complete observability of the situation, right? We remove that assumption, you need a much more complicated kind of computing design. It needs, it needs something that actually keeps track of all the things you can't see and tries to estimate what's going on. And there's inevitable uncertainty in that. So it becomes a much more complicated problem. But, you know, we are removing those assumptions. We are starting to have algorithms that can cope with much longer timescales, that can cope with uncertainty, that can cope with partial observability. And so each of those steps sort of magnifies by a thousand the range of things that we can do with AI systems. So the way I started in AI, I wanted to be a psychiatrist for a long time. I wanted to understand the mind in high school and of course program and so on. And I showed up University of Illinois to an AI lab and they said, okay, I don't have time for you, but here's a book, AI and Modern Approach. I think it was the first edition at the time. Here, go, go, go learn this. And I remember the lay of the land was, well, it's incredible that we solved chess, but we'll never solve go. I mean, it was pretty certain that go in the way we thought about systems that reason wasn't possible to solve. And now we've solved this. So it's a very... Well, I think I would have said that it's unlikely we could take the kind of algorithm that was used for chess and just get it to scale up and work well for go. And at the time what we thought was that in order to solve go, we would have to do something similar to the way humans manage the complexity of go, which is to break it down into kind of sub games. So when a human thinks about a go board, they think about different parts of the board as sort of weakly connected to each other. And they think about, okay, within this part of the board, here's how things could go in that part of board, here's how things could go. And then you try to sort of couple those two analyses together and deal with the interactions and maybe revise your views of how things are going to go in each part. And then you've got maybe five, six, seven, ten parts of the board. And that actually resembles the real world much more than chess does because in the real world, we have work, we have home life, we have sport, different kinds of activities, shopping, these all are connected to each other, but they're weakly connected. So when I'm typing a paper, I don't simultaneously have to decide which order I'm going to get the milk and the butter, that doesn't affect the typing. But I do need to realize, okay, I better finish this before the shops close because I don't have anything, I don't have any food at home. So there's some weak connection, but not in the way that chess works where everything is tied into a single stream of thought. So the thought was that to solve go, we'd have to make progress on stuff that would be useful for the real world. And in a way, AlphaGo is a little bit disappointing, right? Because the program designed for AlphaGo is actually not that different from Deep Blue or even from Arthur Samuel's checker playing program from the 1950s. And in fact, the two things that make AlphaGo work is one is this amazing ability to evaluate the positions, and the other is the meta reasoning capability, which allows it to explore some paths in the tree very deeply and to abandon other paths very quickly. Including yourself because you're on camera now and your voice is coming through with high resolution. Yeah, so you could take what I'm saying and replace it with pretty much anything else you wanted me to be saying. And it's a very simple thing. Take what I'm saying and replace it with pretty much anything else you wanted me to be saying. And even it would change my lips and facial expressions to fit. And there's actually not much in the way of real legal protection against that. I think in the commercial area, you could say, yeah, you're using my brand and so on. There are rules about that. But in the political sphere, I think at the moment, anything goes. That could be really, really damaging. And let me just try to make not an argument, but try to look back at history and say something dark in essence is while regulation seems to be, oversight seems to be exactly the right thing to do here. It seems that human beings, what they naturally do is they wait for something to go wrong. If you're talking about nuclear weapons, you can't talk about nuclear weapons being dangerous until somebody actually like the United States drops the bomb or Chernobyl melting. Do you think we will have to wait for things going wrong in a way that's obviously damaging to society, not an existential risk, but obviously damaging? Or do you have faith that... I hope not, but I think we do have to look at history. And so the two examples you gave, nuclear weapons and nuclear power are very, very interesting because nuclear weapons, we knew in the early years of the 20th century that atoms contained a huge amount of energy. We had E equals MC squared. We knew the mass differences between the different atoms and their components. And we knew that you might be able to make an incredibly powerful explosive. So HG Wells wrote science fiction book, I think in 1912. Frederick Soddy, who was the guy who discovered isotopes, the Nobel prize winner, he gave a speech in 1915 saying that one pound of this new explosive would be the equivalent of 150 tons of dynamite, which turns out to be about right. And this was in World War I, so he was imagining how much worse the world war would be if we were using that kind of explosive. But the physics establishment simply refused to believe that these things could be made. Including the people who are making it. Well, so they were doing the nuclear physics. I mean, eventually were the ones who made it. You talk about Fermi or whoever. Well, so up to the development was mostly theoretical. So it was people using sort of primitive kinds of particle acceleration and doing experiments at the level of single particles or collections of particles. They weren't yet thinking about how to actually make a bomb or anything like that. But they knew the energy was there and they figured if they understood it better, it might be possible. But the physics establishment, their view, and I think because they did not want it to be true, their view was that it could not be true. That this could not not provide a way to make a super weapon. And there was this famous speech given by Rutherford, who was the sort of leader of nuclear physics. And it was on September 11th, 1933. And he said, anyone who talks about the possibility of obtaining energy from transformation of atoms is talking complete moonshine. And the next morning, Leo Szilard read about that speech and then invented the nuclear chain reaction. And so as soon as he invented, as soon as he had that idea that you could make a chain reaction with neutrons, because neutrons were not repelled by the nucleus, so they could enter the nucleus and then continue the reaction. As soon as he has that idea, he instantly realized that the world was in deep doo doo. Because this is 1933, right? Hitler had recently come to power in Germany. Szilard was in London and eventually became a refugee and came to the US. And in the process of having the idea about the chain reaction, he figured out basically how to make a bomb and also how to make a reactor. And he patented the reactor in 1934. But because of the situation, the great power conflict situation that he could see happening, he kept that a secret. And so between then and the beginning of World War II, people were working, including the Germans, on how to actually create neutron sources, what specific fission reactions would produce neutrons of the right energy to continue the reaction. And that was demonstrated in Germany, I think in 1938, if I remember correctly. The first nuclear weapon patent was 1939 by the French. So this was actually going on well before World War II really got going. And then the British probably had the most advanced capability in this area. But for safety reasons, among others, and just resources, they moved the program from Britain to the US and then that became Manhattan Project. So the reason why we couldn't have any kind of oversight of nuclear weapons and nuclear technology was because we were basically already in an arms race and a war. LR But you mentioned then in the 20s and 30s. So what are the echoes? The way you've described this story, I mean, there's clearly echoes. Why do you think most AI researchers, folks who are really close to the metal, they really are not concerned about AI. They don't think about it, whether it's they don't want to think about it. But why do you think that is, is what are the echoes of the nuclear situation to the current AI situation? And what can we do about it? BF I think there is a kind of motivated cognition, which is a term in psychology means that you believe what you would like to be true, rather than what is true. And it's unsettling to think that what you're working on might be the end of the human race, obviously. So you would rather instantly deny it and come up with some reason why it couldn't be true. And I have, I collected a long list of reasons that extremely intelligent, competent AI scientists have come up with for why we shouldn't worry about this. For example, calculators are superhuman at arithmetic and they haven't taken over the world. So there's nothing to worry about. Well, okay, my five year old, you know, could have figured out why that was an unreasonable and really quite weak argument. Another one was, while it's theoretically possible that you could have superhuman AI destroy the world, it's also theoretically possible that a black hole could materialize right next to the earth and destroy humanity. I mean, yes, it's theoretically possible, quantum theoretically, extremely unlikely that it would just materialize right there. But that's a completely bogus analogy, because, you know, if the whole physics community on earth was working to materialize a black hole in near earth orbit, right? Wouldn't you ask them, is that a good idea? Is that going to be safe? You know, what if you succeed? Right. And that's the thing, right? The AI community is sort of refused to ask itself, what if you succeed? And initially I think that was because it was too hard, but, you know, Alan Turing asked himself that, and he said, we'd be toast, right? If we were lucky, we might be able to switch off the power, but probably we'd be toast. But there's also an aspect that because we're not exactly sure what the future holds, it's not clear exactly, so technically what to worry about, sort of how things go wrong. And so there is something, it feels like, maybe you can correct me if I'm wrong, but there's something paralyzing about worrying about something that logically is inevitable, but you have to think about it, logically is inevitable, but you don't really know what that will look like. Yeah, I think that's, it's a reasonable point and, you know, it's certainly in terms of existential risks, it's different from, you know, asteroid collides with the earth, right? Which, again, is quite possible, you know, it's happened in the past, it'll probably happen again, we don't know right now, but if we did detect an asteroid that was going to hit the earth in 75 years time, we'd certainly be doing something about it. Well, it's clear there's got big rock and there's, we'll probably have a meeting and see what do we do about the big rock with AI. Right, with AI, I mean, there are very few people who think it's not going to happen within the next 75 years. I know Rod Brooks doesn't think it's going to happen, maybe Andrew Ng doesn't think it's happened, but, you know, a lot of the people who work day to day, you know, as you say, at the rock face, they think it's going to happen. I think the median estimate from AI researchers is somewhere in 40 to 50 years from now, or maybe, you know, I think in Asia, they think it's going to be even faster than that. I'm a little bit more conservative, I think it'd probably take longer than that, but I think, you know, as happened with nuclear weapons, it can happen overnight that you have these breakthroughs and we need more than one breakthrough, but, you know, it's on the order of half a dozen, I mean, this is a very rough scale, but sort of half a dozen breakthroughs of that nature would have to happen for us to reach the superhuman AI. But the, you know, the AI research community is vast now, the massive investments from governments, from corporations, tons of really, really smart people, you know, you just have to look at the rate of progress in different areas of AI to see that things are moving pretty fast. So to say, oh, it's just going to be thousands of years, I don't see any basis for that. You know, I see, you know, for example, the Stanford 100 year AI project, right, which is supposed to be sort of, you know, the serious establishment view, their most recent report actually said it's probably not even possible. Oh, wow. Right. Which if you want a perfect example of people in denial, that's it. Because, you know, for the whole history of AI, we've been saying to philosophers who said it wasn't possible, well, you have no idea what you're talking about. Of course it's possible, right? Give me an argument for why it couldn't happen. And there isn't one, right? And now, because people are worried that maybe AI might get a bad name, or I just don't want to think about this, they're saying, okay, well, of course, it's not really possible. You know, imagine if, you know, the leaders of the cancer biology community got up and said, well, you know, of course, curing cancer, it's not really possible. There'd be complete outrage and dismay. And, you know, I find this really a strange phenomenon. So, okay, so if you accept that it's possible, and if you accept that it's probably going to happen, the point that you're making that, you know, how does it go wrong? A valid question. Without that, without an answer to that question, then you're stuck with what I call the gorilla problem, which is, you know, the problem that the gorillas face, right? They made something more intelligent than them, namely us, a few million years ago, and now they're in deep doo doo. So there's really nothing they can do. They've lost the control. They failed to solve the control problem of controlling humans, and so they've lost. So we don't want to be in that situation. And if the gorilla problem is the only formulation you have, there's not a lot you can do, right? Other than to say, okay, we should try to stop, you know, we should just not make the humans, or in this case, not make the AI. And I think that's really hard to do. I'm not actually proposing that that's a feasible course of action. I also think that, you know, if properly controlled AI could be incredibly beneficial. But it seems to me that there's a consensus that one of the major failure modes is this loss of control, that we create AI systems that are pursuing incorrect objectives. And because the AI system believes it knows what the objective is, it has no incentive to listen to us anymore, so to speak, right? It's just carrying out the strategy that it has computed as being the optimal solution. And, you know, it may be that in the process, it needs to acquire more resources to increase the possibility of success or prevent various failure modes by defending itself against interference. And so that collection of problems, I think, is something we can address. The other problems are, roughly speaking, you know, misuse, right? So even if we solve the control problem, we make perfectly safe controllable AI systems. Well, why? You know, why does Dr. Evil going to use those, right? He wants to just take over the world and he'll make unsafe AI systems that then get out of control. So that's one problem, which is sort of a, you know, partly a policing problem, partly a sort of a cultural problem for the profession of how we teach people what kinds of AI systems are safe. You talk about autonomous weapon system and how pretty much everybody agrees that there's too many ways that that can go horribly wrong. This great slaughterbots movie that kind of illustrates that beautifully. I want to talk about that. That's another, there's another topic I'm having to talk about. I just want to mention that what I see is the third major failure mode, which is overuse, not so much misuse, but overuse of AI that we become overly dependent. So I call this the WALL E problem. So if you've seen WALL E, the movie, all right, all the humans are on the spaceship and the machines look after everything for them, and they just watch TV and drink big gulps. And they're all sort of obese and stupid and they sort of totally lost any notion of human autonomy. And, you know, so in effect, right. This would happen like the slow boiling frog, right? We would gradually turn over more and more of the management of our civilization to machines as we are already doing. And this, you know, if this if this process continues, you know, we sort of gradually switch from sort of being the masters of technology to just being the guests. Right. So we become guests on a cruise ship, you know, which is fine for a week, but not not for the rest of eternity. You know, and it's almost irreversible. Right. Once you once you lose the incentive to, for example, you know, learn to be an engineer or a doctor or a sanitation operative or any other of the infinitely many ways that we maintain and propagate our civilization. You know, if you if you don't have the incentive to do any of that, you won't. And then it's really hard to recover. And of course, as just one of the technologies that could that third failure mode result in that there's probably other technology in general detaches us from it does a bit. But the difference is that in terms of the knowledge to to run our civilization, you know, up to now, we've had no alternative but to put it into people's heads. Right. And if you software with Google, I mean, so software in general, so computers in general, but but the, you know, the knowledge of how, you know, how a sanitation system works, you know, that's an AI has to understand that it's no good putting it into Google. So, I mean, we we've always put knowledge in on paper, but paper doesn't run our civilization and only runs when it goes from the paper into people's heads again. Right. So we've always propagated civilization through human minds. And we've spent about a trillion person years doing that. I literally write you, you can work it out. It's about right. There's about just over 100 billion people who've ever lived. And each of them has spent about 10 years learning stuff to keep their civilization going. And so that's a trillion person years we put into this effort. Beautiful way to describe all civilization. And now we're, you know, we're in danger of throwing that away. So this is a problem that AI can't solve. It's not a technical problem. It's you know, if we do our job right, the AI systems will say, you know, the human race doesn't in the long run want to be passengers in a cruise ship. The human race wants autonomy. This is part of human preferences. So we, the AI systems are not going to do this stuff for you. You've got to do it for yourself. Right. I'm not going to carry you to the top of Everest in an autonomous helicopter. You have to climb it if you want to get the benefit and so on. So, but I'm afraid that because we are short sighted and lazy, we're going to override the AI systems. And, and there's an amazing short story that I recommend to everyone that I talked to about this called The Machine Stops, written in 1909 by E.M. Forster, who, you know, wrote novels about the British Empire and sort of things that became costume dramas on the BBC. But he wrote this one science fiction story, which is an amazing vision of the future. It has basically iPads, it has video conferencing, it has MOOCs, it has computer induced obesity. I mean, literally it's what people spend their time doing is giving online courses or listening to online courses and talking about ideas, but they never get out there in the real world. They don't really have a lot of face to face contact. Everything is done online, you know, so all the things we're worrying about now were described in the story. And, and then the human race becomes more and more dependent on the machine, loses knowledge of how things really run and then becomes vulnerable to collapse. And so it's a, it's a pretty unbelievably amazing story for someone writing in 1909 to imagine all this. So there's very few people that represent artificial intelligence more than you Stuart Russell. If you say it's okay, that's very kind. So it's all my fault. Right. You're often brought up as the person, well, Stuart Russell, like the AI person is worried about this. That's why you should be worried about it. Do you feel the burden of that? I don't know if you feel that at all, but when I talk to people like from, you talk about people outside of computer science, when they think about this, Stuart Russell is worried about AI safety. You should be worried too. Do you feel the burden of that? I mean, in a practical sense, yeah, because I get, you know, a dozen, sometimes 25 invitations a day to talk about it, to give interviews, to write press articles and so on. So in that very practical sense, I'm seeing that people are concerned and really interested about this. Are you worried that you could be wrong as all good scientists are? Of course. I worry about that all the time. I mean, that's, that's always been the way that I, I've worked, you know, is like I have an argument in my head with myself, right? So I have, I have some idea and then I think, okay, how could that be wrong? Or did someone else already have that idea? So I'll go and, you know, search in as much literature as I can to see whether someone else already thought of that or, or even refuted it. So, you know, I, right now I'm, I'm reading a lot of philosophy because, you know, in, in the form of the debates over, over utilitarianism and, and other kinds of moral, moral formulas, shall we say, people have already thought through some of these issues. But, you know, what, one of the things I'm, I'm not seeing in a lot of these debates is this specific idea about the importance of uncertainty in the objective that this is the way we should think about machines that are beneficial to humans. So this idea of provably beneficial machines based on explicit uncertainty in the objective, you know, it seems to be, you know, my gut feeling is this is the core of it. It's going to have to be elaborated in a lot of different directions and there are a lot of beneficial. Yeah. But there, there are, I mean, it has to be right. We can't afford, you know, hand wavy beneficial because there are, you know, whenever we do hand wavy stuff, there are loopholes. And the thing about super intelligent machines is they find the loopholes, you know, just like, you know, tax evaders. If you don't write your tax law properly, people will find the loopholes and end up paying no tax. And, and so you should think of it this way and, and getting those definitions right, you know, it is really a long process, you know, so you can, you can define mathematical frameworks and within that framework, you can prove mathematical theorems that yes, this will, you know, this, this theoretical entity will be provably beneficial to that theoretical entity, but that framework may not match the real world in some crucial way. So it's a long process, thinking through it, iterating and so on. Last question. Yep. You have 10 seconds to answer it. What is your favorite sci fi movie about AI? I would say interstellar has my favorite robots. Oh, beats space. Yeah. Yeah. Yeah. So, so Tars, the robots, one of the robots in interstellar is the way robot should behave. And, uh, I would say ex machina is in some ways, the one, the one that makes you think, uh, in a nervous kind of way about, about where we're going. Well Stuart, thank you so much for talking today. Pleasure. So this word meta reasoning, while technically correct, inspires perhaps the wrong degree of power that AlphaGo has, for example, the word reasoning is a powerful word. So let me ask you, sort of, you were part of the symbolic AI world for a while, like AI was, there's a lot of excellent, interesting ideas there that unfortunately met a winter. And so do you think it reemerges? So I would say, yeah, it's not quite as simple as that. So the AI winter for the first winter that was actually named as such was the one in the late 80s. And that came about because in the mid 80s, there was a really a concerted attempt to push AI out into the real world using what was called expert system technology. And for the most part, that technology was just not ready for primetime. They were trying, in many cases, to do a form of uncertain reasoning, judgment, combinations of evidence, diagnosis, those kinds of things, which was simply invalid. And when you try to apply invalid reasoning methods to real problems, you can fudge it for small versions of the problem. But when it starts to get larger, the thing just falls apart. So many companies found that the stuff just didn't work, and they were spending tons of money on consultants to try to make it work. And there were other practical reasons, like they were asking the companies to buy incredibly expensive Lisp machine workstations, which were literally between $50,000 and $100,000 in 1980s money, which would be like between $150,000 and $300,000 per workstation in current prices. And then the bottom line, they weren't seeing a profit from it. Yeah, in many cases. I think there were some successes, there's no doubt about that. But people, I would say, overinvested. Every major company was starting an AI department, just like now. And I worry a bit that we might see similar disappointments, not because the current technology is invalid, but it's limited in its scope. And it's almost the duel of the scope problems that expert systems had. So what have you learned from that hype cycle? And what can we do to prevent another winter, for example? Yeah, so when I'm giving talks these days, that's one of the warnings that I give. So this is a two part warning slide. One is that rather than data being the new oil, data is the new snake oil. That's a good line. And then the other is that we might see a kind of very visible failure in some of the major application areas. And I think self driving cars would be the flagship. And I think when you look at the history, so the first self driving car was on the freeway, driving itself, changing lanes, overtaking in 1987. And so it's more than 30 years. And that kind of looks like where we are today, right? You know, prototypes on the freeway, changing lanes and overtaking. Now, I think that's one of the things that's been made, particularly on the perception side. So we worked a lot on autonomous vehicles in the early mid 90s at Berkeley. And we had our own big demonstrations. We put congressmen into self driving cars and had them zooming along the freeway. And the problem was clearly perception. At the time, the problem was perception. Yeah. So in simulation, with perfect perception, you could actually show that you can drive safely for a long time, even if the other cars are misbehaving and so on. But simultaneously, we worked on machine vision for detecting cars and tracking pedestrians and so on. And we couldn't get the cars to do that. And so we had to do that for pedestrians and so on. And we couldn't get the reliability of detection and tracking up to a high enough level, particularly in bad weather conditions, nighttime, rainfall. Good enough for demos, but perhaps not good enough to cover the general operation. Yeah. So the thing about driving is, you know, suppose you're a taxi driver, you know, and you drive every day, eight hours a day for 10 years, right? That's 100 million seconds of driving, you know, and any one of those seconds, you can make a fatal mistake. So you're talking about eight nines of reliability, right? Now, if your vision system only detects 98.3% of the vehicles, right, then that's sort of, you know, one in a bit nines of reliability. So you have another seven orders of magnitude to go. And this is what people don't understand. They think, oh, because I had a successful demo, I'm pretty much done. But you're not even within seven orders of magnitude of being done. And that's the difficulty. And it's not the, can I follow a white line? That's not the problem, right? We follow a white line all the way across the country. But it's the weird stuff that happens. It's all the edge cases, yeah. The edge case, other drivers doing weird things. You know, so if you talk to Google, right, so they had actually a very classical architecture where, you know, you had machine vision which would detect all the other cars and pedestrians and the white lines and the road signs. And then basically that was fed into a logical database. And then you had a classical 1970s rule based expert system telling you, okay, if you're in the middle lane and there's a bicyclist in the right lane who is signaling this, then you do that, right? And what they found was that every day they'd go out and there'd be another situation that the rules didn't cover. You know, so they'd come to a traffic circle and there's a little girl riding her bicycle the wrong way around the traffic circle. Okay, what do you do? We don't have a rule. Oh my God. Okay, stop. And then, you know, they come back and add more rules and they just found that this was not really converging. And if you think about it, right, how do you deal with an unexpected situation, meaning one that you've never previously encountered and the sort of reasoning required to figure out the solution for that situation has never been done. It doesn't match any previous situation in terms of the kind of reasoning you have to do. Well, you know, in chess programs, this happens all the time, right? You're constantly coming up with situations you haven't seen before and you have to reason about them and you have to think about, okay, here are the possible things I could do. Here are the outcomes. Here's how desirable the outcomes are and then pick the right one. You know, in the 90s, we were saying, okay, this is how you're going to have to do automated vehicles. They're going to have to have a look ahead capability, but the look ahead for driving is more difficult than it is for chess because there's humans and they're less predictable than chess pieces. Well, then you have an opponent in chess who's also somewhat unpredictable. But for example, in chess, you always know the opponent's intention. They're trying to beat you, right? Whereas in driving, you don't know is this guy trying to turn left or has he just forgotten to turn off his turn signal or is he drunk or is he changing the channel on his radio or whatever it might be. You've got to try and figure out the mental state, the intent of the other drivers to forecast the possible evolutions of their trajectories. And then you've got to figure out, okay, which is the trajectory for me that's going to be safest. And those all interact with each other because the other drivers are going to react to your trajectory and so on. So, you know, they've got the classic merging onto the freeway problem where you're kind of racing a vehicle that's already on the freeway and you're going to pull ahead of them or you're going to let them go first and pull in behind and you get this sort of uncertainty about who's going first. So all those kinds of things mean that you need a decision making architecture that's very different from either a rule based system or it seems to me kind of an end to end neural network system. So just as AlphaGo is pretty good when it doesn't do any look ahead, but it's way, way, way, way better when it does, I think the same is going to be true for driving. You can have a driving system that's pretty good when it doesn't do any look ahead, but that's not good enough. And we've already seen multiple deaths caused by poorly designed machine learning algorithms that don't really understand what they're doing. Yeah. On several levels, I think on the perception side, there's mistakes being made by those algorithms where the perception is very shallow. On the planning side, the look ahead, like you said, and the thing that we come up against that's really interesting when you try to deploy systems in the real world is you can't think of an artificial intelligence system as a thing that responds to the world always. You have to realize that it's an agent that others will respond to as well. So in order to drive successfully, you can't just try to do obstacle avoidance. Right. You can't pretend that you're invisible, right? You're the invisible car. Right. It doesn't work that way. I mean, but you have to assert yet others have to be scared of you. Just we're all, there's this tension, there's this game. So if we study a lot of work with pedestrians, if you approach pedestrians as purely an obstacle avoidance, so you're doing look ahead as in modeling the intent that they're not going to, they're going to take advantage of you. They're not going to respect you at all. There has to be a tension, a fear, some amount of uncertainty. That's how we have created. Or at least just a kind of a resoluteness. You have to display a certain amount of resoluteness. You can't be too tentative. And yeah, so the solutions then become pretty complicated, right? You get into game theoretic analyses. And so at Berkeley now, we're working a lot on this kind of interaction between machines and humans. And that's exciting. And so my colleague, Ankur Dragan, actually, if you formulate the problem game theoretically, you just let the system figure out the solution. It does interesting unexpected things. Like sometimes at a stop sign, if no one is going first, the car will actually back up a little, right? And just to indicate to the other cars that they should go. And that's something it invented entirely by itself. We didn't say this is the language of communication at stop signs. It figured it out. That's really interesting. So let me one just step back for a second. Just this beautiful philosophical notion. So Pamela McCordick in 1979 wrote, AI began with the ancient wish to forge the gods. So when you think about the history of our civilization, do you think that there is an inherent desire to create, let's not say gods, but to create superintelligence? Is it inherent to us? Is it in our genes? That the natural arc of human civilization is to create things that are of greater and greater power and perhaps echoes of ourselves. So to create the gods as Pamela said. Maybe. I mean, we're all individuals, but certainly we see over and over again in history, individuals who thought about this possibility. Hopefully when I'm not being too philosophical here, but if you look at the arc of this, where this is going and we'll talk about AI safety, we'll talk about greater and greater intelligence. Do you see that there in, when you created the Othello program and you felt this excitement, what was that excitement? Was it excitement of a tinkerer who created something cool like a clock? Or was there a magic or was it more like a child being born? Yeah. So I mean, I certainly understand that viewpoint. And if you look at the Lighthill report, which was, so in the 70s, there was a lot of controversy in the UK about AI and whether it was for real and how much money the government should invest. And there was a long story, but the government commissioned a report by Lighthill, who was a physicist, and he wrote a very damning report about AI, which I think was the point. And he said that these are frustrated men who are unable to have children would like to create and create a life as a kind of replacement, which I think is really pretty unfair. But there is a kind of magic, I would say, when you build something and what you're building in is really just, you're building in some understanding of the principles of learning and decision making. And to see those principles actually then turn into intelligent behavior in specific situations, it's an incredible thing. And that is naturally going to make you think, okay, where does this end? And so there's magical optimistic views of where it ends, whatever your view of optimism is, whatever your view of utopia is, it's probably different for everybody. But you've often talked about concerns you have of how things may go wrong. So I've talked to Max Tegmark. There's a lot of interesting ways to think about AI safety. You're one of the seminal people thinking about this problem amongst sort of being in the weeds of actually solving specific AI problems. You're also thinking about the big picture of where are we going? So can you talk about several elements of it? Let's just talk about maybe the control problem. So this idea of losing ability to control the behavior in our AI system. So how do you see that? How do you see that coming about? What do you think we can do to manage it? Well, so it doesn't take a genius to realize that if you make something that's smarter than you, you might have a problem. Alan Turing wrote about this and gave lectures about this in 1951. He did a lecture on the radio and he basically says, once the machine thinking method starts, very quickly they'll outstrip humanity. And if we're lucky, we might be able to turn off the power at strategic moments, but even so, our species would be humbled. Actually, he was wrong about that. If it's sufficiently intelligent machine, it's not going to let you switch it off. It's actually in competition with you. So what do you think is most likely going to happen? What do you think is meant just for a quick tangent, if we shut off this super intelligent machine that our species will be humbled? I think he means that we would realize that we are inferior, right? That we only survive by the skin of our teeth because we happen to get to the off switch just in time. And if we hadn't, then we would have lost control over the earth. Are you more worried when you think about this stuff about super intelligent AI, or are you more worried about super powerful AI that's not aligned with our values? So the paperclip scenarios kind of... So the main problem I'm working on is the control problem, the problem of machines pursuing objectives that are, as you say, not aligned with human objectives. And this has been the way we've thought about AI since the beginning. You build a machine for optimizing, and then you put in some objective, and it optimizes, right? And we can think of this as the King Midas problem, right? Because if the King Midas put in this objective, everything I touch should turn to gold. And the gods, that's like the machine, they said, okay, done. You now have this power. And of course, his father, his drink, and his family all turned to gold. And then he dies of misery and starvation. And it's a warning, it's a failure mode that pretty much every culture in history has had some story along the same lines. There's the genie that gives you three wishes, and the third wish is always, you know, please undo the first two wishes because I messed up. And when Arthur Samuel wrote his checker playing program, which learned to play checkers considerably better than Arthur Samuel could play, and actually reached a pretty decent standard. Norbert Wiener, who was one of the major mathematicians of the 20th century, he's sort of the father of modern automation control systems. He saw this and he basically extrapolated, as Turing did, and said, okay, this is how we could lose control. And specifically, that we have to be certain that the purpose we put into the machine is the purpose which we really desire. And the problem is, we can't do that. You mean we're not, it's a very difficult to encode, to put our values on paper is really difficult, or you're just saying it's impossible? So theoretically, it's possible, but in practice, it's extremely unlikely that we could specify correctly in advance, the full range of concerns of humanity. You talked about cultural transmission of values, I think is how humans to human transmission of values happens, right? Well, we learn, yeah, I mean, as we grow up, we learn about the values that matter, how things should go, what is reasonable to pursue and what isn't reasonable to pursue. You think machines can learn in the same kind of way? Yeah, so I think that what we need to do is to get away from this idea that you build an optimising machine, and then you put the objective into it. Because if it's possible that you might put in a wrong objective, and we already know this is possible because it's happened lots of times, right? That means that the machine should never take an objective that's given as gospel truth. Because once it takes the objective as gospel truth, then it believes that whatever actions it's taking in pursuit of that objective are the correct things to do. So you could be jumping up and down and saying, no, no, no, no, you're going to destroy the world, but the machine knows what the true objective is and is pursuing it, and tough luck to you. And this is not restricted to AI, right? This is, I think, many of the 20th century technologies, right? So in statistics, you minimise a loss function, the loss function is exogenously specified. In control theory, you minimise a cost function. In operations research, you maximise a reward function, and so on. So in all these disciplines, this is how we conceive of the problem. And it's the wrong problem because we cannot specify with certainty the correct objective, right? We need uncertainty, we need the machine to be uncertain about what it is that it's supposed to be maximising. Favourite idea of yours, I've heard you say somewhere, well, I shouldn't pick favourites, but it just sounds beautiful, we need to teach machines humility. It's a beautiful way to put it, I love it. That they're humble, they know that they don't know what it is they're supposed to be doing, and that those objectives, I mean, they exist, they're within us, but we may not be able to we may not be able to explicate them, we may not even know how we want our future to go. Exactly. And the machine, a machine that's uncertain is going to be deferential to us. So if we say, don't do that, well, now the machines learn something a bit more about our true objectives, because something that it thought was reasonable in pursuit of our objective, turns out not to be, so now it's learned something. So it's going to defer because it wants to be doing what we really want. And that point, I think, is absolutely central to solving the control problem. And it's a different kind of AI when you take away this idea that the objective is known, then in fact, a lot of the theoretical frameworks that we're so familiar with, you know, Markov decision processes, goal based planning, you know, standard games research, all of these techniques actually become inapplicable. And you get a more complicated problem because now the interaction with the human becomes part of the problem. Because the human by making choices is giving you more information about the true objective and that information helps you achieve the objective better. And so that really means that you're mostly dealing with game theoretic problems where you've got the machine and the human and they're coupled together, rather than a machine going off by itself with a fixed objective. LW. Which is fascinating on the machine and the human level that we, when you don't have an objective, means you're together coming up with an objective. I mean, there's a lot of philosophy that, you know, you could argue that life doesn't really have meaning. We together agree on what gives it meaning and we kind of culturally create things that give why the heck we are on this earth anyway. We together as a society create that meaning and you have to learn that objective. And one of the biggest, I thought that's where you were going to go for a second, one of the biggest troubles we run into outside of statistics and machine learning and AI and just human civilization is when you look at, I came from, I was born in the Soviet Union and the history of the 20th century, we ran into the most trouble, us humans, when there was a certainty about the objective and you do whatever it takes to achieve that objective, whether you're talking about Germany or communist Russia. You get into trouble with humans. I would say with, you know, corporations, in fact, some people argue that, you know, we don't have to look forward to a time when AI systems take over the world. They already have and they call corporations, right? That corporations happen to be using people as components right now, but they are effectively algorithmic machines and they're optimizing an objective, which is quarterly profit that isn't aligned with overall wellbeing of the human race. And they are destroying the world. They are primarily responsible for our inability to tackle climate change. So I think that's one way of thinking about what's going on with corporations, but I think the point you're making is valid that there are many systems in the real world where we've sort of prematurely fixed on the objective and then decoupled the machine from those that's supposed to be serving. And I think you see this with government, right? Government is supposed to be a machine that serves people, but instead it tends to be taken over by people who have their own objective and use government to optimize that objective regardless of what people want. Do you find appealing the idea of almost arguing machines where you have multiple AI systems with a clear fixed objective. We have in government, the red team and the blue team, they're very fixed on their objectives and they argue and they kind of may disagree, but it kind of seems to make it work somewhat that the duality of it. Okay. Let's go a hundred years back when there was still was going on or at the founding of this country, there was disagreements and that disagreement is where, so it was a balance between certainty and forced humility because the power was distributed. Yeah. I think that the nature of debate and disagreement argument takes as a premise, the idea that you could be wrong, which means that you're not necessarily absolutely convinced that your objective is the correct one. If you were absolutely convinced, there'd be no point in having any discussion or argument because you would never change your mind and there wouldn't be any sort of synthesis or anything like that. I think you can think of argumentation as an implementation of a form of uncertain reasoning. I've been reading recently about utilitarianism and the history of efforts to define in a sort of clear mathematical way, if you like a formula for moral or political decision making. It's really interesting that the parallels between the philosophical discussions going back 200 years and what you see now in discussions about existential risk because it's almost exactly the same. Someone would say, okay, well here's a formula for how we should make decisions. Utilitarianism is roughly each person has a utility function and then we make decisions to maximize the sum of everybody's utility. Then people point out, well, in that case, the best policy is one that leads to the enormously vast population, all of whom are living a life that's barely worth living. This is called the repugnant conclusion. Another version is that we should maximize pleasure and that's what we mean by utility. Then you'll get people effectively saying, well, in that case, we might as well just have everyone hooked up to a heroin drip. They didn't use those words, but that debate was happening in the 19th century as it is now about AI that if we get the formula wrong, we're going to have AI systems working towards an outcome that in retrospect would be exactly wrong. Do you think there's, as beautifully put, so the echoes are there, but do you think, I mean, if you look at Sam Harris, our imagination worries about the AI version of that because of the speed at which the things going wrong in the utilitarian context could happen. Is that a worry for you? Yeah. I think that in most cases, not in all, but if we have a wrong political idea, we see it starting to go wrong and we're not completely stupid and so we say, okay, maybe that was a mistake. Let's try something different. Also, we're very slow and inefficient about implementing these things and so on. So you have to worry when you have corporations or political systems that are extremely efficient. But when we look at AI systems or even just computers in general, they have this different characteristic from ordinary human activity in the past. So let's say you were a surgeon, you had some idea about how to do some operation. Well, and let's say you were wrong, that way of doing the operation would mostly kill the patient. Well, you'd find out pretty quickly, like after three, maybe three or four tries. But that isn't true for pharmaceutical companies because they don't do three or four operations. They manufacture three or four billion pills and they sell them and then they find out maybe six months or a year later that, oh, people are dying of heart attacks or getting cancer from this drug. And so that's why we have the FDA, right? Because of the scalability of pharmaceutical production. And there have been some unbelievably bad episodes in the history of pharmaceuticals and adulteration of products and so on that have killed tens of thousands or paralyzed hundreds of thousands of people. Now with computers, we have that same scalability problem that you can sit there and type for I equals one to five billion do, right? And all of a sudden you're having an impact on a global scale. And yet we have no FDA, right? There's absolutely no controls at all over what a bunch of undergraduates with too much caffeine can do to the world. And we look at what happened with Facebook, well, social media in general and click through optimization. So you have a simple feedback algorithm that's trying to just optimize click through, right? That sounds reasonable, right? Because you don't want to be feeding people ads that they don't care about or not interested in. And you might even think of that process as simply adjusting the feeding of ads or news articles or whatever it might be to match people's preferences, right? Which sounds like a good idea. But in fact, that isn't how the algorithm works, right? You make more money, the algorithm makes more money if it can better predict what people are going to click on, because then it can feed them exactly that, right? So the way to maximize click through is actually to modify the people to make them more predictable. And one way to do that is to feed them information, which will change their behavior and preferences towards extremes that make them predictable. Whatever is the nearest extreme or the nearest predictable point, that's where you're going to end up. And the machines will force you there. And I think there's a reasonable argument to say that this, among other things, is contributing to the destruction of democracy in the world. And where was the oversight of this process? Where were the people saying, okay, you would like to apply this algorithm to 5 billion people on the face of the earth. Can you show me that it's safe? Can you show me that it won't have various kinds of negative effects? No, there was no one asking that question. There was no one placed between the undergrads with too much caffeine and the human race. They just did it. But some way outside the scope of my knowledge, so economists would argue that the, what is it, the invisible hand, so the capitalist system, it was the oversight. So if you're going to corrupt society with whatever decision you make as a company, then that's going to be reflected in people not using your product. That's one model of oversight. We shall see, but in the meantime, but you might even have broken the political system that enables capitalism to function. Well, you've changed it. We shall see. Change is often painful. So my question is absolutely, it's fascinating. You're absolutely right that there was zero oversight on algorithms that can have a profound civilization changing effect. So do you think it's possible? I mean, I haven't, have you seen government? So do you think it's possible to create regulatory bodies oversight over AI algorithms, which are inherently such cutting edge set of ideas and technologies? Yeah, but I think it takes time to figure out what kind of oversight, what kinds of controls. I mean, it took time to design the FDA regime, you know, and some people still don't like it and they want to fix it. And I think there are clear ways that it could be improved. But the whole notion that you have stage one, stage two, stage three, and here are the criteria for what you have to do to pass a stage one trial, right? We haven't even thought about what those would be for algorithms. So, I mean, I think there are things we could do right now with regard to bias, for example, we have a pretty good technical handle on how to detect algorithms that are propagating bias that exists in data sets, how to de bias those algorithms, and even what it's going to cost you to do that. So I think we could start having some standards on that. I think there are things to do with impersonation and falsification that we could work on. Fakes, yeah. A very simple point. So impersonation is a machine acting as if it was a person. I can't see a real justification for why we shouldn't insist that machines self identify as machines. Where is the social benefit in fooling people into thinking that this is really a person when it isn't? I don't mind if it uses a human like voice, that's easy to understand, that's fine, but it should just say, I'm a machine in some form. And how many people are speaking to that? I would think relatively obvious facts. Yeah, I mean, there is actually a law in California that bans impersonation, but only in certain restricted circumstances. So for the purpose of engaging in a fraudulent transaction and for the purpose of modifying someone's voting behavior. So those are the circumstances where machines have to self identify. But I think arguably, it should be in all circumstances. And then when you talk about deep fakes, we're just at the beginning, but already it's possible to make a movie of anybody saying anything in ways that are pretty hard to detect.",following conversation stuart russell professor computer science uc berkeley coauthor book introduce million people amazing world ai call artificial intelligence modern approach honor conversation mit course artificial general intelligence artificial intelligence podcast enjoy subscribe youtube itunes podcast provider choice simply connect twitter lex friedman spell f r conversation stuart russell mention high school create ai program play chess able build program beat chess board game program beat chess actually write program imperial college bus wednesday box card big shove card reader give second cpu time take second read card compile code second cpu time know deep search print queue wait feed card deep search talk move move think get depth alpha beta trick order pruning tree able beat program yeah yeah reasonable chess player youth othello program backgammon program get berkeley work lot meta reasoning mean reason reasoning case game playing program need reason part search tree actually go explore search tree enormous big number atom universe way program succeed way human succeed look small fraction search tree look right fraction play look wrong fraction waste time think thing go happen move go go lose will able figure right decision question machine manage computation decide think meta reasoning question develop method simply machine think thought go improve decision quality able othello standard player game backgammon include dice roll player game uncertainty case come algorithm actually efficient standard alpha beta search chess program time program beat think basic idea alpha alpha zero today way explore tree form meta reasoning select think base useful think insight describe greek symbol select path kind learn go alpha learn evaluate board position look board actually probably superhuman ability instantly tell promising situation amazing thing alpha world champion hand tie fact stop search altogether okay allow thinking ahead consider legal move look result situation evaluate depth search immediate outcome move decide good bad version alpha play professional level human professional sit minute decide alpha second instantly intuit right base ability evaluate position remarkable level intuition actually think situation capability alpha big beat human big able look ahead move future consider possibility move future possibility way atom universe selective look let try intuition decide think combination thing promising convince terrible point spend lot time convince terrible probably go change mind real reason think possibility change mind change mind result well final action real world purpose thinking improve final action real world think guarantee terrible convince terrible go change mind hand suppose choice move figure guarantee draw let look little bit bad look fairly likely go lose uncertainty value possibility turn win worth think promising average good worth think average guarantee draw purpose think chance change mind discover fact well combination good appear uncertainty value uncertainty worth think high upside want think way course beginning especially alphago zero formulation shroud uncertainty swim sea uncertainty benefit mean actually follow process describe uncertain basically try lot different direction yeah early part search tree fairly bushy look lot different possibility fairly quickly degree certainty move mean terrible pretty quickly find right lose half piece half territory okay worth think anymore tree long narrow follow line play move future human being hard time mainly lack short term memory remember sequence move move long imagine board correctly move future course player familiar chess player probably echo kind intuition instinct moment time alphago apply board mean see pattern human being see pattern grandmaster level similarity maybe imagination create vision similarity feel like kind pattern recognition alphago approach similar human being level think truth entirely yeah mean think extent human grandmaster reliably instantly recognize right instantly recognize value position think little bit overrated sacrifice queen example mean beautiful game chess bobby fischer somebody bad sure perfect degree calculation involve calculate possible thing happen instinct right add yeah think happen sense possibility position weird look open line calculation definitely bad intuition position yield win follow right sense chess player follow line mind mentally simulate person go opponent go long move kind force right long know fort force variation opponent choice respond follow respond force situation win know plenty mistake grandmaster game miss simple combination know particularly apparent position thing make human yeah mention othello game matter reasoning improvement research able beat feel meta reasoning capability base learn sit day feel get lot smart know sudden feel like sort press wall aggressive totally unforgiving minor mistake actually understand game well gary kasparov quote match deep blue say suddenly feel new kind intelligence board think scary exciting possibility kasparov context chess purely sort like feeling think definitely exciting feeling know work ai place soon understand computer want smart know start program write sinclair programmable calculator think write step algorithm big program write like little arithmetic calculation think implement newton method square root thing like know think okay space thing intelligent start think ai think thing scary chess program know chess program taking world business extrapolate know thing chess resemble real world right know know rule chess chess board completely visible program course real world real world visible sit speak overcome kind problem need qualitatively different algorithm thing real world know regularly plan ahead timescale involve billion trillion step plan detail know choose phd berkeley year commitment amount trillion motor control step eventually commit include go stair open door drink water yeah mean finger movement type character paper thesis commit advance specific motor control step reason timescale eventually reduce trillion motor control action reason know alphago deep blue represent kind threat humanity step right progress ai occur essentially remove assumption problem easy like assumption complete observability situation right remove assumption need complicated kind compute design need need actually keep track thing try estimate go inevitable uncertainty complicated problem know remove assumption start algorithm cope long timescale cope uncertainty cope partial observability step sort magnifie thousand range thing ai system way start ai want psychiatrist long time want understand mind high school course program show university illinois ai lab say okay time book ai modern approach think edition time learn remember lay land incredible solve chess solve mean pretty certain way think system reason possible solve solve think say unlikely kind algorithm chess scale work time think order solve similar way human manage complexity break kind sub game human think board think different part board sort weakly connect think okay board thing board thing try sort couple analysis deal interaction maybe revise view thing go get maybe seven part board actually resemble real world chess real world work home life sport different kind activity shopping connect weakly connect type paper simultaneously decide order go milk butter affect typing need realize okay well finish shop close food home weak connection way chess work tie single stream thought thought solve progress stuff useful real world way alphago little bit disappointing right program design alphago actually different deep blue arthur samuel checker playing program fact thing alphago work amazing ability evaluate position meta reasoning capability allow explore path tree deeply abandon path quickly include camera voice come high resolution yeah say replace pretty want say simple thing say replace pretty want say change lip facial expression fit actually way real legal protection think commercial area yeah brand rule political sphere think moment go damaging let try argument try look history dark essence regulation oversight exactly right thing human being naturally wait wrong talk nuclear weapon talk nuclear weapon dangerous somebody actually like united states drop bomb chernobyl melting think wait thing go wrong way obviously damaging society existential risk obviously damaging faith hope think look history example give nuclear weapon nuclear power interesting nuclear weapon know early year century atom contain huge energy e equal mc square know mass difference different atom component know able incredibly powerful explosive hg wells write science fiction book think frederick soddy guy discover isotope nobel prize winner give speech say pound new explosive equivalent ton dynamite turn right world war imagine bad world war kind explosive physics establishment simply refuse believe thing include people make nuclear physic mean eventually one talk fermi development theoretical people sort primitive kind particle acceleration experiment level single particle collection particle think actually bomb like know energy figure understand well possible physics establishment view think want true view true provide way super weapon famous speech give rutherford sort leader nuclear physic september say talk possibility obtain energy transformation atom talk complete moonshine morning leo szilard read speech invent nuclear chain reaction soon invent soon idea chain reaction neutron neutron repel nucleus enter nucleus continue reaction soon idea instantly realize world deep doo doo right hitler recently come power germany szilard london eventually refugee come process have idea chain reaction figure basically bomb reactor patent reactor situation great power conflict situation happen keep secret beginning world war ii people work include germans actually create neutron source specific fission reaction produce neutron right energy continue reaction demonstrate germany think remember correctly nuclear weapon patent french actually go world war ii get go british probably advanced capability area safety reason resource move program britain manhattan project reason kind oversight nuclear weapon nuclear technology basically arm race war lr mention echo way describe story mean clearly echo think ai researcher folk close metal concerned ai think want think think echo nuclear situation current ai situation bf think kind motivated cognition term psychology mean believe like true true unsettling think work end human race obviously instantly deny come reason true collect long list reason extremely intelligent competent ai scientist come worry example calculator superhuman arithmetic take world worry okay year old know figure unreasonable weak argument theoretically possible superhuman ai destroy world theoretically possible black hole materialize right earth destroy humanity mean yes theoretically possible quantum theoretically extremely unlikely materialize right completely bogus analogy know physics community earth work materialize black hole near earth orbit right ask good idea go safe know succeed right thing right ai community sort refuse ask succeed initially think hard know alan turing ask say toast right lucky able switch power probably toast aspect exactly sure future hold clear exactly technically worry sort thing wrong feel like maybe correct wrong paralyze worry logically inevitable think logically inevitable know look like yeah think reasonable point know certainly term existential risk different know asteroid collide earth right possible know happen past probably happen know right detect asteroid go hit earth year time certainly clear get big rock probably meeting big rock ai right ai mean people think go happen year know rod brooks think go happen maybe andrew ng think happen know lot people work day day know rock face think go happen think median estimate ai researcher year maybe know think asia think go fast little bit conservative think probably long think know happen nuclear weapon happen overnight breakthrough need breakthrough know order half dozen mean rough scale sort half dozen breakthrough nature happen reach superhuman ai know ai research community vast massive investment government corporation ton smart people know look rate progress different area ai thing move pretty fast oh go thousand year basis know know example stanford year ai project right suppose sort know establishment view recent report actually say probably possible oh wow right want perfect example people denial know history ai say philosopher say possible idea talk course possible right argument happen right people worried maybe ai bad want think say okay course possible know imagine know leader cancer biology community get say know course cure cancer possible complete outrage dismay know find strange phenomenon okay accept possible accept probably go happen point make know wrong valid question answer question stuck gorilla problem know problem gorilla face right intelligent million year ago deep doo doo lose control fail solve control problem control human lose want situation gorilla problem formulation lot right okay try stop know human case ai think hard actually propose feasible course action think know properly control ai incredibly beneficial consensus major failure mode loss control create ai system pursue incorrect objective ai system believe know objective incentive listen anymore speak right carry strategy compute optimal solution know process need acquire resource increase possibility success prevent failure mode defend interference collection problem think address problem roughly speak know misuse right solve control problem perfectly safe controllable ai system know evil go use right want world unsafe ai system control problem sort know partly policing problem partly sort cultural problem profession teach people kind ai system safe talk autonomous weapon system pretty everybody agree way horribly wrong great slaughterbot movie kind illustrate beautifully want talk topic have talk want mention major failure mode overuse misuse overuse ai overly dependent wall e problem see wall e movie right human spaceship machine look watch tv drink big gulp sort obese stupid sort totally lose notion human autonomy know effect right happen like slow boiling frog right gradually turn management civilization machine know process continue know sort gradually switch sort master technology guest right guest cruise ship know fine week rest eternity know irreversible right lose incentive example know learn engineer doctor sanitation operative infinitely way maintain propagate civilization know incentive will hard recover course technology failure mode result probably technology general detach bit difference term knowledge run civilization know alternative people head right software google mean software general computer general know knowledge know sanitation system work know ai understand good put google mean knowledge paper paper run civilization run go paper people head right propagate civilization human mind spend trillion person year literally write work right billion people live spend year learn stuff civilization go trillion person year effort beautiful way describe civilization know danger throw away problem ai solve technical problem know job right ai system know human race long run want passenger cruise ship human race want autonomy human preference ai system go stuff get right go carry everest autonomous helicopter climb want benefit afraid short sighted lazy go override ai system amazing short story recommend talk call machine stops write forster know write novel british empire sort thing costume drama bbc write science fiction story amazing vision future basically ipads video conferencing moocs computer induce obesity mean literally people spend time give online course listen online course talk idea real world lot face face contact online know thing worry describe story human race dependent machine lose knowledge thing run vulnerable collapse pretty unbelievably amazing story write imagine people represent artificial intelligence stuart russell okay kind fault right bring person stuart russell like ai person worried worried feel burden know feel talk people like talk people outside computer science think stuart russell worried ai safety worry feel burden mean practical sense yeah know dozen invitation day talk interview write press article practical sense see people concerned interested worried wrong good scientist course worry time mean way work know like argument head right idea think okay wrong idea know search literature think refute know right read lot philosophy know form debate utilitarianism kind moral moral formula shall people think issue know thing see lot debate specific idea importance uncertainty objective way think machine beneficial human idea provably beneficial machine base explicit uncertainty objective know know gut feeling core go elaborate lot different direction lot beneficial yeah mean right afford know hand wavy beneficial know hand wavy stuff loophole thing super intelligent machine find loophole know like know tax evader write tax law properly people find loophole end pay tax think way get definition right know long process know define mathematical framework framework prove mathematical theorem yes know theoretical entity provably beneficial theoretical entity framework match real world crucial way long process think iterate question yep second answer favorite sci fi movie ai interstellar favorite robot oh beat space yeah yeah yeah tars robot robot interstellar way robot behave uh ex machina way make think uh nervous kind way go stuart thank talk today pleasure word meta reasoning technically correct inspire wrong degree power alphago example word reasoning powerful word let ask sort symbolic ai world like ai lot excellent interesting idea unfortunately meet winter think reemerge yeah simple ai winter winter actually name late come mid concert attempt push ai real world call expert system technology technology ready primetime try case form uncertain reasoning judgment combination evidence diagnosis kind thing simply invalid try apply invalid reasoning method real problem fudge small version problem start large thing fall apart company find stuff work spend ton money consultant try work practical reason like ask company buy incredibly expensive lisp machine workstation literally money like workstation current price line see profit yeah case think success doubt people overinveste major company start ai department like worry bit similar disappointment current technology invalid limit scope duel scope problem expert system learn hype cycle prevent winter example yeah give talk day warning warning slide datum new oil datum new snake oil good line kind visible failure major application area think self drive car flagship think look history self driving car freeway drive change lane overtake year kind look like today right know prototype freeway change lane overtake think thing particularly perception work lot autonomous vehicle early mid berkeley big demonstration congressman self drive car zoom freeway problem clearly perception time problem perception yeah simulation perfect perception actually drive safely long time car misbehave simultaneously work machine vision detect car track pedestrian car pedestrian reliability detection track high level particularly bad weather condition nighttime rainfall good demos good cover general operation yeah thing driving know suppose taxi driver know drive day hour day year right million second driving know second fatal mistake talk nine reliability right vision system detect vehicle right sort know bit nine reliability seven order magnitude people understand think oh successful demo pretty seven order magnitude difficulty follow white line problem right follow white line way country weird stuff happen edge case yeah edge case driver weird thing know talk google right actually classical architecture know machine vision detect car pedestrian white line road sign basically feed logical database classical rule base expert system tell okay middle lane bicyclist right lane signal right find day situation rule cover know come traffic circle little girl ride bicycle wrong way traffic circle okay rule oh god okay stop know come add rule find converge think right deal unexpected situation mean previously encounter sort reasoning require figure solution situation match previous situation term kind reasoning know chess program happen time right constantly come situation see reason think okay possible thing outcome desirable outcome pick right know say okay go automate vehicle go look ahead capability look ahead driving difficult chess human predictable chess piece opponent chess somewhat unpredictable example chess know opponent intention try beat right driving know guy try turn left forget turn turn signal drunk change channel radio get try figure mental state intent driver forecast possible evolution trajectory get figure okay trajectory go safest interact driver go react trajectory know get classic merging freeway problem kind race vehicle freeway go pull ahead go let pull sort uncertainty go kind thing mean need decision make architecture different rule base system kind end end neural network system alphago pretty good look ahead way way way way well think go true drive driving system pretty good look ahead good see multiple death cause poorly design machine learning algorithm understand yeah level think perception mistake algorithm perception shallow planning look ahead like say thing come interesting try deploy system real world think artificial intelligence system thing respond world realize agent respond order drive successfully try obstacle avoidance right pretend invisible right invisible car right work way mean assert scared tension game study lot work pedestrian approach pedestrian purely obstacle avoidance look ahead model intent go go advantage go respect tension fear uncertainty create kind resoluteness display certain resoluteness tentative yeah solution pretty complicated right game theoretic analysis berkeley work lot kind interaction machine human exciting colleague ankur dragan actually formulate problem game theoretically let system figure solution interesting unexpected thing like stop sign go car actually little right indicate car invent entirely language communication stop sign figure interesting let step second beautiful philosophical notion pamela mccordick write ai begin ancient wish forge god think history civilization think inherent desire create let god create superintelligence inherent gene natural arc human civilization create thing great great power echo create god pamela say maybe mean individual certainly history individual think possibility hopefully philosophical look arc go talk ai safety talk great great intelligence create othello program feel excitement excitement excitement tinkerer create cool like clock magic like child bear yeah mean certainly understand viewpoint look lighthill report lot controversy uk ai real money government invest long story government commission report lighthill physicist write damning report ai think point say frustrated man unable child like create create life kind replacement think pretty unfair kind magic build build build understanding principle learning decision making principle actually turn intelligent behavior specific situation incredible thing naturally go think okay end magical optimistic view end view optimism view utopia probably different everybody talk concern thing wrong talk max tegmark lot interesting way think ai safety seminal people think problem sort weed actually solve specific ai problem think big picture go talk element let talk maybe control problem idea lose ability control behavior ai system come think manage genius realize smart problem alan turing write give lecture lecture radio basically say machine think method start quickly outstrip humanity lucky able turn power strategic moment specie humble actually wrong sufficiently intelligent machine go let switch actually competition think likely go happen think mean quick tangent shut super intelligent machine specie humble think mean realize inferior right survive skin tooth happen switch time lose control earth worried think stuff super intelligent ai worried super powerful ai align value paperclip scenario kind main problem work control problem problem machine pursue objective align human objective way think ai beginning build machine optimize objective optimize right think king midas problem right king midas objective touch turn gold god like machine say okay power course father drink family turn gold die misery starvation warning failure mode pretty culture history story line genie give wish wish know undo wish mess arthur samuel write checker playing program learn play checker considerably well arthur samuel play actually reach pretty decent standard norbert wiener major mathematician century sort father modern automation control system see basically extrapolate turing say okay lose control specifically certain purpose machine purpose desire problem mean difficult encode value paper difficult say impossible theoretically possible practice extremely unlikely specify correctly advance range concern humanity talk cultural transmission value think human human transmission value happen right learn yeah mean grow learn value matter thing reasonable pursue reasonable pursue think machine learn kind way yeah think need away idea build optimising machine objective possible wrong objective know possible happen lot time right mean machine objective give gospel truth take objective gospel truth believe action take pursuit objective correct thing jump say go destroy world machine know true objective pursue tough luck restrict ai right think century technology right statistic minimise loss function loss function exogenously specify control theory minimise cost function operation research maximise reward function discipline conceive problem wrong problem specify certainty correct objective right need uncertainty need machine uncertain suppose maximise favourite idea hear pick favourite sound beautiful need teach machine humility beautiful way love humble know know suppose objective mean exist able able explicate know want future exactly machine machine uncertain go deferential machine learn bit true objective think reasonable pursuit objective turn learn go defer want want point think absolutely central solve control problem different kind ai away idea objective know fact lot theoretical framework familiar know markov decision process goal base planning know standard game research technique actually inapplicable complicated problem interaction human problem human make choice give information true objective information help achieve objective well mean deal game theoretic problem get machine human couple machine go fix objective lw fascinating machine human level objective mean come objective mean lot philosophy know argue life meaning agree give meaning kind culturally create thing heck earth society create meaning learn objective big think go second big trouble run outside statistic machine learning ai human civilization look come bear soviet union history century run trouble human certainty objective take achieve objective talk germany communist russia trouble human know corporation fact people argue know look forward time ai system world corporation right corporation happen people component right effectively algorithmic machine optimize objective quarterly profit align overall wellbeing human race destroy world primarily responsible inability tackle climate change think way think go corporation think point make valid system real world sort prematurely fix objective decouple machine suppose serve think government right government suppose machine serve people instead tend take people objective use government optimize objective regardless people want find appeal idea argue machine multiple ai system clear fix objective government red team blue team fixed objective argue kind disagree kind work somewhat duality okay let year go founding country disagreement disagreement balance certainty force humility power distribute yeah think nature debate disagreement argument take premise idea wrong mean necessarily absolutely convinced objective correct absolutely convinced point have discussion argument change mind sort synthesis like think think argumentation implementation form uncertain reasoning read recently utilitarianism history effort define sort clear mathematical way like formula moral political decision making interesting parallel philosophical discussion go year discussion existential risk exactly okay formula decision utilitarianism roughly person utility function decision maximize sum everybody utility people point case good policy lead enormously vast population live life barely worth live call repugnant conclusion version maximize pleasure mean utility people effectively say case hook heroin drip use word debate happen century ai formula wrong go ai system work outcome retrospect exactly wrong think beautifully echo think mean look sam harris imagination worry ai version speed thing go wrong utilitarian context happen worry yeah think case wrong political idea start wrong completely stupid okay maybe mistake let try different slow inefficient implement thing worry corporation political system extremely efficient look ai system computer general different characteristic ordinary human activity past let surgeon idea operation let wrong way operation kill patient find pretty quickly like maybe try true pharmaceutical company operation manufacture billion pill sell find maybe month year later oh people die heart attack get cancer drug fda right scalability pharmaceutical production unbelievably bad episode history pharmaceutical adulteration product kill ten thousand paralyze hundred thousand people computer scalability problem sit type equal billion right sudden have impact global scale fda right absolutely control bunch undergraduate caffeine world look happen facebook social medium general click optimization simple feedback algorithm try optimize click right sound reasonable right want feed people ad care interested think process simply adjust feeding ad news article match people preference right sound like good idea fact algorithm work right money algorithm make money well predict people go click feed exactly right way maximize click actually modify people predictable way feed information change behavior preference extreme predictable near extreme near predictable point go end machine force think reasonable argument thing contribute destruction democracy world oversight process people say okay like apply algorithm billion people face earth safe will kind negative effect ask question place undergrad caffeine human race way outside scope knowledge economist argue invisible hand capitalist system oversight go corrupt society decision company go reflect people product model oversight shall meantime break political system enable capitalism function change shall change painful question absolutely fascinating absolutely right zero oversight algorithm profound civilization change effect think possible mean see government think possible create regulatory body oversight ai algorithm inherently cut edge set idea technology yeah think take time figure kind oversight kind control mean take time design fda regime know people like want fix think clear way improve notion stage stage stage criterion pass stage trial right think algorithm mean think thing right regard bias example pretty good technical handle detect algorithm propagate bias exist data set de bias algorithm go cost think start have standard think thing impersonation falsification work fake yeah simple point impersonation machine act person real justification insist machine self identify machine social benefit fool people think person mind use human like voice easy understand fine machine form people speak think relatively obvious fact yeah mean actually law california ban impersonation certain restricted circumstance purpose engage fraudulent transaction purpose modify voting behavior circumstance machine self identify think arguably circumstance talk deep fake beginning possible movie anybody say way pretty hard detect,"['Stuart Russell', 'Alpha Go', 'Bobby Fischer', 'Gary Kasparov', 'Deep Blue', 'Arthur Samuel', 'HG Wells', 'Frederick Soddy', 'Leo Szilard', 'Alan Turing', 'Rod Brooks', 'Andrew Ng', 'E.M. Forster', 'Ankur Dragan', 'Pamela McCordick', 'Max Tegmark', 'King Midas', 'Norbert Wiener', 'Sam Harris']","['UC Berkeley', 'OpenAI', 'DeepMind']","['Reinforcement Learning Algorithms', 'Deep Neural Networks', 'Robotics Control Systems']","['AI Safety and Ethics', 'Artificial General Intelligence (AGI)', 'Future of Technology', 'Philosophy of Mind and AI', 'Human-AI Interaction']"
10,Pieter Abbeel,Deep Reinforcement Learning,"The following is a conversation with Peter Abbeel. He's a professor at UC Berkeley and the director of the Berkeley Robotics Learning Lab. He's one of the top researchers in the world working on how we make robots understand and interact with the world around them, especially using imitation and deep reinforcement learning. This conversation is part of the MIT course on Artificial General Intelligence and the Artificial Intelligence podcast. If you enjoy it, please subscribe on YouTube, iTunes, or your podcast provider of choice, or simply connect with me on Twitter at Lex Friedman, spelled F R I D. And now, here's my conversation with Peter Abbeel. You've mentioned that if there was one person you could meet, it would be Roger Federer. So let me ask, when do you think we'll have a robot that fully autonomously can beat Roger Federer at tennis? Roger Federer level player at tennis? Well, first, if you can make it happen for me to meet Roger, let me know. In terms of getting a robot to beat him at tennis, it's kind of an interesting question because for a lot of the challenges we think about in AI, the software is really the missing piece, but for something like this, the hardware is nowhere near either. To really have a robot that can physically run around, the Boston Dynamics robots are starting to get there, but still not really human level ability to run around and then swing a racket. So you think that's a hardware problem? I don't think it's a hardware problem only. I think it's a hardware and a software problem. I think it's both. And I think they'll have independent progress. So I'd say the hardware maybe in 10, 15 years. On clay, not grass. I mean, grass is probably harder. With the sliding? Yeah. With the clay, I'm not sure what's harder, grass or clay. The clay involves sliding, which might be harder to master actually, yeah. But you're not limited to a bipedal. I mean, I'm sure there's no... Well, if we can build a machine, it's a whole different question, of course. If you can say, okay, this robot can be on wheels, it can move around on wheels and can be designed differently, then I think that can be done sooner probably than a full humanoid type of setup. What do you think of swing a racket? So you've worked at basic manipulation. How hard do you think is the task of swinging a racket would be able to hit a nice backhand or a forehand? Let's say we just set up stationary, a nice robot arm, let's say, a standard industrial arm, and it can watch the ball come and then swing the racket. It's a good question. I'm not sure it would be super hard to do. I mean, I'm sure it would require a lot, if we do it with reinforcement learning, it would require a lot of trial and error. It's not gonna swing it right the first time around, but yeah, I don't see why I couldn't swing it the right way. I think it's learnable. I think if you set up a ball machine, let's say on one side, and then a robot with a tennis racket on the other side, I think it's learnable and maybe a little bit of pre training and simulation. Yeah, I think that's feasible. I think the swing the racket is feasible. It'd be very interesting to see how much precision it can get. Cause I mean, that's where, I mean, some of the human players can hit it on the lines, which is very high precision. With spin, the spin is an interesting, whether RL can learn to put a spin on the ball. Well, you got me interested. Maybe someday we'll set this up. Sure, you got me intrigued. Your answer is basically, okay, for this problem, it sounds fascinating, but for the general problem of a tennis player, we might be a little bit farther away. What's the most impressive thing you've seen a robot do in the physical world? So physically for me, it's the Boston Dynamics videos. Always just bring home and just super impressed. Recently, the robot running up the stairs, doing the parkour type thing. I mean, yes, we don't know what's underneath. They don't really write a lot of detail, but even if it's hard coded underneath, which it might or might not be just the physical abilities of doing that parkour, that's a very impressive. So have you met Spot Mini or any of those robots in person? Met Spot Mini last year in April at the Mars event that Jeff Bezos organizes. They brought it out there and it was nicely following around Jeff. When Jeff left the room, they had it follow him along, which is pretty impressive. So I think there's some confidence to know that there's no learning going on in those robots. The psychology of it, so while knowing that, while knowing there's not, if there's any learning going on, it's very limited. I met Spot Mini earlier this year and knowing everything that's going on, having one on one interaction, so I got to spend some time alone and there's immediately a deep connection on the psychological level. Even though you know the fundamentals, how it works, there's something magical. So do you think about the psychology of interacting with robots in the physical world? Even you just showed me the PR2, the robot, and there was a little bit something like a face, had a little bit something like a face. There's something that immediately draws you to it. Do you think about that aspect of the robotics problem? Well, it's very hard with Brad here. We'll give him a name, Berkeley Robot for the Elimination of Tedious Tasks. It's very hard to not think of the robot as a person and it seems like everybody calls him a he for whatever reason, but that also makes it more a person than if it was a it, and it seems pretty natural to think of it that way. This past weekend really struck me. I've seen Pepper many times on videos, but then I was at an event organized by, this was by Fidelity, and they had scripted Pepper to help moderate some sessions, and they had scripted Pepper to have the personality of a child a little bit, and it was very hard to not think of it as its own person in some sense because it would just jump in the conversation, making it very interactive. Moderate would be saying, Pepper would just jump in, hold on, how about me? Can I participate in this too? And you're just like, okay, this is like a person, and that was 100% scripted, and even then it was hard not to have that sense of somehow there is something there. So as we have robots interact in this physical world, is that a signal that could be used in reinforcement learning? You've worked a little bit in this direction, but do you think that psychology can be somehow pulled in? Yes, that's a question I would say a lot of people ask, and I think part of why they ask it is they're thinking about how unique are we really still as people? Like after they see some results, they see a computer play Go, they see a computer do this, that, they're like, okay, but can it really have emotion? Can it really interact with us in that way? And then once you're around robots, you already start feeling it, and I think that kind of maybe mythologically, the way that I think of it is if you run something like reinforcement learning, it's about optimizing some objective, and there's no reason that the objective couldn't be tied into how much does a person like interacting with this system, and why could not the reinforcement learning system optimize for the robot being fun to be around? And why wouldn't it then naturally become more and more interactive and more and more maybe like a person or like a pet? I don't know what it would exactly be, but more and more have those features and acquire them automatically. As long as you can formalize an objective of what it means to like something, what, how you exhibit, what's the ground truth? How do you get the reward from human? Because you have to somehow collect that information within you, human. But you're saying if you can formulate as an objective, it can be learned. There's no reason it couldn't emerge through learning, and maybe one way to formulate as an objective, you wouldn't have to necessarily score it explicitly, so standard rewards are numbers, and numbers are hard to come by. This is a 1.5 or a 1.7 on some scale. It's very hard to do for a person, but much easier is for a person to say, okay, what you did the last five minutes was much nicer than what you did the previous five minutes, and that now gives a comparison. And in fact, there have been some results on that. For example, Paul Christiano and collaborators at OpenAI had the Hopper, Mojoko Hopper, a one legged robot, going through backflips purely from feedback. I like this better than that. That's kind of equally good, and after a bunch of interactions, it figured out what it was the person was asking for, namely a backflip. And so I think the same thing. Oh, it wasn't trying to do a backflip. It was just getting a comparison score from the person based on? Person having in mind, in their own mind, I wanted to do a backflip, but the robot didn't know what it was supposed to be doing. It just knew that sometimes the person said, this is better, this is worse, and then the robot figured out what the person was actually after was a backflip. And I'd imagine the same would be true for things like more interactive robots, that the robot would figure out over time, oh, this kind of thing apparently is appreciated more than this other kind of thing. So when I first picked up Sutton's, Richard Sutton's reinforcement learning book, before sort of this deep learning, before the reemergence of neural networks as a powerful mechanism for machine learning, RL seemed to me like magic. It was beautiful. So that seemed like what intelligence is, RL reinforcement learning. So how do you think we can possibly learn anything about the world when the reward for the actions is delayed, is so sparse? Like where is, why do you think RL works? Why do you think you can learn anything under such sparse rewards, whether it's regular reinforcement learning or deep reinforcement learning? What's your intuition? The counterpart of that is why is RL, why does it need so many samples, so many experiences to learn from? Because really what's happening is when you have a sparse reward, you do something maybe for like, I don't know, you take 100 actions and then you get a reward. And maybe you get like a score of three. And I'm like okay, three, not sure what that means. You go again and now you get two. And now you know that that sequence of 100 actions that you did the second time around somehow was worse than the sequence of 100 actions you did the first time around. But that's tough to now know which one of those were better or worse. Some might have been good and bad in either one. And so that's why it needs so many experiences. But once you have enough experiences, effectively RL is teasing that apart. It's trying to say okay, what is consistently there when you get a higher reward and what's consistently there when you get a lower reward? And then kind of the magic of sometimes the policy gradient update is to say now let's update the neural network to make the actions that were kind of present when things are good more likely and make the actions that are present when things are not as good less likely. So that is the counterpoint, but it seems like you would need to run it a lot more than you do. Even though right now people could say that RL is very inefficient, but it seems to be way more efficient than one would imagine on paper. That the simple updates to the policy, the policy gradient, that somehow you can learn, exactly you just said, what are the common actions that seem to produce some good results? That that somehow can learn anything. It seems counterintuitive at least. Is there some intuition behind it? Yeah, so I think there's a few ways to think about this. The way I tend to think about it mostly originally, so when we started working on deep reinforcement learning here at Berkeley, which was maybe 2011, 12, 13, around that time, John Schulman was a PhD student initially kind of driving it forward here. And the way we thought about it at the time was if you think about rectified linear units or kind of rectifier type neural networks, what do you get? You get something that's piecewise linear feedback control. And if you look at the literature, linear feedback control is extremely successful, can solve many, many problems surprisingly well. I remember, for example, when we did helicopter flight, if you're in a stationary flight regime, not a non stationary, but a stationary flight regime like hover, you can use linear feedback control to stabilize a helicopter, very complex dynamical system, but the controller is relatively simple. And so I think that's a big part of it is that if you do feedback control, even though the system you control can be very, very complex, often relatively simple control architectures can already do a lot. But then also just linear is not good enough. And so one way you can think of these neural networks is that sometimes they tile the space, which people were already trying to do more by hand or with finite state machines, say this linear controller here, this linear controller here. Neural network learns to tile the space and say linear controller here, another linear controller here, but it's more subtle than that. And so it's benefiting from this linear control aspect, it's benefiting from the tiling, but it's somehow tiling it one dimension at a time. Because if let's say you have a two layer network, if in that hidden layer, you make a transition from active to inactive or the other way around, that is essentially one axis, but not axis aligned, but one direction that you change. And so you have this kind of very gradual tiling of the space where you have a lot of sharing between the linear controllers that tile the space. And that was always my intuition as to why to expect that this might work pretty well. It's essentially leveraging the fact that linear feedback control is so good, but of course not enough. And this is a gradual tiling of the space with linear feedback controls that share a lot of expertise across them. So that's really nice intuition, but do you think that scales to the more and more general problems of when you start going up the number of dimensions when you start going down in terms of how often you get a clean reward signal? Does that intuition carry forward to those crazier, weirder worlds that we think of as the real world? So I think where things get really tricky in the real world compared to the things we've looked at so far with great success in reinforcement learning is the time scales, which takes us to an extreme. So when you think about the real world, I mean, I don't know, maybe some student decided to do a PhD here, right? Okay, that's a decision. That's a very high level decision. But if you think about their lives, I mean, any person's life, it's a sequence of muscle fiber contractions and relaxations, and that's how you interact with the world. And that's a very high frequency control thing, but it's ultimately what you do and how you affect the world, until I guess we have brain readings and you can maybe do it slightly differently. But typically that's how you affect the world. And the decision of doing a PhD is so abstract relative to what you're actually doing in the world. And I think that's where credit assignment becomes just completely beyond what any current RL algorithm can do. And we need hierarchical reasoning at a level that is just not available at all yet. Where do you think we can pick up hierarchical reasoning? By which mechanisms? Yeah, so maybe let me highlight what I think the limitations are of what already was done 20, 30 years ago. In fact, you'll find reasoning systems that reason over relatively long horizons, but the problem is that they were not grounded in the real world. So people would have to hand design some kind of logical, dynamical descriptions of the world and that didn't tie into perception. And so it didn't tie into real objects and so forth. And so that was a big gap. Now with deep learning, we start having the ability to really see with sensors, process that and understand what's in the world. And so it's a good time to try to bring these things together. I see a few ways of getting there. One way to get there would be to say deep learning can get bolted on somehow to some of these more traditional approaches. Now bolted on would probably mean you need to do some kind of end to end training where you say my deep learning processing somehow leads to a representation that in term uses some kind of traditional underlying dynamical systems that can be used for planning. And that's, for example, the direction Aviv Tamar and Thanard Kuretach here have been pushing with causal info again and of course other people too. That's one way. Can we somehow force it into the form factor that is amenable to reasoning? Another direction we've been thinking about for a long time and didn't make any progress on was more information theoretic approaches. So the idea there was that what it means to take high level action is to take and choose a latent variable now that tells you a lot about what's gonna be the case in the future. Because that's what it means to take a high level action. I say okay, I decide I'm gonna navigate to the gas station because I need to get gas for my car. Well, that'll now take five minutes to get there. But the fact that I get there, I could already tell that from the high level action I took much earlier. That we had a very hard time getting success with. Not saying it's a dead end necessarily, but we had a lot of trouble getting that to work. And then we started revisiting the notion of what are we really trying to achieve? What we're trying to achieve is not necessarily hierarchy per se, but you could think about what does hierarchy give us? What we hope it would give us is better credit assignment. What is better credit assignment? It's giving us, it gives us faster learning, right? And so faster learning is ultimately maybe what we're after. And so that's where we ended up with the RL squared paper on learning to reinforcement learn, which at a time Rocky Dwan led. And that's exactly the meta learning approach where you say, okay, we don't know how to design hierarchy. We know what we want to get from it. Let's just enter and optimize for what we want to get from it and see if it might emerge. And we saw things emerge. The maze navigation had consistent motion down hallways, which is what you want. A hierarchical control should say, I want to go down this hallway. And then when there is an option to take a turn, I can decide whether to take a turn or not and repeat. Even had the notion of where have you been before or not to not revisit places you've been before. It still didn't scale yet to the real world kind of scenarios I think you had in mind, but it was some sign of life that maybe you can meta learn these hierarchical concepts. I mean, it seems like through these meta learning concepts, get at the, what I think is one of the hardest and most important problems of AI, which is transfer learning. So it's generalization. How far along this journey towards building general systems are we? Being able to do transfer learning well. So there's some signs that you can generalize a little bit, but do you think we're on the right path or it's totally different breakthroughs are needed to be able to transfer knowledge between different learned models? Yeah, I'm pretty torn on this in that I think there are some very impressive. Well, there's just some very impressive results already. I mean, I would say when, even with the initial kind of big breakthrough in 2012 with AlexNet, the initial thing is okay, great. This does better on ImageNet, hence image recognition. But then immediately thereafter, there was of course the notion that, wow, what was learned on ImageNet and you now wanna solve a new task, you can fine tune AlexNet for new tasks. And that was often found to be the even bigger deal that you learn something that was reusable, which was not often the case before. Usually machine learning, you learn something for one scenario and that was it. And that's really exciting. I mean, that's a huge application. That's probably the biggest success of transfer learning today in terms of scope and impact. That was a huge breakthrough. And then recently, I feel like similar kind of, by scaling things up, it seems like this has been expanded upon. Like people training even bigger networks, they might transfer even better. If you looked at, for example, some of the OpenAI results on language models and some of the recent Google results on language models, they're learned for just prediction and then they get reused for other tasks. And so I think there is something there where somehow if you train a big enough model on enough things, it seems to transfer some deep mind results that I thought were very impressive, the Unreal results, where it was learned to navigate mazes in ways where it wasn't just doing reinforcement learning, but it had other objectives it was optimizing for. So I think there's a lot of interesting results already. I think maybe where it's hard to wrap my head around this, to which extent or when do we call something generalization? Or the levels of generalization in the real world, or the levels of generalization involved in these different tasks, right? You draw this, by the way, just to frame things. I've heard you say somewhere, it's the difference between learning to master versus learning to generalize, that it's a nice line to think about. And I guess you're saying that it's a gray area of what learning to master and learning to generalize, where one starts. I think I might have heard this. I might have heard it somewhere else. And I think it might've been one of your interviews, maybe the one with Yoshua Benjamin, I'm not 100% sure. But I liked the example, I'm not sure who it was, but the example was essentially, if you use current deep learning techniques, what we're doing to predict, let's say, the relative motion of our planets, it would do pretty well. But then now if a massive new mass enters our solar system, it would probably not predict what will happen, right? And that's a different kind of generalization. That's a generalization that relies on the ultimate simplest, simplest explanation that we have available today to explain the motion of planets, whereas just pattern recognition could predict our current solar system motion pretty well, no problem. And so I think that's an example of a kind of generalization that is a little different from what we've achieved so far. And it's not clear if just regularizing more and forcing it to come up with a simpler, simpler, simpler explanation and say, look, this is not simple. But that's what physics researchers do, right? They say, can I make this even simpler? How simple can I get this? What's the simplest equation that can explain everything? The master equation for the entire dynamics of the universe, we haven't really pushed that direction as hard in deep learning, I would say. Not sure if it should be pushed, but it seems a kind of generalization you get from that that you don't get in our current methods so far. So I just talked to Vladimir Vapnik, for example, who's a statistician of statistical learning, and he kind of dreams of creating the E equals MC squared for learning, right? The general theory of learning. Do you think that's a fruitless pursuit in the near term, within the next several decades? I think that's a really interesting pursuit in the following sense, in that there is a lot of evidence that the brain is pretty modular. And so I wouldn't maybe think of it as the theory, maybe the underlying theory, but more kind of the principle where there have been findings where people who are blind will use the part of the brain usually used for vision for other functions. And even after some kind of, if people get rewired in some way, they might be able to reuse parts of their brain for other functions. And so what that suggests is some kind of modularity. And I think it is a pretty natural thing to strive for to see, can we find that modularity? Can we find this thing? Of course, every part of the brain is not exactly the same. Not everything can be rewired arbitrarily. But if you think of things like the neocortex, which is a pretty big part of the brain, that seems fairly modular from what the findings so far. Can you design something equally modular? And if you can just grow it, it becomes more capable probably. I think that would be the kind of interesting underlying principle to shoot for that is not unrealistic. Do you think you prefer math or empirical trial and error for the discovery of the essence of what it means to do something intelligent? So reinforcement learning embodies both groups, right? To prove that something converges, prove the bounds. And then at the same time, a lot of those successes are, well, let's try this and see if it works. So which do you gravitate towards? How do you think of those two parts of your brain? Maybe I would prefer we could make the progress with mathematics. And the reason maybe I would prefer that is because often if you have something you can mathematically formalize, you can leapfrog a lot of experimentation. And experimentation takes a long time to get through. And a lot of trial and error, kind of reinforcement learning, your research process, but you need to do a lot of trial and error before you get to a success. So if you can leapfrog that, to my mind, that's what the math is about. And hopefully once you do a bunch of experiments, you start seeing a pattern. You can do some derivations that leapfrog some experiments. But I agree with you. I mean, in practice, a lot of the progress has been such that we have not been able to find the math that allows you to leapfrog ahead. And we are kind of making gradual progress one step at a time, a new experiment here, a new experiment there that gives us new insights and gradually building up, but not getting to something yet where we're just, okay, here's an equation that now explains how, you know, that would be, have been two years of experimentation to get there, but this tells us what the result's going to be. Unfortunately, not so much yet. Not so much yet, but your hope is there. In trying to teach robots or systems to do everyday tasks or even in simulation, what do you think you're more excited about? Imitation learning or self play? So letting robots learn from humans or letting robots plan their own to try to figure out in their own way and eventually play, eventually interact with humans or solve whatever the problem is. What's the more exciting to you? What's more promising you think as a research direction? So when we look at self play, what's so beautiful about it is goes back to kind of the challenges in reinforcement learning. So the challenge of reinforcement learning is getting signal. And if you don't never succeed, you don't get any signal. In self play, you're on both sides. So one of you succeeds. And the beauty is also one of you fails. And so you see the contrast. You see the one version of me that did better than the other version. So every time you play yourself, you get signal. And so whenever you can turn something into self play, you're in a beautiful situation where you can naturally learn much more quickly than in most other reinforcement learning environments. So I think if somehow we can turn more reinforcement learning problems into self play formulations, that would go really, really far. So far, self play has been largely around games where there is natural opponents. But if we could do self play for other things, and let's say, I don't know, a robot learns to build a house. I mean, that's a pretty advanced thing to try to do for a robot, but maybe it tries to build a hut or something. If that can be done through self play, it would learn a lot more quickly if somebody can figure that out. And I think that would be something where it goes closer to kind of the mathematical leapfrogging where somebody figures out a formalism to say, okay, any RL problem by playing this and this idea, you can turn it into a self play problem where you get signal a lot more easily. Reality is, many problems we don't know how to turn into self play. And so either we need to provide detailed reward. That doesn't just reward for achieving a goal, but rewards for making progress, and that becomes time consuming. And once you're starting to do that, let's say you want a robot to do something, you need to give all this detailed reward. Well, why not just give a demonstration? Because why not just show the robot? And now the question is, how do you show the robot? One way to show is to tally operate the robot, and then the robot really experiences things. And that's nice, because that's really high signal to noise ratio data, and we've done a lot of that. And you teach your robot skills in just 10 minutes, you can teach your robot a new basic skill, like okay, pick up the bottle, place it somewhere else. That's a skill, no matter where the bottle starts, maybe it always goes onto a target or something. That's fairly easy to teach your robot with tally up. Now, what's even more interesting if you can now teach your robot through third person learning, where the robot watches you do something and doesn't experience it, but just kind of watches you. It doesn't experience it, but just watches it and says, okay, well, if you're showing me that, that means I should be doing this. And I'm not gonna be using your hand, because I don't get to control your hand, but I'm gonna use my hand, I do that mapping. And so that's where I think one of the big breakthroughs has happened this year. This was led by Chelsea Finn here. It's almost like learning a machine translation for demonstrations, where you have a human demonstration, and the robot learns to translate it into what it means for the robot to do it. And that was a meta learning formulation, learn from one to get the other. And that, I think, opens up a lot of opportunities to learn a lot more quickly. So my focus is on autonomous vehicles. Do you think this approach of third person watching, the autonomous driving is amenable to this kind of approach? So for autonomous driving, I would say third person is slightly easier. And the reason I'm gonna say it's slightly easier to do with third person is because the car dynamics are very well understood. So the... Easier than first person, you mean? Or easier than... So I think the distinction between third person and first person is not a very important distinction for autonomous driving. They're very similar. Because the distinction is really about who turns the steering wheel. Or maybe, let me put it differently. How to get from a point where you are now to a point, let's say, a couple meters in front of you. And that's a problem that's very well understood. And that's the only distinction between third and first person there. Whereas with the robot manipulation, interaction forces are very complex. And it's still a very different thing. For autonomous driving, I think there is still the question, imitation versus RL. So imitation gives you a lot more signal. I think where imitation is lacking and needs some extra machinery is, it doesn't, in its normal format, doesn't think about goals or objectives. And of course, there are versions of imitation learning and versus reinforcement learning type imitation learning which also thinks about goals. I think then we're getting much closer. But I think it's very hard to think of a fully reactive car, generalizing well. If it really doesn't have a notion of objectives to generalize well to the kind of general that you would want. You'd want more than just that reactivity that you get from just behavioral cloning slash supervised learning. So a lot of the work, whether it's self play or even imitation learning, would benefit significantly from simulation, from effective simulation. And you're doing a lot of stuff in the physical world and in simulation. Do you have hope for greater and greater power of simulation being boundless eventually to where most of what we need to operate in the physical world could be simulated to a degree that's directly transferable to the physical world? Or are we still very far away from that? So I think we could even rephrase that question in some sense. Please. And so the power of simulation, right? As simulators get better and better, of course, becomes stronger and we can learn more in simulation. But there's also another version which is where you say the simulator doesn't even have to be that precise. As long as it's somewhat representative and instead of trying to get one simulator that is sufficiently precise to learn in and transfer really well to the real world, I'm gonna build many simulators. Ensemble of simulators? Ensemble of simulators. Not any single one of them is sufficiently representative of the real world such that it would work if you train in there. But if you train in all of them, then there is something that's good in all of them. The real world will just be another one of them that's not identical to any one of them but just another one of them. Another sample from the distribution of simulators. Exactly. We do live in a simulation, so this is just one other one. I'm not sure about that, but yeah. It's definitely a very advanced simulator if it is. Yeah, it's a pretty good one. I've talked to Stuart Russell. It's something you think about a little bit too. Of course, you're really trying to build these systems, but do you think about the future of AI? A lot of people have concern about safety. How do you think about AI safety? As you build robots that are operating in the physical world, what is, yeah, how do you approach this problem in an engineering kind of way, in a systematic way? So when a robot is doing things, you kind of have a few notions of safety to worry about. One is that the robot is physically strong and of course could do a lot of damage. Same for cars, which we can think of as robots too in some way. And this could be completely unintentional. So it could be not the kind of longterm AI safety concerns that, okay, AI is smarter than us and now what do we do? But it could be just very practical. Okay, this robot, if it makes a mistake, what are the results going to be? Of course, simulation comes in a lot there to test in simulation. It's a difficult question. And I'm always wondering, like, I always wonder, let's say you look at, let's go back to driving because a lot of people know driving well, of course. What do we do to test somebody for driving, right? Get a driver's license. What do they really do? I mean, you fill out some tests and then you drive. And I mean, it's suburban California. That driving test is just you drive around the block, pull over, you do a stop sign successfully, and then you pull over again and you're pretty much done. And you're like, okay, if a self driving car did that, would you trust it that it can drive? And I'd be like, no, that's not enough for me to trust it. But somehow for humans, we've figured out that somebody being able to do that is representative of them being able to do a lot of other things. And so I think somehow for humans, we figured out representative tests of what it means if you can do this, what you can really do. Of course, testing humans, humans don't wanna be tested at all times. Self driving cars or robots could be tested more often probably. You can have replicas that get tested that are known to be identical because they use the same neural net and so forth. But still, I feel like we don't have this kind of unit tests or proper tests for robots. And I think there's something very interesting to be thought about there, especially as you update things. Your software improves, you have a better self driving car suite, you update it. How do you know it's indeed more capable on everything than what you had before, that you didn't have any bad things creep into it? So I think that's a very interesting direction of research that there is no real solution yet, except that somehow for humans we do. Because we say, okay, you have a driving test, you passed, you can go on the road now, and humans have accidents every like a million or 10 million miles, something pretty phenomenal compared to that short test that is being done. So let me ask, you've mentioned that Andrew Ng by example showed you the value of kindness. Do you think the space of policies, good policies for humans and for AI is populated by policies that with kindness or ones that are the opposite, exploitation, even evil? So if you just look at the sea of policies we operate under as human beings, or if AI system had to operate in this real world, do you think it's really easy to find policies that are full of kindness, like we naturally fall into them? Or is it like a very hard optimization problem? I mean, there is kind of two optimizations happening for humans, right? So for humans, there's kind of the very long term optimization which evolution has done for us and we're kind of predisposed to like certain things. And that's in some sense what makes our learning easier because I mean, we know things like pain and hunger and thirst. And the fact that we know about those is not something that we were taught, that's kind of innate. When we're hungry, we're unhappy. When we're thirsty, we're unhappy. When we have pain, we're unhappy. And ultimately evolution built that into us to think about those things. And so I think there is a notion that it seems somehow humans evolved in general to prefer to get along in some ways, but at the same time also to be very territorial and kind of centric to their own tribe. Like it seems like that's the kind of space we converged onto. I mean, I'm not an expert in anthropology, but it seems like we're very kind of good within our own tribe, but need to be taught to be nice to other tribes. Well, if you look at Steven Pinker, he highlights this pretty nicely in Better Angels of Our Nature, where he talks about violence decreasing over time consistently. So whatever tension, whatever teams we pick, it seems that the long arc of history goes towards us getting along more and more. So. I hope so. So do you think that, do you think it's possible to teach RL based robots this kind of kindness, this kind of ability to interact with humans, this kind of policy, even to, let me ask a fun one. Do you think it's possible to teach RL based robot to love a human being and to inspire that human to love the robot back? So to like RL based algorithm that leads to a happy marriage. That's an interesting question. Maybe I'll answer it with another question, right? Because I mean, but I'll come back to it. So another question you can have is okay. I mean, how close does some people's happiness get from interacting with just a really nice dog? Like, I mean, dogs, you come home, that's what dogs do. They greet you, they're excited, makes you happy when you come home to your dog. You're just like, okay, this is exciting. They're always happy when I'm here. And if they don't greet you, cause maybe whatever, your partner took them on a trip or something, you might not be nearly as happy when you get home, right? And so the kind of, it seems like the level of reasoning a dog has is pretty sophisticated, but then it's still not yet at the level of human reasoning. And so it seems like we don't even need to achieve human level reasoning to get like very strong affection with humans. And so my thinking is why not, right? Why couldn't, with an AI, couldn't we achieve the kind of level of affection that humans feel among each other or with friendly animals and so forth? So question, is it a good thing for us or not? That's another thing, right? Because I mean, but I don't see why not. Why not, yeah, so Elon Musk says love is the answer. Maybe he should say love is the objective function and then RL is the answer, right? Well, maybe. Oh, Peter, thank you so much. I don't want to take up more of your time. Thank you so much for talking today. Well, thanks for coming by. Great to have you visit.",following conversation peter abbeel professor uc berkeley director berkeley robotics learning lab researcher world work robot understand interact world especially imitation deep reinforcement learning conversation mit course artificial general intelligence artificial intelligence podcast enjoy subscribe youtube itunes podcast provider choice simply connect twitter lex friedman spell f r conversation peter abbeel mention person meet roger federer let ask think robot fully autonomously beat roger federer tennis roger federer level player tennis happen meet roger let know term get robot beat tennis kind interesting question lot challenge think ai software miss piece like hardware near robot physically run boston dynamics robot start human level ability run swing racket think hardware problem think hardware problem think hardware software problem think think independent progress hardware maybe year clay grass mean grass probably hard sliding yeah clay sure hard grass clay clay involve slide hard master actually yeah limit bipedal mean sure build machine different question course okay robot wheel wheel design differently think soon probably humanoid type setup think swing racket work basic manipulation hard think task swinge racket able hit nice backhand forehand let set stationary nice robot arm let standard industrial arm watch ball come swing racket good question sure super hard mean sure require lot reinforcement learning require lot trial error go to swing right time yeah swing right way think learnable think set ball machine let robot tennis racket think learnable maybe little bit pre training simulation yeah think feasible think swing racket feasible interesting precision cause mean mean human player hit line high precision spin spin interesting rl learn spin ball get interested maybe someday set sure get intrigued answer basically okay problem sound fascinating general problem tennis player little bit far away impressive thing see robot physical world physically boston dynamics video bring home super impressed recently robot run stair parkour type thing mean yes know underneath write lot detail hard code underneath physical ability parkour impressive meet spot mini robot person met spot mini year april mars event jeff bezos organize bring nicely follow jeff jeff leave room follow pretty impressive think confidence know learning go robot psychology know know learning go limited meet spot mini early year know go have interaction get spend time immediately deep connection psychological level know fundamental work magical think psychology interact robot physical world show robot little bit like face little bit like face immediately draw think aspect robotic problem hard brad berkeley robot elimination tedious tasks hard think robot person like everybody call reason make person pretty natural think way past weekend strike see pepper time video event organize fidelity script pepper help moderate session script pepper personality child little bit hard think person sense jump conversation make interactive moderate say pepper jump hold participate like okay like person scripted hard sense robot interact physical world signal reinforcement learning work little bit direction think psychology pull yes question lot people ask think ask think unique people like result computer play computer like okay emotion interact way robot start feel think kind maybe mythologically way think run like reinforcement learning optimize objective reason objective tie person like interact system reinforcement learning system optimize robot fun naturally interactive maybe like person like pet know exactly feature acquire automatically long formalize objective mean like exhibit ground truth reward human collect information human say formulate objective learn reason emerge learning maybe way formulate objective necessarily score explicitly standard reward number number hard come scale hard person easy person okay minute nice previous minute give comparison fact result example paul christiano collaborator openai hopper mojoko hopper legged robot go backflip purely feedback like well kind equally good bunch interaction figure person ask backflip think thing oh try backflip get comparison score person base person have mind mind want backflip robot know suppose know person say well bad robot figure person actually backflip imagine true thing like interactive robot robot figure time oh kind thing apparently appreciate kind thing pick sutton richard sutton reinforcement learning book sort deep learning reemergence neural network powerful mechanism machine learning rl like magic beautiful like intelligence rl reinforcement learning think possibly learn world reward action delay sparse like think rl work think learn sparse reward regular reinforcement learning deep reinforcement learning intuition counterpart rl need sample experience learn happen sparse reward maybe like know action reward maybe like score like okay sure mean know sequence action second time bad sequence action time tough know well bad good bad need experience experience effectively rl tease apart try okay consistently high reward consistently low reward kind magic policy gradient update let update neural network action kind present thing good likely action present thing good likely counterpoint like need run lot right people rl inefficient way efficient imagine paper simple update policy policy gradient learn exactly say common action produce good result learn counterintuitive intuition yeah think way think way tend think originally start work deep reinforcement learning berkeley maybe time john schulman phd student initially kind drive forward way think time think rectified linear unit kind rectifi type neural network piecewise linear feedback control look literature linear feedback control extremely successful solve problem surprisingly remember example helicopter flight stationary flight regime non stationary stationary flight regime like hover use linear feedback control stabilize helicopter complex dynamical system controller relatively simple think big feedback control system control complex relatively simple control architecture lot linear good way think neural network tile space people try hand finite state machine linear controller linear controller neural network learn tile space linear controller linear controller subtle benefit linear control aspect benefit tiling tile dimension time let layer network hide layer transition active inactive way essentially axis axis align direction change kind gradual tiling space lot sharing linear controller tile space intuition expect work pretty essentially leverage fact linear feedback control good course gradual tiling space linear feedback control share lot expertise nice intuition think scale general problem start go number dimension start go term clean reward signal intuition carry forward crazy weird world think real world think thing tricky real world compare thing look far great success reinforcement learning time scale take extreme think real world mean know maybe student decide phd right okay decision high level decision think life mean person life sequence muscle fiber contraction relaxation interact world high frequency control thing ultimately affect world guess brain reading maybe slightly differently typically affect world decision phd abstract relative actually world think credit assignment completely current rl algorithm need hierarchical reasoning level available think pick hierarchical reasoning mechanism yeah maybe let highlight think limitation year ago fact find reasoning system reason relatively long horizon problem ground real world people hand design kind logical dynamical description world tie perception tie real object forth big gap deep learning start have ability sensor process understand world good time try bring thing way get way deep learning bolt traditional approach bolt probably mean need kind end end training deep learning processing lead representation term use kind traditional underlie dynamical system plan example direction aviv tamar thanard kuretach push causal info course people way force form factor amenable reason direction think long time progress information theoretic approach idea mean high level action choose latent variable tell lot go to case future mean high level action okay decide go to navigate gas station need gas car minute fact tell high level action take early hard time get success say dead end necessarily lot trouble get work start revisit notion try achieve try achieve necessarily hierarchy se think hierarchy hope well credit assignment well credit assignment give give fast learning right fast learning ultimately maybe end rl square paper learn reinforcement learn time rocky dwan lead exactly meta learning approach okay know design hierarchy know want let enter optimize want emerge see thing emerge maze navigation consistent motion hallway want hierarchical control want hallway option turn decide turn repeat notion revisit place scale real world kind scenario think mind sign life maybe meta learn hierarchical concept mean like meta learning concept think hard important problem ai transfer learn generalization far journey build general system able transfer learn sign generalize little bit think right path totally different breakthrough need able transfer knowledge different learned model yeah pretty torn think impressive impressive result mean initial kind big breakthrough alexnet initial thing okay great well imagenet image recognition immediately course notion wow learn imagenet wanna solve new task fine tune alexnet new task find big deal learn reusable case usually machine learning learn scenario exciting mean huge application probably big success transfer learn today term scope impact huge breakthrough recently feel like similar kind scale thing like expand like people train big network transfer well look example openai result language model recent google result language model learn prediction reuse task think train big model thing transfer deep mind result think impressive unreal result learn navigate maze way reinforcement learning objective optimize think lot interesting result think maybe hard wrap head extent generalization level generalization real world level generalization involve different task right draw way frame thing hear difference learn master versus learn generalize nice line think guess say gray area learn master learn generalize start think hear hear think interview maybe yoshua benjamin sure like example sure example essentially use current deep learning technique predict let relative motion planet pretty massive new mass enter solar system probably predict happen right different kind generalization generalization rely ultimate simple simple explanation available today explain motion planet pattern recognition predict current solar system motion pretty problem think example kind generalization little different achieve far clear regularize force come simple simple simple explanation look simple physics researcher right simple simple simple equation explain master equation entire dynamic universe push direction hard deep learning sure push kind generalization current method far talk vladimir vapnik example statistician statistical learning kind dream create e equal mc square learning right general theory learn think fruitless pursuit near term decade think interesting pursuit following sense lot evidence brain pretty modular maybe think theory maybe underlying theory kind principle finding people blind use brain usually vision function kind people rewire way able reuse part brain function suggest kind modularity think pretty natural thing strive find modularity find thing course brain exactly rewire arbitrarily think thing like neocortex pretty big brain fairly modular finding far design equally modular grow capable probably think kind interesting underlying principle shoot unrealistic think prefer math empirical trial error discovery essence mean intelligent reinforcement learning embody group right prove converge prove bound time lot success let try work gravitate think part brain maybe prefer progress mathematic reason maybe prefer mathematically formalize leapfrog lot experimentation experimentation take long time lot trial error kind reinforcement learning research process need lot trial error success leapfrog mind math hopefully bunch experiment start see pattern derivation leapfrog experiment agree mean practice lot progress able find math allow leapfrog ahead kind make gradual progress step time new experiment new experiment give new insight gradually build get okay equation explain know year experimentation tell result go unfortunately hope try teach robot system everyday task simulation think excited imitation learning self play let robot learn human let robot plan try figure way eventually play eventually interact human solve problem exciting promising think research direction look self play beautiful go kind challenge reinforcement learning challenge reinforcement learning get signal succeed signal self play side succeed beauty fail contrast version well version time play signal turn self play beautiful situation naturally learn quickly reinforcement learning environment think turn reinforcement learning problem self play formulation far far self play largely game natural opponent self play thing let know robot learn build house mean pretty advanced thing try robot maybe try build hut self play learn lot quickly somebody figure think go close kind mathematical leapfrogging somebody figure formalism okay rl problem play idea turn self play problem signal lot easily reality problem know turn self play need provide detailed reward reward achieve goal reward make progress time consume start let want robot need detailed reward demonstration robot question robot way tally operate robot robot experience thing nice high signal noise ratio datum lot teach robot skill minute teach robot new basic skill like okay pick bottle place skill matter bottle start maybe go target fairly easy teach robot tally interesting teach robot person learn robot watch experience kind watch experience watch say okay show mean go to hand control hand go to use hand mapping think big breakthrough happen year lead chelsea finn like learn machine translation demonstration human demonstration robot learn translate mean robot meta learning formulation learn think open lot opportunity learn lot quickly focus autonomous vehicle think approach person watch autonomous driving amenable kind approach autonomous driving person slightly easy reason go to slightly easy person car dynamic understand easy person mean easy think distinction person person important distinction autonomous driving similar distinction turn steering wheel maybe let differently point point let couple meter problem understood distinction person robot manipulation interaction force complex different thing autonomous driving think question imitation versus rl imitation give lot signal think imitation lack need extra machinery normal format think goal objective course version imitation learning versus reinforcement learning type imitation learning think goal think get close think hard think fully reactive car generalize notion objective generalize kind general want want reactivity behavioral cloning slash supervise learning lot work self play imitation learning benefit significantly simulation effective simulation lot stuff physical world simulation hope great great power simulation boundless eventually need operate physical world simulate degree directly transferable physical world far away think rephrase question sense power simulation right simulator well well course strong learn simulation version simulator precise long somewhat representative instead try simulator sufficiently precise learn transfer real world go to build simulator ensemble simulator ensemble simulator single sufficiently representative real world work train train good real world identical sample distribution simulator exactly live simulation sure yeah definitely advanced simulator yeah pretty good talk stuart russell think little bit course try build system think future ai lot people concern safety think ai safety build robot operate physical world yeah approach problem engineering kind way systematic way robot thing kind notion safety worry robot physically strong course lot damage car think robot way completely unintentional kind longterm ai safety concern okay ai smart practical okay robot make mistake result go course simulation come lot test simulation difficult question wonder like wonder let look let drive lot people know drive course test somebody driving right driver license mean fill test drive mean suburban california drive test drive block pull stop sign successfully pull pretty like okay self driving car trust drive like trust human figure somebody able representative able lot thing think human figure representative test mean course test human human wanna test time self drive car robot test probably replica test know identical use neural net forth feel like kind unit test proper test robot think interesting think especially update thing software improve well self drive car suite update know capable bad thing creep think interesting direction research real solution human okay drive test pass road human accident like million million mile pretty phenomenal compare short test let ask mention andrew ng example show value kindness think space policy good policy human ai populate policy kindness one opposite exploitation evil look sea policy operate human being ai system operate real world think easy find policy kindness like naturally fall like hard optimization problem mean kind optimization happen human right human kind long term optimization evolution kind predispose like certain thing sense make learning easy mean know thing like pain hunger thirst fact know teach kind innate hungry unhappy thirsty unhappy pain unhappy ultimately evolution build think thing think notion human evolve general prefer way time territorial kind centric tribe like like kind space converge mean expert anthropology like kind good tribe need teach nice tribe look steven pinker highlight pretty nicely better angels nature talk violence decrease time consistently tension team pick long arc history go get hope think think possible teach rl base robot kind kindness kind ability interact human kind policy let ask fun think possible teach rl base robot love human inspire human love robot like rl base algorithm lead happy marriage interesting question maybe answer question right mean come question okay mean close people happiness interact nice dog like mean dog come home dog greet excited make happy come home dog like okay exciting happy greet cause maybe partner take trip nearly happy home right kind like level reason dog pretty sophisticated level human reasoning like need achieve human level reasoning like strong affection human thinking right ai achieve kind level affection human feel friendly animal forth question good thing thing right mean yeah elon musk say love answer maybe love objective function rl answer right maybe oh peter thank want time thank talk today thank come great visit,"['Peter Abbeel', 'Lex Friedman', 'Roger Federer', 'Spot Mini', 'Jeff Bezos', 'Paul Christiano', 'Mojoko Hopper', 'Richard Sutton', 'John Schulman', 'Aviv Tamar', 'Thanard Kuretach', 'Rocky Dwan', 'Yoshua Benjamin', 'Vladimir Vapnik', 'Chelsea Finn', 'Stuart Russell', 'Andrew Ng', 'Steven Pinker', 'Elon Musk']","['UC Berkeley', 'OpenAI', 'Google']","['Reinforcement Learning Algorithms', 'Deep Neural Networks', 'Robotics Control Systems', 'PyTorch']","['Reinforcement Learning', 'Deep Learning', 'Robotics and Automation', 'Machine Learning Fundamentals', 'AI in Business and Industry']"
